{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + (np.e**-x))\n",
    "                \n",
    "def clean_documents(docs):\n",
    "    def clean_doc(doc):\n",
    "        ''' remove unwanter characters line new line '''\n",
    "\n",
    "        unwanted_chrs = [')', '(', '{', '}', '\\t', '\\n', '\\r', \"'\", '\"', \"!\"]\n",
    "        for unwanted_chr in unwanted_chrs:\n",
    "            doc = doc.replace(unwanted_chr, ' ')\n",
    "\n",
    "        return doc.strip()\n",
    "    \n",
    "    return [clean_doc(doc) for doc in docs]\n",
    "\n",
    "def build_topic_word_distr(topics, word_topic_cos, words, topic_word_window_width, word_doc_frequency):\n",
    "    topic_word_distr = pd.DataFrame(data=0.0, columns=topics, index=words)\n",
    "\n",
    "    for topic in tqdm(range(len(topics))):\n",
    "        word_topic_co = word_topic_cos[topic]\n",
    "        word_word_co = pd.DataFrame(data=0.0, columns=word_topic_co[:topic_word_window_width].index, index=words)\n",
    "\n",
    "        for index, (top_word, corelation) in enumerate(word_topic_co.items()):\n",
    "            if index == topic_word_window_width:\n",
    "                break\n",
    "\n",
    "            word_word_frequency = corelation * word_doc_binary_freqency[word_doc_binary_freqency[top_word] > 0].sum(0)\n",
    "            trust_factor = sigmoid(word_doc_frequency)\n",
    "\n",
    "            word_word_co[top_word] = (word_word_frequency * trust_factor) / word_doc_frequency\n",
    "        topic_word_distr[topics[topic]] = word_word_co.max(1)\n",
    "    return topic_word_distr\n",
    "\n",
    "def infer_topic(topics, doc_vector, topic_word_distr):\n",
    "    doc_topic_word_distr = topic_word_distr.copy()\n",
    "    doc_word_freq_norm = (doc_vector > 0).astype(int)\n",
    "#     doc_word_freq_norm = doc_vector / doc_vector.sum() if doc_vector.sum() else 0\n",
    "\n",
    "    for topic in topics:\n",
    "        doc_topic_word_distr[topic] *= doc_word_freq_norm\n",
    "    \n",
    "    return doc_topic_word_distr, np.max(doc_topic_word_distr).idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of samples needed\n",
    "datasize = 1000\n",
    "randomize = False\n",
    "\n",
    "# retrieve dataset\n",
    "docs = fetch_20newsgroups(subset='train', shuffle=randomize, remove=('headers', 'footers', 'quotes'))\n",
    "docs, old_labels, classes = docs.data[:datasize], docs.target[:datasize], docs.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the actual labels as np array\n",
    "old_labels = np.array(old_labels)\n",
    "labels = np.zeros(old_labels.shape, dtype=int)\n",
    "\n",
    "# the new classes\n",
    "label_classes = list(set([x.split('.')[0] for x in classes]))\n",
    "\n",
    "# restructuring classes  from 19 to less\n",
    "for label, cl in enumerate(classes):\n",
    "    labels[old_labels == label] = label_classes.index(cl.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 1000 docs and 7 classes: ['comp', 'talk', 'sci', 'soc', 'alt', 'rec', 'misc']\n"
     ]
    }
   ],
   "source": [
    "print(f\"there are {len(docs)} docs and {len(label_classes)} classes: {label_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'morgan and guzman will have era s 1 run higher than last year, and  the cubs will be idiots and not pitch harkey as much as hibbard.  castillo won t be good  i think he s a stud pitcher'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean out the new line characters from text in docs\n",
    "clean_docs = clean_documents(docs)\n",
    "clean_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### count words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_count shape is (1, 19476)\n"
     ]
    }
   ],
   "source": [
    "# initialize the count vectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "# count_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# fit it to dataset\n",
    "count_vectorizer.fit(clean_docs)\n",
    "\n",
    "# create dataset\n",
    "word_count = pd.DataFrame(count_vectorizer.vocabulary_, index=[0])\n",
    "\n",
    "print(\"word_count shape is\", word_count.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>morgan</th>\n",
       "      <th>and</th>\n",
       "      <th>guzman</th>\n",
       "      <th>will</th>\n",
       "      <th>have</th>\n",
       "      <th>era</th>\n",
       "      <th>run</th>\n",
       "      <th>higher</th>\n",
       "      <th>than</th>\n",
       "      <th>last</th>\n",
       "      <th>...</th>\n",
       "      <th>optilink</th>\n",
       "      <th>molested</th>\n",
       "      <th>w4wg</th>\n",
       "      <th>lastdrive</th>\n",
       "      <th>refund</th>\n",
       "      <th>lurch</th>\n",
       "      <th>conical</th>\n",
       "      <th>cornea</th>\n",
       "      <th>skysweepers</th>\n",
       "      <th>skies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12098</td>\n",
       "      <td>2746</td>\n",
       "      <td>8904</td>\n",
       "      <td>19022</td>\n",
       "      <td>9063</td>\n",
       "      <td>7336</td>\n",
       "      <td>15421</td>\n",
       "      <td>9215</td>\n",
       "      <td>17511</td>\n",
       "      <td>10791</td>\n",
       "      <td>...</td>\n",
       "      <td>12940</td>\n",
       "      <td>12042</td>\n",
       "      <td>18740</td>\n",
       "      <td>10792</td>\n",
       "      <td>14779</td>\n",
       "      <td>11250</td>\n",
       "      <td>5281</td>\n",
       "      <td>5505</td>\n",
       "      <td>16267</td>\n",
       "      <td>16249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 19476 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   morgan   and  guzman   will  have   era    run  higher   than   last  ...  \\\n",
       "0   12098  2746    8904  19022  9063  7336  15421    9215  17511  10791  ...   \n",
       "\n",
       "   optilink  molested   w4wg  lastdrive  refund  lurch  conical  cornea  \\\n",
       "0     12940     12042  18740      10792   14779  11250     5281    5505   \n",
       "\n",
       "   skysweepers  skies  \n",
       "0        16267  16249  \n",
       "\n",
       "[1 rows x 19476 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Datatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670 train_docs, 330 test docs\n"
     ]
    }
   ],
   "source": [
    "# create doc count vectors\n",
    "doc_vectors = count_vectorizer.transform(clean_docs).toarray()\n",
    "\n",
    "train_doc_vectors, test_doc_vectors, train_labels, test_labels = train_test_split(doc_vectors, labels, test_size=.33, random_state=42)\n",
    "print(f\"{len(train_labels)} train_docs, {len(test_labels)} test docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document_word_frequency shape is (670, 19477)\n"
     ]
    }
   ],
   "source": [
    "document_word_frequency = pd.DataFrame(train_doc_vectors, columns=count_vectorizer.get_feature_names())\n",
    "document_word_binary_frequency = (document_word_frequency > 0).astype('int')\n",
    "\n",
    "document_word_frequency[\"__labels__\"] = train_labels\n",
    "document_word_binary_frequency[\"__labels__\"] = train_labels\n",
    "\n",
    "print(\"document_word_frequency shape is\", document_word_frequency.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 1000 docs and 7 classes\n"
     ]
    }
   ],
   "source": [
    "print(f\"there are {len(clean_docs)} docs and {len(label_classes)} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>00000000</th>\n",
       "      <th>00000000b</th>\n",
       "      <th>00000001</th>\n",
       "      <th>00000001b</th>\n",
       "      <th>00000010</th>\n",
       "      <th>00000010b</th>\n",
       "      <th>00000011</th>\n",
       "      <th>...</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoomed</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zubov</th>\n",
       "      <th>zum</th>\n",
       "      <th>zupancic</th>\n",
       "      <th>zx</th>\n",
       "      <th>zx900a</th>\n",
       "      <th>zzz</th>\n",
       "      <th>__labels__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 19477 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0000  00000000  00000000b  00000001  00000001b  00000010  \\\n",
       "0   0    0     0         0          0         0          0         0   \n",
       "1   0    0     0         0          0         0          0         0   \n",
       "2   0    0     0         0          0         0          0         0   \n",
       "3   0    0     0         0          0         0          0         0   \n",
       "4   0    0     0         0          0         0          0         0   \n",
       "\n",
       "   00000010b  00000011  ...  zoom  zoomed  zooming  zubov  zum  zupancic  zx  \\\n",
       "0          0         0  ...     0       0        0      0    0         0   0   \n",
       "1          0         0  ...     0       0        0      0    0         0   0   \n",
       "2          0         0  ...     0       0        0      0    0         0   0   \n",
       "3          0         0  ...     0       0        0      0    0         0   0   \n",
       "4          0         0  ...     0       0        0      0    0         0   0   \n",
       "\n",
       "   zx900a  zzz  __labels__  \n",
       "0       0    0           2  \n",
       "1       0    0           0  \n",
       "2       0    0           1  \n",
       "3       0    0           2  \n",
       "4       0    0           5  \n",
       "\n",
       "[5 rows x 19477 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_word_frequency.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>00000000</th>\n",
       "      <th>00000000b</th>\n",
       "      <th>00000001</th>\n",
       "      <th>00000001b</th>\n",
       "      <th>00000010</th>\n",
       "      <th>00000010b</th>\n",
       "      <th>00000011</th>\n",
       "      <th>...</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoomed</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zubov</th>\n",
       "      <th>zum</th>\n",
       "      <th>zupancic</th>\n",
       "      <th>zx</th>\n",
       "      <th>zx900a</th>\n",
       "      <th>zzz</th>\n",
       "      <th>__labels__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 19477 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0000  00000000  00000000b  00000001  00000001b  00000010  \\\n",
       "0   0    0     0         0          0         0          0         0   \n",
       "1   0    0     0         0          0         0          0         0   \n",
       "2   0    0     0         0          0         0          0         0   \n",
       "3   0    0     0         0          0         0          0         0   \n",
       "4   0    0     0         0          0         0          0         0   \n",
       "\n",
       "   00000010b  00000011  ...  zoom  zoomed  zooming  zubov  zum  zupancic  zx  \\\n",
       "0          0         0  ...     0       0        0      0    0         0   0   \n",
       "1          0         0  ...     0       0        0      0    0         0   0   \n",
       "2          0         0  ...     0       0        0      0    0         0   0   \n",
       "3          0         0  ...     0       0        0      0    0         0   0   \n",
       "4          0         0  ...     0       0        0      0    0         0   0   \n",
       "\n",
       "   zx900a  zzz  __labels__  \n",
       "0       0    0           2  \n",
       "1       0    0           0  \n",
       "2       0    0           1  \n",
       "3       0    0           2  \n",
       "4       0    0           5  \n",
       "\n",
       "[5 rows x 19477 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_word_binary_frequency.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cherry pick dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trim the data to words that spread round the corpus\n",
    "\n",
    "#reduce freq in doc to bin value of 1 or 0\n",
    "word_doc_binary_freqency = document_word_binary_frequency.drop([\"__labels__\"], axis='columns')\n",
    "\n",
    "#the sum vertically of bin freq\n",
    "word_doc_frequency = word_doc_binary_freqency.sum(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic and word corelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0 has (2108,) skew words\n",
      "topic 1 has (4005,) skew words\n",
      "topic 2 has (2502,) skew words\n",
      "topic 3 has (694,) skew words\n",
      "topic 4 has (217,) skew words\n",
      "topic 5 has (2444,) skew words\n",
      "topic 6 has (352,) skew words\n"
     ]
    }
   ],
   "source": [
    "word_topic_cos = []\n",
    "for topic, label in enumerate(label_classes):\n",
    "    word_topic_frequency = word_doc_binary_freqency[document_word_frequency['__labels__'] == topic].sum(0)\n",
    "    trust_factor = sigmoid(word_doc_frequency)\n",
    "    \n",
    "    word_topic_co = (word_topic_frequency * trust_factor) / word_doc_frequency\n",
    "    word_topic_co = word_topic_co[word_topic_co > 0.5].sort_values(ascending=False)\n",
    "    \n",
    "    word_topic_cos.append(word_topic_co)\n",
    "    print(f\"topic {topic} has {word_topic_co.shape} skew words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comp', 'talk', 'sci', 'soc', 'alt', 'rec', 'misc']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "encryption    0.999998\n",
       "clipper       0.999994\n",
       "escrow        0.999665\n",
       "lunar         0.999089\n",
       "orbit         0.997527\n",
       "                ...   \n",
       "step          0.555487\n",
       "sort          0.550000\n",
       "safety        0.545445\n",
       "science       0.538460\n",
       "cause         0.526316\n",
       "Length: 2502, dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_index = label_classes.index('sci')\n",
    "word_topic_cos[topic_index][word_topic_cos[topic_index] > 0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Topic_word_distr_prime...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf36729e28644b0a491112002e8e15c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3640374ef8e345febf450c06e39117ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=670.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> topic_word_distr_prime has shape (19476, 7) from window_size 100 and window_step 100 accuracy is 76.12%\n",
      "\n",
      "Building Topic_word_distr_prime...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a9e54576d424c26a728b9ae269eafde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aee258cd3624f5f96cae824b5f2cef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=670.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> topic_word_distr_prime has shape (19476, 7) from window_size 200 and window_step 100 accuracy is 82.54%\n",
      "\n",
      "Building Topic_word_distr_prime...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bea61a20a19499f925922cfba68ca91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bafd3b49fcfa45f3bde37afac81d9e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=670.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> topic_word_distr_prime has shape (19476, 7) from window_size 300 and window_step 100 accuracy is 85.67%\n",
      "\n",
      "Building Topic_word_distr_prime...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa848b9d54341e9831eaaa01c09c474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0de2569fa243e88def7faead2bbd66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=670.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> topic_word_distr_prime has shape (19476, 7) from window_size 400 and window_step 100 accuracy is 85.52%\n",
      "\n",
      "Building Topic_word_distr_prime...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c85d3455cf411db7ae0a6b90187ba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f181795996cb4009b48260dae7d146ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=670.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> topic_word_distr_prime has shape (19476, 7) from window_size 310 and window_step 10 accuracy is 85.67%\n",
      "\n",
      "accuracy low 0.0\n"
     ]
    }
   ],
   "source": [
    "converged = False\n",
    "last_accuracy = last_max_accuracy = 0\n",
    "window_size = 100\n",
    "window_step = window_base_step = 100\n",
    "decay_factor = 10\n",
    "\n",
    "while not converged:\n",
    "    print(\"Building Topic_word_distr_prime...\")\n",
    "    topic_word_distr_prime = build_topic_word_distr(label_classes, word_topic_cos, word_doc_binary_freqency.columns, window_size, word_doc_frequency)\n",
    "\n",
    "    score = 0\n",
    "    print(\"Evaluating Topic Model...\")\n",
    "    for doc_index in tqdm(range(len(train_labels))):\n",
    "        doc_vector = train_doc_vectors[doc_index]\n",
    "        doc_topic_word_distr, doc_topic = infer_topic(label_classes, doc_vector, topic_word_distr_prime)\n",
    "        score += int(doc_topic == label_classes[train_labels[doc_index]])\n",
    "\n",
    "    accuracy = score / (doc_index + 1)\n",
    "    print(f\"==> topic_word_distr_prime has shape {topic_word_distr_prime.shape} from window_size {window_size} and window_step {window_step} accuracy is {accuracy*100:.2f}%\\n\")\n",
    "    \n",
    "    if abs(accuracy - last_max_accuracy) < .001:\n",
    "        print(\"accuracy low\", abs(accuracy - last_max_accuracy))\n",
    "        converged = True\n",
    "        \n",
    "    elif accuracy >= last_max_accuracy:\n",
    "        window_size += window_step\n",
    "        last_max_accuracy = accuracy\n",
    "    \n",
    "    else:\n",
    "        if last_accuracy == last_max_accuracy:\n",
    "            window_size -= window_step\n",
    "            window_step = int(window_step / decay_factor)\n",
    "            \n",
    "            if not window_step:\n",
    "                print(\"window decayed!!\")\n",
    "                converged = False\n",
    "        window_size += window_step\n",
    "        \n",
    "    last_accuracy = accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Topic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "055c232937b448439bf416556fe62561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=330.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> topic_word_distr has shape (19476, 7) from window_size 310 and window_step 10 test-accuracy is 62.73%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "print(\"Evaluating Topic Model...\")\n",
    "for doc_index in tqdm(range(len(test_labels))):\n",
    "    doc_vector = test_doc_vectors[doc_index]\n",
    "    doc_topic_word_distr, doc_topic = infer_topic(label_classes, doc_vector, topic_word_distr_prime)\n",
    "    score += int(doc_topic == label_classes[test_labels[doc_index]])\n",
    "    \n",
    "    if score:\n",
    "        continue\n",
    "    \n",
    "#     print(clean_docs[len(train_labels)+doc_index])\n",
    "#     print(\"{:8s} {:16s} {:6s}\".format(\"topic\", \"word\", \"relation\"))\n",
    "#     print(\"=\"*40)\n",
    "#     for label, word in doc_topic_word_distr.idxmax().items():\n",
    "#         print(\"{:8s} {:16s} {:.4f}\".format(label, word, doc_topic_word_distr[label][word]))\n",
    "\n",
    "#     print(f\"\\nthe topic predicted is ==> '{np.max(doc_topic_word_distr).idxmax()}'\")\n",
    "#     print(f\"the actual topic is ==> '{label_classes[labels[doc_index]]}'\")\n",
    "\n",
    "accuracy = score / (doc_index + 1)\n",
    "print(f\"==> topic_word_distr has shape {topic_word_distr_prime.shape} from window_size {window_size} and window_step {window_step} test-accuracy is {accuracy*100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

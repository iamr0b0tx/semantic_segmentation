{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "from utils import *\n",
    "from word_network import WordNetwork\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import entropy as calculate_entropy\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of samples needed\n",
    "randomize = False\n",
    "\n",
    "# retrieve dataset\n",
    "categories = ['rec.autos', 'talk.politics.mideast', 'comp.graphics', 'sci.space']\n",
    "\n",
    "docs = fetch_20newsgroups(subset='train', shuffle=randomize, remove=('headers', 'footers', 'quotes'), categories=categories)\n",
    "docs, old_labels, classes = docs.data, docs.target, docs.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db9ac0fce5824829881ec3ebd0b6148e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "i don t like this comment about typical think you could state your interpretation of exodus without it a i read exodus i can see a lot of kill there which be paint by the author of the bible in ideological religious color the history in the desert can be see a an ethos of any nomadic people occupy a land that s why i think it be a great book with which descendant arab turk and mongol can unify a well\n"
     ]
    }
   ],
   "source": [
    "datasize = 100\n",
    "max_document_length = None\n",
    "\n",
    "index = -1\n",
    "clean_docs, labels = [], []\n",
    "\n",
    "sizes = [0]*len(categories)\n",
    "\n",
    "with tqdm(total=len(categories)*datasize) as pbar:\n",
    "    while sum(sizes) != len(categories)*datasize:\n",
    "        index += 1\n",
    "        size_index = categories.index(classes[old_labels[index]])\n",
    "        \n",
    "        if sizes[size_index] == datasize:\n",
    "            continue\n",
    "        \n",
    "        doc = docs[index]\n",
    "        status, doc, word_count = clean_doc(doc, True)\n",
    "        \n",
    "        if (not status) or (max_document_length is not None and len(doc) > max_document_length):\n",
    "            continue\n",
    "        \n",
    "        labels.append(categories[size_index])\n",
    "        clean_docs.append(doc)\n",
    "        sizes[size_index] += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: talk.politics.mideast\n",
      "==================================================\n",
      "first of all i never say the holocaust i say before the holocaust i m not ignorant of the holocaust and know more about nazi germany than most people maybe include you what i resent be ignorant statement that call people name when they disagree with your position oppose the atrocity commit by the israeli governement hardly qualifies a anti semitism if you think name call be a valid form of argument in intellectual circle you need to get out more often i don t think the suffer of some jew during wwii justifies the crime commit by the israeli government any attempt to call civil liberterians like myself anti semetic be not appreciate\n"
     ]
    }
   ],
   "source": [
    "index = 13\n",
    "print(f\"Topic: {labels[index]}\\n{'='*50}\\n{clean_docs[index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 100, 100, 100]\n"
     ]
    }
   ],
   "source": [
    "print(sizes)\n",
    "assert min(sizes) == max(sizes) == datasize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 400 docs\n"
     ]
    }
   ],
   "source": [
    "print(f\"there are {len(clean_docs)} docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### count words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_count is 10006\n"
     ]
    }
   ],
   "source": [
    "# mode = \"tfidf\"\n",
    "# mode = \"binary\"\n",
    "# mode = \"normalize\"\n",
    "# mode = \"binary-normalize\"\n",
    "mode = \"pmi\"\n",
    "\n",
    "# initialize the count vectorizer\n",
    "vectorizer = TfidfVectorizer() if mode == \"tfidf\" else CountVectorizer()\n",
    "\n",
    "# fit it to dataset\n",
    "train_docs, test_docs = clean_docs, []\n",
    "# train_docs, test_docs = train_test_split(clean_docs, test_size=.33, random_state=42)\n",
    "\n",
    "vectorizer.fit(train_docs)\n",
    "vocabulary = vectorizer.get_feature_names()\n",
    "\n",
    "print(\"word_count is\", len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Datatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 train_docs, 0 test docs\n"
     ]
    }
   ],
   "source": [
    "# create doc count vectors\n",
    "train_doc_vectors = vectorizer.transform(train_docs).toarray()\n",
    "test_doc_vectors = vectorizer.transform(test_docs).toarray()\n",
    "\n",
    "if mode in [\"binary-normalize\", \"binary\", \"pmi\"]:\n",
    "    train_doc_vectors = (train_doc_vectors > 0).astype(float)\n",
    "    test_doc_vectors = (test_doc_vectors > 0).astype(float)\n",
    "    \n",
    "if mode == \"normalize\" or mode == \"binary-normalize\":\n",
    "    train_doc_vectors = normalize(train_doc_vectors, norm=\"l1\", axis=1)\n",
    "    test_doc_vectors = normalize(test_doc_vectors, norm=\"l1\", axis=1)\n",
    "\n",
    "print(f\"{len(train_doc_vectors)} train_docs, {len(test_doc_vectors)} test docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word-Word Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be36c9f7d5a94285887558195e9a2fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10006.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\pandas\\core\\series.py:679: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\christian\\Documents\\christian\\work\\python\\cyberspace\\semantic_segmentation\\utils.py:15: RuntimeWarning: overflow encountered in power\n",
      "  return 1 / (1 + (np.e**-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "word_word_co has shape (10006, 10006)\n"
     ]
    }
   ],
   "source": [
    "#reduce freq in doc to bin value of 1 or 0\n",
    "word_doc_freqency = pd.DataFrame(train_doc_vectors, columns=vocabulary)\n",
    "\n",
    "#the sum vertically of bin freq\n",
    "word_doc_total_frequency = word_doc_freqency.sum(0)\n",
    "\n",
    "word_word_co = pd.DataFrame(data=0.0, columns=vocabulary, index=vocabulary)\n",
    "\n",
    "word_frequency_norm = ((word_doc_freqency > 0).sum(0) / len(train_doc_vectors))\n",
    "p = pd.DataFrame((train_doc_vectors.sum(0) / len(train_doc_vectors)), columns=[0], index=vocabulary)[0]\n",
    "\n",
    "for word in tqdm(vocabulary):\n",
    "    pxy = word_doc_freqency[word_doc_freqency[word] == 1].sum(0) / len(train_doc_vectors)\n",
    "    word_word_co[word] = sigmoid(np.nan_to_num(np.log2(pxy / (p[word] * p))))\n",
    "\n",
    "# word_word_co = (word_word_co.T / word_word_co.sum(1)).T\n",
    "print(f\"word_word_co has shape {word_word_co.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #reduce freq in doc to bin value of 1 or 0\n",
    "# word_doc_freqency = pd.DataFrame(train_doc_vectors, columns=vocabulary)\n",
    "\n",
    "# #the sum vertically of bin freq\n",
    "# word_doc_total_frequency = word_doc_freqency.sum(0)\n",
    "\n",
    "# word_word_co = pd.DataFrame(data=0.0, columns=vocabulary, index=vocabulary)\n",
    "# word_frequency_norm = ((word_doc_freqency > 0).sum(0) / len(train_doc_vectors))\n",
    "\n",
    "# for word in tqdm(vocabulary):\n",
    "#     word_word_frequency = word_doc_freqency[word_doc_freqency[word] > 0].sum(0)\n",
    "#     word_word_co[word] = ((word_word_frequency * word_frequency_norm) / word_doc_total_frequency).fillna(0)\n",
    "\n",
    "# # word_word_co = (word_word_co.T / word_word_co.sum(1)).T\n",
    "# print(f\"word_word_co has shape {word_word_co.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0007</th>\n",
       "      <th>000th</th>\n",
       "      <th>0029</th>\n",
       "      <th>007</th>\n",
       "      <th>01</th>\n",
       "      <th>011</th>\n",
       "      <th>0119</th>\n",
       "      <th>013</th>\n",
       "      <th>...</th>\n",
       "      <th>zionist</th>\n",
       "      <th>zip</th>\n",
       "      <th>zippy</th>\n",
       "      <th>zman</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zorn</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>0.999521</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999521</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999521</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.989609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.989609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.989609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0007</th>\n",
       "      <td>0.999521</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000th</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0029</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10006 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             00       000      0007     000th      0029       007        01  \\\n",
       "00     0.999521  0.000000  0.999521  0.000000  0.000000  0.000000  0.000000   \n",
       "000    0.000000  0.989609  0.000000  0.000000  0.000000  0.989609  0.000000   \n",
       "0007   0.999521  0.000000  0.999824  0.000000  0.000000  0.000000  0.000000   \n",
       "000th  0.000000  0.000000  0.000000  0.999824  0.000000  0.000000  0.000000   \n",
       "0029   0.000000  0.000000  0.000000  0.000000  0.999824  0.000000  0.999141   \n",
       "\n",
       "       011  0119  013  ...   zionist  zip     zippy      zman  zone  zoo  \\\n",
       "00     0.0   0.0  0.0  ...  0.000000  0.0  0.999521  0.000000   0.0  0.0   \n",
       "000    0.0   0.0  0.0  ...  0.903302  0.0  0.000000  0.989609   0.0  0.0   \n",
       "0007   0.0   0.0  0.0  ...  0.000000  0.0  0.999824  0.000000   0.0  0.0   \n",
       "000th  0.0   0.0  0.0  ...  0.000000  0.0  0.000000  0.000000   0.0  0.0   \n",
       "0029   0.0   0.0  0.0  ...  0.000000  0.0  0.000000  0.000000   0.0  0.0   \n",
       "\n",
       "           zoom  zorn  zulu  zur  \n",
       "00     0.998700   0.0   0.0  0.0  \n",
       "000    0.000000   0.0   0.0  0.0  \n",
       "0007   0.999521   0.0   0.0  0.0  \n",
       "000th  0.000000   0.0   0.0  0.0  \n",
       "0029   0.000000   0.0   0.0  0.0  \n",
       "\n",
       "[5 rows x 10006 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_word_co.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Word Trust ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_entropy = pd.DataFrame(data=np.nan_to_num(calculate_entropy(word_word_co.T, base=2)), columns=[0], index=vocabulary)[0]\n",
    "word_trust_factor = pd.DataFrame(data=gaussian2(word_entropy), columns=[0], index=vocabulary)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = [\"look\", \"algorithm\", \"program\"]\n",
    "# words = [\"looking\", \"algorithm\", \"program\", \"the\", \"to\", \"of\"]\n",
    "\n",
    "fig = plt.figure(figsize=(10,3))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "ax1.set_title(f\"Word Trust factor {word} against TOPICS\")\n",
    "ax1.bar(words, (word_trust_factor)[words])\n",
    "\n",
    "ax2.set_title(f\"Word Frequency Normalized {word} against TOPICS\")\n",
    "ax2.bar(words, word_frequency_norm[words])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe word_word_co ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "word = \"software\"\n",
    "words = [\"car\", \"god\", \"file\", \"nasa\", \"the\", \"to\", \"of\"]\n",
    "\n",
    "plt.title(f\"word_word_co {word} against TOPICS\")\n",
    "plt.bar(words, word_word_co.loc[word][words])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "arbitrary           0.990471\n",
       "sunview             0.990471\n",
       "ultrix              0.990471\n",
       "615                 0.990471\n",
       "multidimensional    0.990471\n",
       "61820               0.990471\n",
       "619                 0.990471\n",
       "ultimage            0.990471\n",
       "bris                0.990471\n",
       "multiplot           0.990471\n",
       "brush               0.990471\n",
       "sunspot             0.990471\n",
       "627                 0.990471\n",
       "multiprocessor      0.990471\n",
       "multispectral       0.990471\n",
       "Name: software, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_word_co.loc[word].sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update word_word_co with gaussian entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_word_co = (word_word_co + (word_word_co * word_word_co.T)) * word_trust_factor\n",
    "word_word_co = (word_word_co * word_trust_factor)\n",
    "word_word_co = (word_word_co.T / word_word_co.sum(1)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe word_word_co ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(f\"Updated word_word_co {word} against TOPICS\")\n",
    "plt.bar(words, word_word_co.loc[word][words])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "showing          0.024811\n",
       "apparantly       0.024811\n",
       "ce               0.024811\n",
       "3do              0.024811\n",
       "licensee         0.024811\n",
       "decompression    0.019568\n",
       "25mhz            0.019568\n",
       "tttddd           0.019544\n",
       "stereo           0.015056\n",
       "sys              0.015056\n",
       "piccy            0.013696\n",
       "ruu              0.013696\n",
       "jhwitten         0.013696\n",
       "dir              0.013696\n",
       "jpegs            0.013696\n",
       "Name: software, dtype: float64"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_word_co.loc[word].sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_entropy2 = pd.DataFrame(data=np.nan_to_num(calculate_entropy(word_word_co.T, base=2)), columns=[0], index=vocabulary)[0]\n",
    "word_trust_factor2 = pd.DataFrame(data=gaussian2(word_entropy2), columns=[0], index=vocabulary)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update word_word_co with word_word_co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wwc = pd.DataFrame(data=0.0, columns=vocabulary, index=vocabulary)\n",
    "\n",
    "# for word in tqdm(vocabulary):\n",
    "#     for other_word in vocabulary:\n",
    "#         ratios = word_word_co.loc[word][other_word] * word_word_co.loc[other_word]\n",
    "#         wwc.loc[word][ratios > wwc.loc[word]] = ratios[ratios > wwc.loc[word]]\n",
    "\n",
    "# print(f\"word_word_co has shape {word_word_co.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_word_distr = pd.DataFrame(data=0.0, columns=vocabulary, index=word_doc_freqency.index)\n",
    "# word_doc_norm = (word_doc_freqency.T / word_doc_freqency.sum(1)).T * word_trust_factor\n",
    "\n",
    "# for doc_index in tqdm([0]):#range(len(train_doc_vectors))):\n",
    "#     wv = word_doc_norm.iloc[0]\n",
    "#     wv_indices = wv[wv > (wv.max() - wv.std())].index\n",
    "#     doc_word_distr.iloc[doc_index] = (word_word_co.loc[wv_indices] * word_doc_norm.iloc[doc_index]).max(0)\n",
    "\n",
    "# print(f\"doc_word_distr has shape {doc_word_distr.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_word_distr = (word_doc_freqency.T / word_doc_freqency.sum(1)).T * word_trust_factor\n",
    "doc_word_distr = (doc_word_distr.T / doc_word_distr.sum(1)).T.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpretation    0.003220\n",
      "ethos             0.003220\n",
      "mongol            0.003220\n",
      "unify             0.003220\n",
      "exodus            0.003220\n",
      "nomadic           0.003220\n",
      "desert            0.003220\n",
      "ideological       0.000675\n",
      "bible             0.000439\n",
      "descendant        0.000210\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print((word_doc_freqency.iloc[0] * word_trust_factor).sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desintegrated    0.944805\n",
      "surgical         0.036779\n",
      "directly         0.003222\n",
      "missile          0.002453\n",
      "someone          0.001305\n",
      "hit              0.001198\n",
      "destroy          0.001196\n",
      "course           0.001151\n",
      "house            0.001135\n",
      "kill             0.000910\n",
      "Name: 10, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print((doc_word_distr.iloc[10]).sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_word_distr.iloc[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "talk.politics.mideast i don t like this comment about typical think you could state your interpretation of exodus without it a i read exodus i can see a lot of kill there which be paint by the author of the bible in ideological religious color the history in the desert can be see a an ethos of any nomadic people occupy a land that s why i think it be a great book with which descendant arab turk and mongol can unify a well\n"
     ]
    }
   ],
   "source": [
    "print(labels[0], train_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0007</th>\n",
       "      <th>000th</th>\n",
       "      <th>0029</th>\n",
       "      <th>007</th>\n",
       "      <th>01</th>\n",
       "      <th>011</th>\n",
       "      <th>0119</th>\n",
       "      <th>013</th>\n",
       "      <th>...</th>\n",
       "      <th>zionist</th>\n",
       "      <th>zip</th>\n",
       "      <th>zippy</th>\n",
       "      <th>zman</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zorn</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10006 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  0007  000th  0029  007   01  011  0119  013  ...  zionist  zip  \\\n",
       "0  0.0  0.0   0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  ...      0.0  0.0   \n",
       "1  0.0  0.0   0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  ...      0.0  0.0   \n",
       "2  0.0  0.0   0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  ...      0.0  0.0   \n",
       "3  0.0  0.0   0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  ...      0.0  0.0   \n",
       "4  0.0  0.0   0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  ...      0.0  0.0   \n",
       "\n",
       "   zippy  zman  zone  zoo  zoom  zorn  zulu  zur  \n",
       "0    0.0   0.0   0.0  0.0   0.0   0.0   0.0  0.0  \n",
       "1    0.0   0.0   0.0  0.0   0.0   0.0   0.0  0.0  \n",
       "2    0.0   0.0   0.0  0.0   0.0   0.0   0.0  0.0  \n",
       "3    0.0   0.0   0.0  0.0   0.0   0.0   0.0  0.0  \n",
       "4    0.0   0.0   0.0  0.0   0.0   0.0   0.0  0.0  \n",
       "\n",
       "[5 rows x 10006 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_word_distr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Latent partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distr_params has shape (400, 2)\n"
     ]
    }
   ],
   "source": [
    "# reduction = None\n",
    "# reduction = \"pca\"\n",
    "reduction = \"normal\"\n",
    "\n",
    "if reduction is None:\n",
    "    columns = doc_word_distr.columns\n",
    "    param_values = doc_word_distr.values\n",
    "\n",
    "if reduction == \"pca\":\n",
    "    num_of_components = 126\n",
    "    columns = list(range(num_of_components))\n",
    "    \n",
    "    pca = PCA(n_components=num_of_components)\n",
    "    param_values = pca.fit_transform(doc_word_distr)\n",
    "\n",
    "if reduction == \"normal\":\n",
    "    columns = [\"mean\", \"std\"]\n",
    "    param_values = np.array([doc_word_distr.mean(1), doc_word_distr.std(1)]).T\n",
    "    \n",
    "distr_params = pd.DataFrame(data=param_values, columns=columns, index=list(range(len(doc_word_distr))))\n",
    "print(f\"distr_params has shape {distr_params.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.003543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.009160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.001676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.003310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.006993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean       std\n",
       "0  0.0001  0.003543\n",
       "1  0.0001  0.009160\n",
       "2  0.0001  0.001676\n",
       "3  0.0001  0.003310\n",
       "4  0.0001  0.006993"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distr_params.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Kmeans MiniBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_topics = 4\n",
    "kmeans_model = MiniBatchKMeans(n_clusters=num_of_topics, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00fe80143e384b84832708a595763378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1024.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_iterations = 1024\n",
    "\n",
    "num_of_samples = len(distr_params)\n",
    "batch_size = num_of_samples // 2\n",
    "\n",
    "for i in tqdm(range(num_of_iterations)):\n",
    "    indices = np.random.randint(num_of_samples, size=batch_size)\n",
    "    \n",
    "    kmeans_model.partial_fit(distr_params.iloc[indices])\n",
    "\n",
    "kmeans_model.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist has shape (400, 4), predicted_labels has shape (400,)\n"
     ]
    }
   ],
   "source": [
    "dist = kmeans_model.transform(distr_params)\n",
    "predicted_labels = kmeans_model.predict(distr_params)\n",
    "\n",
    "# wtf = normalize(dist, norm=\"l1\", axis=1)\n",
    "# wtf = normalize(wtf, norm=\"l1\", axis=0)\n",
    "\n",
    "wtf = (dist / dist.max(0))\n",
    "\n",
    "print(f\"dist has shape {dist.shape}, predicted_labels has shape {predicted_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "voc_array = np.array(vocabulary)\n",
    "\n",
    "def get_top2(topic):\n",
    "    indices = dist[:, topic].argsort()\n",
    "    print(labels[indices[:10]])\n",
    "\n",
    "def get_top2(topic):\n",
    "    indices = np.where(predicted_labels == topic)[0]\n",
    "    print((doc_word_distr.T * wtf[:, 0]).T.iloc[indices].mean(0).sort_values(ascending=False).head(10))\n",
    "\n",
    "def get_top2(topic):\n",
    "    indices = np.where(predicted_labels == topic)[0]\n",
    "    print(((doc_word_distr.T * wtf[:, 0]).T.iloc[indices].sum(0) * word_trust_factor).sort_values(ascending=False).head(10))\n",
    "    \n",
    "def get_top(topic):\n",
    "    indices = np.where(predicted_labels == topic)[0]\n",
    "    print(Counter(labels[indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'comp.graphics': 15, 'rec.autos': 8, 'talk.politics.mideast': 8, 'sci.space': 6})\n"
     ]
    }
   ],
   "source": [
    "get_top(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'sci.space': 45, 'comp.graphics': 44, 'rec.autos': 39, 'talk.politics.mideast': 22})\n"
     ]
    }
   ],
   "source": [
    "get_top(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'rec.autos': 28, 'comp.graphics': 17, 'sci.space': 17, 'talk.politics.mideast': 14})\n"
     ]
    }
   ],
   "source": [
    "get_top(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saab          0.000003\n",
      "bound         0.000003\n",
      "advance       0.000003\n",
      "azarbaijan    0.000003\n",
      "standoff      0.000003\n",
      "mainland      0.000003\n",
      "success       0.000003\n",
      "soc           0.000003\n",
      "tankut        0.000003\n",
      "sabri         0.000003\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "get_top(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Topic model with Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54029e101f0241e6bd32fc3234049bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=268.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> train-accuracy is 90.67%, 25 misclassified\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "misclassified_train = []\n",
    "print(\"Evaluating Topic Model...\")\n",
    "\n",
    "for doc_index in tqdm(range(len(train_labels))):\n",
    "    doc_vector = train_doc_vectors[doc_index]\n",
    "    \n",
    "    doc_topic_word_distr, doc_topic = infer_topic(label_classes, doc_vector, topic_word_distr)\n",
    "    score += int(doc_topic == label_classes[train_labels[doc_index]])\n",
    "    \n",
    "    if doc_topic != label_classes[train_labels[doc_index]]:\n",
    "        misclassified_train.append(doc_index)\n",
    "    \n",
    "train_accuracy = score / (doc_index + 1)\n",
    "print(f\"==> train-accuracy is {train_accuracy*100:.2f}%, {len(misclassified_train)} misclassified\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Topic Model with test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c629d68d6d47ce9cd469637fff64ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=132.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> test-accuracy is 54.55%, avg-accuarcy = 72.61%, 60 misclassified\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "print(\"Evaluating Topic Model...\")\n",
    "\n",
    "misclassified_test = []\n",
    "for doc_index in tqdm(range(len(test_labels))):\n",
    "    doc_vector = test_doc_vectors[doc_index]\n",
    "    \n",
    "    doc_topic_word_distr, doc_topic = infer_topic(label_classes, doc_vector, topic_word_distr)\n",
    "    score += int(doc_topic == label_classes[test_labels[doc_index]])\n",
    "    \n",
    "    if doc_topic != label_classes[test_labels[doc_index]]:\n",
    "        misclassified_test.append(doc_index)\n",
    "    \n",
    "\n",
    "test_accuracy = score / (doc_index + 1)\n",
    "print(f\"==> test-accuracy is {test_accuracy*100:.2f}%, avg-accuarcy = {.5*(train_accuracy + test_accuracy)*100:.2f}%, {len(misclassified_test)} misclassified\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating Misclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac0825f5c8984e1caeb6d5393e151907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              autos  religion  graphics     space\n",
      "ve         0.000334  0.000191  0.001622  0.000000\n",
      "sense      0.000426  0.001182  0.000000  0.000000\n",
      "maybe      0.000000  0.000906  0.000605  0.000000\n",
      "shot       0.000000  0.000677  0.000000  0.000371\n",
      "that       0.000299  0.000251  0.000241  0.000251\n",
      "kind       0.000000  0.000394  0.000588  0.000000\n",
      "cheap      0.000000  0.000954  0.000000  0.000000\n",
      "embarrass  0.000000  0.000954  0.000000  0.000000\n",
      "fundies    0.000000  0.000954  0.000000  0.000000\n",
      "josh       0.000000  0.000954  0.000000  0.000000\n",
      "mood       0.000000  0.000954  0.000000  0.000000\n",
      "mcdowell   0.000000  0.000954  0.000000  0.000000\n",
      "be         0.000165  0.000224  0.000176  0.000203\n",
      "of         0.000119  0.000248  0.000176  0.000181\n",
      "to         0.000140  0.000208  0.000155  0.000176\n",
      "okay       0.000000  0.000375  0.000293  0.000000\n",
      "except     0.000307  0.000350  0.000000  0.000000\n",
      "who        0.000148  0.000316  0.000030  0.000111\n",
      "but        0.000055  0.000224  0.000197  0.000128\n",
      "have       0.000203  0.000131  0.000132  0.000116\n",
      "enough     0.000163  0.000133  0.000000  0.000267\n",
      "in         0.000133  0.000127  0.000159  0.000141\n",
      "know       0.000111  0.000089  0.000153  0.000047\n",
      "by         0.000070  0.000057  0.000077  0.000072\n",
      "few        0.000034  0.000022  0.000042  0.000071\n",
      "true       0.000036  0.000038  0.000019  0.000019\n",
      "true except that i ve know few fundies who have enough sense to be embarrass by josh mcdowell okay maybe a cheap shot but i m in that kind of mood\n",
      "==> predicted_topic = graphics, actual_topic = religion \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "he          0.000000  0.003337  0.000000  0.000834\n",
      "the         0.000517  0.000530  0.000481  0.000611\n",
      "it          0.000522  0.000267  0.000718  0.000488\n",
      "71          0.000000  0.000000  0.000000  0.001833\n",
      "until       0.000000  0.000000  0.000000  0.000917\n",
      "dubbed      0.000000  0.000000  0.000000  0.000917\n",
      "fwiw        0.000000  0.000000  0.000000  0.000917\n",
      "lbj         0.000000  0.000000  0.000000  0.000917\n",
      "mippselled  0.000000  0.000000  0.000000  0.000917\n",
      "page        0.000000  0.000000  0.000000  0.000917\n",
      "sic         0.000000  0.000000  0.000000  0.000917\n",
      "sr          0.000000  0.000000  0.000000  0.000917\n",
      "be          0.000159  0.000215  0.000170  0.000195\n",
      "doug        0.000000  0.000000  0.000438  0.000255\n",
      "who         0.000142  0.000304  0.000029  0.000107\n",
      "also        0.000165  0.000166  0.000000  0.000127\n",
      "one         0.000100  0.000080  0.000046  0.000163\n",
      "he s also the one who dubbed it the sr 71 it be the r 71 until lbj mippselled sic it fwiw doug page\n",
      "==> predicted_topic = religion, actual_topic = space \n",
      "\n",
      "            autos  religion  graphics     space\n",
      "file     0.000000  0.000000  0.005275  0.001317\n",
      "yo       0.000000  0.000000  0.000000  0.004052\n",
      "every    0.000000  0.000000  0.000454  0.001607\n",
      "string   0.000000  0.000000  0.000000  0.002026\n",
      "sig      0.000000  0.000000  0.000000  0.002026\n",
      "look     0.000375  0.000033  0.000778  0.000320\n",
      "publish  0.000000  0.000000  0.000000  0.001088\n",
      "plenty   0.000000  0.000000  0.000000  0.001088\n",
      "kiddo    0.000000  0.000000  0.000000  0.001088\n",
      "be       0.000188  0.000255  0.000201  0.000232\n",
      "to       0.000159  0.000237  0.000177  0.000200\n",
      "you      0.000255  0.000192  0.000166  0.000113\n",
      "have     0.000232  0.000150  0.000150  0.000132\n",
      "get      0.000128  0.000051  0.000223  0.000219\n",
      "one      0.000118  0.000095  0.000055  0.000193\n",
      "like     0.000133  0.000072  0.000077  0.000159\n",
      "just     0.000116  0.000059  0.000069  0.000115\n",
      "we       0.000031  0.000075  0.000074  0.000174\n",
      "we publish plenty kiddo you just have to look sig file be like string every yo yo s get one\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "human      0.000000  0.002433  0.000000  0.000381\n",
      "be         0.000572  0.000774  0.000611  0.000703\n",
      "45g        0.000000  0.000000  0.000000  0.001651\n",
      "sure       0.000000  0.000000  0.000505  0.000851\n",
      "lan        0.000000  0.000000  0.000000  0.000826\n",
      "8g         0.000000  0.000000  0.000000  0.000826\n",
      "9g         0.000000  0.000000  0.000000  0.000826\n",
      "blackout   0.000000  0.000000  0.000000  0.000826\n",
      "clarify    0.000000  0.000000  0.000000  0.000826\n",
      "dive       0.000000  0.000000  0.000000  0.000826\n",
      "pilot      0.000000  0.000000  0.000000  0.000826\n",
      "exceed     0.000000  0.000000  0.000000  0.000826\n",
      "the        0.000155  0.000159  0.000144  0.000183\n",
      "of         0.000103  0.000214  0.000153  0.000157\n",
      "to         0.000121  0.000180  0.000135  0.000152\n",
      "number     0.000048  0.000103  0.000372  0.000053\n",
      "tolerance  0.000000  0.000274  0.000000  0.000293\n",
      "far        0.000276  0.000000  0.000000  0.000290\n",
      "you        0.000193  0.000146  0.000126  0.000086\n",
      "right      0.000249  0.000059  0.000029  0.000172\n",
      "in         0.000115  0.000110  0.000138  0.000122\n",
      "please     0.000023  0.000193  0.000170  0.000090\n",
      "that       0.000130  0.000108  0.000104  0.000109\n",
      "this       0.000081  0.000102  0.000093  0.000119\n",
      "would      0.000123  0.000046  0.000073  0.000128\n",
      "know       0.000096  0.000077  0.000133  0.000041\n",
      "seem       0.000000  0.000145  0.000070  0.000077\n",
      "anybody    0.000064  0.000041  0.000153  0.000030\n",
      "out        0.000067  0.000063  0.000048  0.000029\n",
      "be you sure 45g be the right number a far a i know pilot be blackout in dive that exceed 8g 9g 45g seem to be out of human tolerance would anybody clarify this please lan\n",
      "==> predicted_topic = religion, actual_topic = space \n",
      "\n",
      "                 autos  religion  graphics     space\n",
      "for           0.000393  0.000173  0.001017  0.000217\n",
      "day           0.000000  0.000588  0.000000  0.000864\n",
      "any           0.000239  0.000079  0.000694  0.000206\n",
      "do            0.000234  0.000224  0.000367  0.000203\n",
      "lizard        0.000000  0.000921  0.000000  0.000000\n",
      "thelema       0.000000  0.000921  0.000000  0.000000\n",
      "sf            0.000000  0.000921  0.000000  0.000000\n",
      "organization  0.000000  0.000921  0.000000  0.000000\n",
      "official      0.000000  0.000921  0.000000  0.000000\n",
      "lodge         0.000000  0.000921  0.000000  0.000000\n",
      "bay           0.000000  0.000921  0.000000  0.000000\n",
      "an            0.000347  0.000229  0.000239  0.000082\n",
      "the           0.000173  0.000178  0.000161  0.000205\n",
      "of            0.000115  0.000239  0.000170  0.000175\n",
      "93            0.000272  0.000388  0.000000  0.000000\n",
      "have          0.000196  0.000127  0.000127  0.000112\n",
      "address       0.000144  0.000178  0.000215  0.000000\n",
      "these         0.000140  0.000238  0.000097  0.000000\n",
      "this          0.000090  0.000114  0.000104  0.000133\n",
      "would         0.000137  0.000051  0.000081  0.000142\n",
      "mail          0.000026  0.000037  0.000130  0.000075\n",
      "area          0.000063  0.000075  0.000000  0.000063\n",
      "do this organization have an official e mail address these day an address for any of the sf bay area lodge e g thelema would do 93 a lizard\n",
      "==> predicted_topic = graphics, actual_topic = religion \n",
      "\n",
      "                 autos  religion  graphics     space\n",
      "for           0.000452  0.000199  0.001170  0.000250\n",
      "seriously     0.000890  0.000389  0.000000  0.000000\n",
      "4000          0.001060  0.000000  0.000000  0.000000\n",
      "account       0.001060  0.000000  0.000000  0.000000\n",
      "depreciation  0.001060  0.000000  0.000000  0.000000\n",
      "taurus        0.001060  0.000000  0.000000  0.000000\n",
      "repair        0.001060  0.000000  0.000000  0.000000\n",
      "rack          0.001060  0.000000  0.000000  0.000000\n",
      "doubt         0.001060  0.000000  0.000000  0.000000\n",
      "extra         0.001060  0.000000  0.000000  0.000000\n",
      "cost          0.000124  0.000000  0.000194  0.000477\n",
      "you           0.000248  0.000187  0.000162  0.000110\n",
      "in            0.000148  0.000141  0.000177  0.000157\n",
      "do            0.000135  0.000129  0.000211  0.000117\n",
      "that          0.000166  0.000139  0.000134  0.000139\n",
      "an            0.000200  0.000132  0.000137  0.000047\n",
      "would         0.000158  0.000058  0.000094  0.000164\n",
      "up            0.000212  0.000084  0.000034  0.000066\n",
      "year          0.000070  0.000039  0.000065  0.000173\n",
      "over          0.000097  0.000028  0.000034  0.000030\n",
      "do you account for depreciation i seriously doubt that a taurus would rack up an extra 4000 in repair cost over 5 year\n",
      "==> predicted_topic = graphics, actual_topic = autos \n",
      "\n",
      "            autos  religion  graphics     space\n",
      "be       0.000507  0.000687  0.000542  0.000624\n",
      "brought  0.000595  0.000441  0.000000  0.000000\n",
      "you      0.000343  0.000258  0.000223  0.000152\n",
      "ok       0.000604  0.000181  0.000000  0.000151\n",
      "right    0.000442  0.000104  0.000051  0.000304\n",
      "john     0.000433  0.000281  0.000111  0.000000\n",
      "that     0.000230  0.000193  0.000185  0.000193\n",
      "if       0.000137  0.000137  0.000217  0.000159\n",
      "up       0.000293  0.000116  0.000047  0.000091\n",
      "name     0.000191  0.000195  0.000038  0.000079\n",
      "so       0.000155  0.000119  0.000109  0.000064\n",
      "good     0.000121  0.000086  0.000137  0.000031\n",
      "few      0.000052  0.000034  0.000065  0.000110\n",
      "example  0.000051  0.000023  0.000054  0.000028\n",
      "ok if you be so right name a few good example that be brought up john\n",
      "==> predicted_topic = religion, actual_topic = autos \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "thanks      0.000873  0.000124  0.003023  0.000781\n",
      "help        0.000000  0.000330  0.001958  0.000345\n",
      "for         0.000504  0.000222  0.001304  0.000279\n",
      "several     0.000000  0.000000  0.001029  0.000786\n",
      "it          0.000448  0.000230  0.000617  0.000419\n",
      "via         0.000000  0.000000  0.001130  0.000575\n",
      "found       0.000000  0.000675  0.000000  0.000509\n",
      "be          0.000205  0.000277  0.000219  0.000251\n",
      "offer       0.000335  0.000000  0.000000  0.000541\n",
      "contact     0.000000  0.000417  0.000000  0.000393\n",
      "and         0.000163  0.000217  0.000204  0.000217\n",
      "will        0.000103  0.000330  0.000044  0.000206\n",
      "get         0.000139  0.000055  0.000243  0.000237\n",
      "those       0.000058  0.000402  0.000111  0.000089\n",
      "people      0.000134  0.000136  0.000024  0.000067\n",
      "mail        0.000033  0.000047  0.000167  0.000096\n",
      "appreciate  0.000023  0.000073  0.000105  0.000042\n",
      "again       0.000033  0.000031  0.000017  0.000023\n",
      "found it thanks i get several offer for help i appreciate it and will be contact those people via e mail thanks again\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "moon        0.000000  0.001101  0.000000  0.001325\n",
      "the         0.000544  0.000558  0.000506  0.000643\n",
      "of          0.000240  0.000501  0.000356  0.000367\n",
      "have        0.000411  0.000265  0.000267  0.000234\n",
      "worship     0.000000  0.000964  0.000000  0.000000\n",
      "element     0.000000  0.000964  0.000000  0.000000\n",
      "sabbath     0.000000  0.000964  0.000000  0.000000\n",
      "phase       0.000000  0.000964  0.000000  0.000000\n",
      "originally  0.000000  0.000964  0.000000  0.000000\n",
      "nature      0.000000  0.000964  0.000000  0.000000\n",
      "egyptian    0.000000  0.000964  0.000000  0.000000\n",
      "be          0.000167  0.000226  0.000178  0.000205\n",
      "determine   0.000000  0.000321  0.000341  0.000000\n",
      "and         0.000133  0.000177  0.000166  0.000177\n",
      "in          0.000135  0.000128  0.000161  0.000143\n",
      "that        0.000151  0.000127  0.000122  0.000127\n",
      "early       0.000150  0.000092  0.000000  0.000077\n",
      "by          0.000071  0.000058  0.000078  0.000073\n",
      "heard       0.000028  0.000091  0.000024  0.000098\n",
      "stuff       0.000035  0.000042  0.000019  0.000016\n",
      "i have heard that the sabbath be originally determine by the phase of the moon and have element of moon worship early stuff egyptian in nature\n",
      "==> predicted_topic = space, actual_topic = religion \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "file       0.000000  0.000000  0.005253  0.001311\n",
      "every      0.000000  0.000000  0.000452  0.001601\n",
      "feel       0.000000  0.000000  0.000000  0.002018\n",
      "be         0.000375  0.000508  0.000401  0.000461\n",
      "day        0.000000  0.000692  0.000000  0.001016\n",
      "could      0.000264  0.000000  0.000293  0.000662\n",
      "wonder     0.000000  0.000000  0.000714  0.000434\n",
      "monthly    0.000000  0.000000  0.000000  0.001083\n",
      "quarterly  0.000000  0.000000  0.000000  0.001083\n",
      "bloat      0.000000  0.000000  0.000000  0.001083\n",
      "28         0.000000  0.000000  0.000000  0.001083\n",
      "post       0.000401  0.000129  0.000000  0.000323\n",
      "the        0.000204  0.000209  0.000189  0.000241\n",
      "rather     0.000000  0.000128  0.000169  0.000380\n",
      "get        0.000128  0.000051  0.000223  0.000218\n",
      "this       0.000106  0.000134  0.000122  0.000157\n",
      "if         0.000101  0.000102  0.000160  0.000117\n",
      "30         0.000161  0.000000  0.000142  0.000094\n",
      "than       0.000041  0.000120  0.000050  0.000094\n",
      "faq        0.000000  0.000067  0.000080  0.000103\n",
      "i be wonder if the faq file could be post quarterly rather than monthly every 28 30 day i get this bloat feel\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "thanks     0.000397  0.000056  0.001375  0.000355\n",
      "be         0.000372  0.000504  0.000397  0.000457\n",
      "explain    0.000000  0.000358  0.000000  0.001189\n",
      "could      0.000262  0.000000  0.000290  0.000657\n",
      "activity   0.000000  0.000000  0.000000  0.001074\n",
      "loss       0.000000  0.000000  0.000000  0.001074\n",
      "alan       0.000000  0.000000  0.000000  0.001074\n",
      "ron        0.000000  0.000000  0.000000  0.001074\n",
      "regularly  0.000000  0.000000  0.000000  0.001074\n",
      "timer      0.000000  0.000000  0.000000  0.001074\n",
      "post       0.000397  0.000128  0.000000  0.000320\n",
      "the        0.000202  0.000207  0.000188  0.000239\n",
      "command    0.000000  0.000000  0.000315  0.000459\n",
      "report     0.000000  0.000000  0.000441  0.000321\n",
      "someone    0.000083  0.000319  0.000000  0.000306\n",
      "in         0.000150  0.000143  0.000179  0.000159\n",
      "this       0.000105  0.000133  0.000121  0.000155\n",
      "what       0.000085  0.000068  0.000085  0.000078\n",
      "interest   0.000000  0.000072  0.000079  0.000081\n",
      "this activity be regularly report in ron s interest post could someone explain what the command loss timer be thanks alan\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "image       0.000000  0.000000  0.003353  0.000625\n",
      "of          0.000269  0.000561  0.000399  0.000411\n",
      "thanks      0.000266  0.000038  0.000921  0.000238\n",
      "stereo      0.000000  0.000000  0.000000  0.001439\n",
      "planetary   0.000000  0.000000  0.000000  0.001439\n",
      "phobos      0.000000  0.000000  0.000000  0.001340\n",
      "satellite   0.000000  0.000000  0.000000  0.001340\n",
      "mar         0.000000  0.000000  0.000000  0.001340\n",
      "tell        0.000000  0.000000  0.000306  0.001020\n",
      "anyone      0.000262  0.000000  0.000733  0.000307\n",
      "might       0.000000  0.000000  0.000321  0.000896\n",
      "the         0.000271  0.000277  0.000252  0.000320\n",
      "surface     0.000000  0.000000  0.000495  0.000491\n",
      "and         0.000199  0.000265  0.000248  0.000265\n",
      "any         0.000187  0.000062  0.000542  0.000161\n",
      "moon        0.000000  0.000411  0.000000  0.000494\n",
      "in          0.000201  0.000191  0.000240  0.000213\n",
      "deimos      0.000000  0.000000  0.000000  0.000720\n",
      "gifs        0.000000  0.000000  0.000506  0.000175\n",
      "where       0.000135  0.000000  0.000286  0.000234\n",
      "me          0.000094  0.000182  0.000294  0.000036\n",
      "especially  0.000387  0.000000  0.000000  0.000192\n",
      "but         0.000042  0.000169  0.000149  0.000096\n",
      "will        0.000063  0.000201  0.000027  0.000126\n",
      "do          0.000091  0.000088  0.000143  0.000079\n",
      "that        0.000113  0.000095  0.000091  0.000095\n",
      "prefer      0.000071  0.000000  0.000235  0.000080\n",
      "can         0.000066  0.000054  0.000123  0.000099\n",
      "order       0.000193  0.000077  0.000000  0.000066\n",
      "find        0.000079  0.000030  0.000090  0.000019\n",
      "interested  0.000020  0.000014  0.000021  0.000020\n",
      "can anyone tell me where i might find stereo image of planetary and planetary satellite surface gifs prefer but any will do i m especially interested in stereo of the surface of phobos deimos mar and the moon in that order thanks\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "            autos  religion  graphics     space\n",
      "42       0.000502  0.000000  0.001259  0.000000\n",
      "thought  0.000000  0.000000  0.000329  0.001421\n",
      "be       0.000363  0.000492  0.000388  0.000447\n",
      "the      0.000395  0.000404  0.000367  0.000466\n",
      "help     0.000000  0.000195  0.001159  0.000204\n",
      "chip     0.000000  0.000000  0.001302  0.000000\n",
      "really   0.000268  0.000739  0.000237  0.000000\n",
      "that     0.000329  0.000276  0.000265  0.000276\n",
      "on       0.000145  0.000152  0.000413  0.000366\n",
      "it       0.000265  0.000136  0.000365  0.000248\n",
      "could    0.000170  0.000000  0.000189  0.000428\n",
      "hear     0.000000  0.000303  0.000365  0.000097\n",
      "24       0.000000  0.000282  0.000454  0.000000\n",
      "pete     0.000000  0.000000  0.000699  0.000000\n",
      "intel    0.000000  0.000000  0.000699  0.000000\n",
      "reason   0.000000  0.000000  0.000699  0.000000\n",
      "proper   0.000000  0.000000  0.000699  0.000000\n",
      "egg      0.000000  0.000000  0.000699  0.000000\n",
      "stomp    0.000000  0.000000  0.000699  0.000000\n",
      "endian   0.000000  0.000000  0.000699  0.000000\n",
      "war      0.000000  0.000471  0.000173  0.000000\n",
      "value    0.000000  0.000469  0.000173  0.000000\n",
      "break    0.000000  0.000000  0.000220  0.000265\n",
      "side     0.000262  0.000000  0.000222  0.000000\n",
      "you      0.000164  0.000123  0.000107  0.000073\n",
      "but      0.000040  0.000164  0.000145  0.000094\n",
      "get      0.000082  0.000033  0.000144  0.000140\n",
      "write    0.000000  0.000066  0.000196  0.000099\n",
      "some     0.000027  0.000045  0.000169  0.000119\n",
      "their    0.000187  0.000101  0.000028  0.000032\n",
      "so       0.000074  0.000057  0.000052  0.000030\n",
      "out      0.000057  0.000053  0.000041  0.000025\n",
      "hear hear really i thought that the reason it be 42 be that it be really 24 but write a 42 so that on intel chip you could get the proper value pete help stomp out the endian war break some egg on their side\n",
      "==> predicted_topic = space, actual_topic = graphics \n",
      "\n",
      "             autos  religion  graphics     space\n",
      "see       0.000979  0.001563  0.000139  0.000000\n",
      "you       0.000655  0.000493  0.000427  0.000290\n",
      "need      0.000262  0.000000  0.000793  0.000403\n",
      "unless    0.001399  0.000000  0.000000  0.000000\n",
      "hmmmmmmm  0.001399  0.000000  0.000000  0.000000\n",
      "accident  0.001399  0.000000  0.000000  0.000000\n",
      "me        0.000184  0.000354  0.000572  0.000070\n",
      "won       0.000645  0.000395  0.000000  0.000000\n",
      "have      0.000298  0.000192  0.000193  0.000170\n",
      "let       0.000224  0.000309  0.000200  0.000000\n",
      "an        0.000264  0.000174  0.000181  0.000062\n",
      "more      0.000097  0.000104  0.000052  0.000061\n",
      "let me see unless you have an accident you won t need more hmmmmmmm\n",
      "==> predicted_topic = religion, actual_topic = autos \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "for         0.000740  0.000326  0.001915  0.000409\n",
      "motorcycle  0.001734  0.000000  0.000000  0.000000\n",
      "mandatory   0.001734  0.000000  0.000000  0.000000\n",
      "drl         0.001734  0.000000  0.000000  0.000000\n",
      "already     0.001038  0.000000  0.000446  0.000000\n",
      "be          0.000300  0.000407  0.000321  0.000369\n",
      "well        0.000068  0.000065  0.000040  0.000045\n",
      "well drl s be already mandatory for motorcycle\n",
      "==> predicted_topic = graphics, actual_topic = autos \n",
      "\n",
      "             autos  religion  graphics     space\n",
      "god       0.000000  0.003608  0.000000  0.000499\n",
      "profit    0.000000  0.000000  0.000000  0.001706\n",
      "the       0.000345  0.000353  0.000320  0.000407\n",
      "twilight  0.000000  0.000000  0.000000  0.000916\n",
      "blare     0.000000  0.000000  0.000000  0.000916\n",
      "bless     0.000000  0.000000  0.000000  0.000916\n",
      "cacs      0.000000  0.000000  0.000000  0.000916\n",
      "caste     0.000000  0.000000  0.000000  0.000916\n",
      "fraering  0.000000  0.000000  0.000000  0.000916\n",
      "freely    0.000000  0.000000  0.000000  0.000916\n",
      "usl       0.000000  0.000000  0.000000  0.000916\n",
      "pgf       0.000000  0.000000  0.000000  0.000916\n",
      "presence  0.000000  0.000000  0.000000  0.000916\n",
      "srl03     0.000000  0.000000  0.000000  0.000916\n",
      "edu       0.000099  0.000000  0.000348  0.000377\n",
      "be        0.000159  0.000215  0.000169  0.000195\n",
      "phil      0.000000  0.000257  0.000000  0.000430\n",
      "it        0.000174  0.000089  0.000239  0.000163\n",
      "and       0.000127  0.000169  0.000158  0.000169\n",
      "right     0.000276  0.000065  0.000032  0.000190\n",
      "in        0.000128  0.000122  0.000153  0.000136\n",
      "from      0.000060  0.000069  0.000096  0.000115\n",
      "even      0.000027  0.000153  0.000054  0.000087\n",
      "by        0.000067  0.000055  0.000074  0.000069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "may       0.000021  0.000090  0.000056  0.000031\n",
      "from phil g fraering pgf srl03 cacs usl edu right the profit caste be bless by god and may freely blare it presence in the even twilight\n",
      "==> predicted_topic = religion, actual_topic = space \n",
      "\n",
      "            autos  religion  graphics     space\n",
      "help     0.000000  0.000315  0.001873  0.000330\n",
      "the      0.000425  0.000436  0.000395  0.000502\n",
      "rest     0.000000  0.000886  0.000000  0.000424\n",
      "shirt    0.000000  0.001130  0.000000  0.000000\n",
      "night    0.000000  0.001130  0.000000  0.000000\n",
      "delete   0.000000  0.001130  0.000000  0.000000\n",
      "brown    0.000000  0.001130  0.000000  0.000000\n",
      "of       0.000141  0.000293  0.000209  0.000215\n",
      "out      0.000276  0.000259  0.000199  0.000120\n",
      "in       0.000158  0.000150  0.000188  0.000167\n",
      "can      0.000104  0.000085  0.000193  0.000155\n",
      "about    0.000169  0.000113  0.000081  0.000073\n",
      "anybody  0.000088  0.000057  0.000209  0.000041\n",
      "find     0.000124  0.000046  0.000141  0.000030\n",
      "rest delete can anybody out in a p h help out find out about the night of the brown shirt\n",
      "==> predicted_topic = graphics, actual_topic = religion \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "for         0.000710  0.000312  0.001838  0.000393\n",
      "new         0.001201  0.000000  0.000375  0.000582\n",
      "23          0.000685  0.000000  0.000000  0.001035\n",
      "thermostat  0.001664  0.000000  0.000000  0.000000\n",
      "sound       0.000415  0.000000  0.000242  0.000819\n",
      "you         0.000389  0.000293  0.000254  0.000173\n",
      "do          0.000211  0.000202  0.000331  0.000183\n",
      "that        0.000261  0.000219  0.000211  0.000219\n",
      "can         0.000153  0.000125  0.000284  0.000228\n",
      "say         0.000156  0.000370  0.000136  0.000080\n",
      "how         0.000102  0.000131  0.000086  0.000072\n",
      "again       0.000047  0.000044  0.000024  0.000033\n",
      "you can say that again how do 23 for a new thermostat sound\n",
      "==> predicted_topic = graphics, actual_topic = autos \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "he          0.000000  0.002411  0.000000  0.000602\n",
      "land        0.000000  0.000000  0.000000  0.001753\n",
      "mach        0.000000  0.000000  0.000000  0.001325\n",
      "flight      0.000000  0.000000  0.000000  0.001234\n",
      "head        0.000000  0.000000  0.000000  0.001234\n",
      "military    0.000000  0.000000  0.000000  0.001234\n",
      "of          0.000165  0.000344  0.000245  0.000252\n",
      "new         0.000478  0.000000  0.000149  0.000232\n",
      "could       0.000161  0.000000  0.000179  0.000405\n",
      "handle      0.000000  0.000000  0.000257  0.000474\n",
      "month       0.000000  0.000000  0.000260  0.000459\n",
      "belive      0.000000  0.000000  0.000000  0.000662\n",
      "boom        0.000000  0.000000  0.000000  0.000662\n",
      "decent      0.000000  0.000000  0.000000  0.000662\n",
      "direction   0.000000  0.000000  0.000000  0.000662\n",
      "fran        0.000000  0.000000  0.000000  0.000662\n",
      "aircraft    0.000000  0.000000  0.000000  0.000662\n",
      "25aircraft  0.000000  0.000000  0.000000  0.000662\n",
      "int         0.000000  0.000000  0.000000  0.000662\n",
      "25          0.000000  0.000000  0.000000  0.000662\n",
      "san         0.000000  0.000000  0.000000  0.000662\n",
      "odd         0.000000  0.000000  0.000000  0.000662\n",
      "supersonic  0.000000  0.000000  0.000000  0.000662\n",
      "super       0.000000  0.000000  0.000436  0.000165\n",
      "be          0.000115  0.000155  0.000123  0.000141\n",
      "the         0.000125  0.000128  0.000116  0.000147\n",
      "on          0.000069  0.000072  0.000196  0.000173\n",
      "ago         0.000053  0.000071  0.000048  0.000323\n",
      "it          0.000126  0.000064  0.000173  0.000118\n",
      "question    0.000086  0.000294  0.000043  0.000035\n",
      "east        0.000000  0.000222  0.000000  0.000232\n",
      "what        0.000105  0.000084  0.000104  0.000096\n",
      "hear        0.000000  0.000144  0.000173  0.000046\n",
      "that        0.000104  0.000087  0.000084  0.000087\n",
      "there       0.000113  0.000040  0.000062  0.000139\n",
      "some        0.000026  0.000043  0.000160  0.000113\n",
      "speed       0.000118  0.000000  0.000069  0.000051\n",
      "heard       0.000019  0.000062  0.000017  0.000067\n",
      "base        0.000015  0.000048  0.000024  0.000065\n",
      "over        0.000061  0.000018  0.000021  0.000019\n",
      "few         0.000024  0.000015  0.000029  0.000050\n",
      "the supersonic boom hear a few month ago over i belive san fran head east of what i heard some new super speed mach 25 aircraft what military base int he direction of flight be there that could handle a mach 25aircraft on it land decent odd question\n",
      "==> predicted_topic = religion, actual_topic = space \n",
      "\n",
      "                  autos  religion  graphics     space\n",
      "try            0.000000  0.000329  0.004991  0.001203\n",
      "he             0.000000  0.002812  0.000000  0.000703\n",
      "thought        0.000000  0.000000  0.000363  0.001570\n",
      "be             0.000268  0.000362  0.000286  0.000329\n",
      "to             0.000226  0.000336  0.000252  0.000285\n",
      "win            0.000000  0.000000  0.000000  0.000773\n",
      "consideration  0.000000  0.000000  0.000000  0.000773\n",
      "sam            0.000000  0.000000  0.000000  0.000773\n",
      "ross           0.000000  0.000000  0.000000  0.000773\n",
      "perot          0.000000  0.000000  0.000000  0.000773\n",
      "disappoint     0.000000  0.000000  0.000000  0.000773\n",
      "further        0.000000  0.000000  0.000000  0.000773\n",
      "matt           0.000000  0.000000  0.000000  0.000773\n",
      "likely         0.000000  0.000000  0.000000  0.000773\n",
      "walton         0.000000  0.000000  0.000000  0.000773\n",
      "gate           0.000000  0.000000  0.000000  0.000773\n",
      "after          0.000414  0.000091  0.000000  0.000187\n",
      "it             0.000147  0.000075  0.000202  0.000137\n",
      "bill           0.000000  0.000301  0.000000  0.000239\n",
      "third          0.000282  0.000000  0.000000  0.000250\n",
      "kid            0.000000  0.000256  0.000000  0.000274\n",
      "but            0.000045  0.000182  0.000160  0.000103\n",
      "my             0.000224  0.000105  0.000045  0.000086\n",
      "in             0.000108  0.000103  0.000129  0.000114\n",
      "first          0.000076  0.000175  0.000041  0.000029\n",
      "think          0.000107  0.000054  0.000065  0.000018\n",
      "more           0.000054  0.000057  0.000029  0.000034\n",
      "come           0.000024  0.000019  0.000050  0.000060\n",
      "my first thought be ross perot after further consideration i think he d be more likely to try to win it but come in a disappoint third try bill gate try sam walton s kid matt\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "         autos  religion  graphics     space\n",
      "to    0.000505  0.000751  0.000563  0.000636\n",
      "know  0.000402  0.000322  0.000555  0.000171\n",
      "just  0.000370  0.000188  0.000218  0.000366\n",
      "want  0.000256  0.000173  0.000163  0.000111\n",
      "i just want to know\n",
      "==> predicted_topic = religion, actual_topic = autos \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "it         0.000610  0.000313  0.000839  0.000571\n",
      "be         0.000278  0.000377  0.000297  0.000342\n",
      "gee        0.000272  0.000000  0.000000  0.000856\n",
      "look       0.000277  0.000024  0.000574  0.000237\n",
      "you        0.000376  0.000283  0.000245  0.000167\n",
      "any        0.000209  0.000069  0.000605  0.000180\n",
      "release    0.000469  0.000000  0.000342  0.000000\n",
      "tion       0.000804  0.000000  0.000000  0.000000\n",
      "radia      0.000804  0.000000  0.000000  0.000000\n",
      "confuse    0.000804  0.000000  0.000000  0.000000\n",
      "genus      0.000804  0.000000  0.000000  0.000000\n",
      "hole       0.000804  0.000000  0.000000  0.000000\n",
      "locate     0.000804  0.000000  0.000000  0.000000\n",
      "tor        0.000804  0.000000  0.000000  0.000000\n",
      "radiation  0.000804  0.000000  0.000000  0.000000\n",
      "radiator   0.000804  0.000000  0.000000  0.000000\n",
      "punch      0.000804  0.000000  0.000000  0.000000\n",
      "where      0.000150  0.000000  0.000319  0.000262\n",
      "really     0.000154  0.000425  0.000136  0.000000\n",
      "sound      0.000200  0.000000  0.000117  0.000396\n",
      "me         0.000106  0.000204  0.000328  0.000040\n",
      "like       0.000197  0.000106  0.000114  0.000235\n",
      "what       0.000128  0.000102  0.000127  0.000117\n",
      "will       0.000070  0.000225  0.000030  0.000140\n",
      "do         0.000102  0.000098  0.000160  0.000088\n",
      "when       0.000041  0.000172  0.000039  0.000083\n",
      "since      0.000074  0.000065  0.000114  0.000000\n",
      "make       0.000051  0.000059  0.000031  0.000028\n",
      "gee you really make me confuse what be radiator where be it locate what do it look like will it release any radiation since it sound like radia tion genus tor when you punch hole\n",
      "==> predicted_topic = space, actual_topic = autos \n",
      "\n",
      "             autos  religion  graphics     space\n",
      "file      0.000000  0.000000  0.003935  0.000982\n",
      "yo        0.000000  0.000000  0.000000  0.003023\n",
      "assume    0.000000  0.000000  0.000000  0.002742\n",
      "be        0.000421  0.000571  0.000450  0.000518\n",
      "every     0.000000  0.000000  0.000339  0.001199\n",
      "string    0.000000  0.000000  0.000000  0.001512\n",
      "sig       0.000000  0.000000  0.000000  0.001512\n",
      "mining    0.000000  0.000000  0.000000  0.001512\n",
      "you       0.000380  0.000286  0.000248  0.000168\n",
      "cash      0.000000  0.000000  0.000000  0.000812\n",
      "limit     0.000000  0.000000  0.000000  0.000812\n",
      "award     0.000000  0.000000  0.000000  0.000812\n",
      "to        0.000119  0.000177  0.000132  0.000149\n",
      "away      0.000306  0.000000  0.000000  0.000257\n",
      "own       0.000000  0.000261  0.000000  0.000299\n",
      "ok        0.000335  0.000100  0.000000  0.000083\n",
      "right     0.000245  0.000058  0.000028  0.000169\n",
      "get       0.000096  0.000038  0.000167  0.000163\n",
      "there     0.000138  0.000049  0.000076  0.000170\n",
      "can       0.000075  0.000061  0.000138  0.000111\n",
      "them      0.000018  0.000142  0.000078  0.000142\n",
      "would     0.000121  0.000045  0.000072  0.000125\n",
      "one       0.000088  0.000071  0.000041  0.000144\n",
      "like      0.000099  0.000053  0.000058  0.000119\n",
      "because   0.000066  0.000122  0.000000  0.000130\n",
      "don       0.000044  0.000086  0.000057  0.000043\n",
      "anything  0.000030  0.000019  0.000036  0.000088\n",
      "give      0.000056  0.000046  0.000044  0.000014\n",
      "time      0.000023  0.000025  0.000046  0.000045\n",
      "mine      0.000022  0.000020  0.000024  0.000054\n",
      "nice      0.000013  0.000011  0.000013  0.000013\n",
      "a cash award be ok a time limit would be nice you can t give away mining right assume there s anything to mine because you don t own them sig file be like string every yo yo s get one\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "           autos  religion  graphics     space\n",
      "get     0.000358  0.000143  0.000625  0.000611\n",
      "life    0.000587  0.000170  0.000000  0.000775\n",
      "people  0.000346  0.000350  0.000062  0.000173\n",
      "people get a life\n",
      "==> predicted_topic = space, actual_topic = autos \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "image       0.000000  0.000000  0.004100  0.000764\n",
      "site        0.000000  0.000000  0.001891  0.000881\n",
      "ftp         0.000000  0.000000  0.001515  0.000650\n",
      "the         0.000497  0.000509  0.000461  0.000587\n",
      "thanks      0.000325  0.000046  0.001126  0.000291\n",
      "phobos      0.000000  0.000000  0.000000  0.001639\n",
      "spacecraft  0.000000  0.000000  0.000000  0.001639\n",
      "russian     0.000000  0.000000  0.000000  0.001639\n",
      "house       0.000000  0.000000  0.000000  0.001639\n",
      "anyone      0.000321  0.000000  0.000897  0.000375\n",
      "any         0.000229  0.000076  0.000663  0.000197\n",
      "moon        0.000000  0.000502  0.000000  0.000605\n",
      "do          0.000223  0.000214  0.000350  0.000194\n",
      "fat         0.000000  0.000000  0.000000  0.000880\n",
      "ill         0.000000  0.000000  0.000000  0.000880\n",
      "martian     0.000000  0.000000  0.000000  0.000880\n",
      "mission     0.000000  0.000000  0.000000  0.000880\n",
      "if          0.000164  0.000165  0.000260  0.000191\n",
      "on          0.000091  0.000096  0.000260  0.000230\n",
      "of          0.000110  0.000228  0.000163  0.000167\n",
      "ago         0.000070  0.000094  0.000064  0.000429\n",
      "back        0.000245  0.000093  0.000000  0.000139\n",
      "an          0.000166  0.000110  0.000114  0.000039\n",
      "they        0.000139  0.000066  0.000048  0.000130\n",
      "send        0.000176  0.000000  0.000076  0.000120\n",
      "know        0.000102  0.000082  0.000141  0.000044\n",
      "year        0.000058  0.000032  0.000054  0.000144\n",
      "so          0.000093  0.000071  0.000066  0.000038\n",
      "re          0.000049  0.000092  0.000018  0.000102\n",
      "at          0.000047  0.000048  0.000077  0.000062\n",
      "few         0.000031  0.000021  0.000039  0.000066\n",
      "do the russian spacecraft s on the ill fat phobos mission a few year ago send back any image of the martian moon if so do anyone know if they re house at an ftp site thanks\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training = True\n",
    "tlabels = train_labels if training else test_labels\n",
    "tdoc_vectors = train_doc_vectors if training else test_doc_vectors\n",
    "misclassified = misclassified_train if training else misclassified_test\n",
    "\n",
    "for doc_index in tqdm(misclassified):\n",
    "    doc_vector = tdoc_vectors[doc_index]\n",
    "    doc_topic_word_distr, doc_topic = infer_topic(label_classes, doc_vector, topic_word_distr)\n",
    "    \n",
    "    xv = doc_topic_word_distr.iloc[np.where(doc_topic_word_distr.sum(1) > 0)]\n",
    "    print(xv.loc[xv.sum(1).sort_values(ascending=False).index])\n",
    "    print(train_docs[doc_index])\n",
    "    print(f\"==> predicted_topic = {doc_topic}, actual_topic = {label_classes[tlabels[doc_index]]} \\n\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuarcy = 100.00%, test_accuarcy = 62.88%, avg-accuarcy = 81.44%\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=.01)\n",
    "clf.fit(train_doc_vectors, train_labels)\n",
    "\n",
    "train_accuracy = clf.score(train_doc_vectors, train_labels)\n",
    "test_accuracy = clf.score(test_doc_vectors, test_labels)\n",
    "\n",
    "print(f\"training_accuarcy = {train_accuracy*100:.2f}%, test_accuarcy = {test_accuracy*100:.2f}%, avg-accuarcy = {.5*(train_accuracy + test_accuracy)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

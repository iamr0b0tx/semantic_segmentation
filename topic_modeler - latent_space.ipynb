{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "from utils import *\n",
    "from word_network import WordNetwork\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.special import softmax\n",
    "from scipy.stats import entropy as calculate_entropy\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of samples needed\n",
    "randomize = False\n",
    "\n",
    "# retrieve dataset\n",
    "categories = ['rec.autos', 'talk.politics.mideast', 'alt.atheism', 'sci.space']\n",
    "\n",
    "docs = fetch_20newsgroups(subset='train', shuffle=randomize, remove=('headers', 'footers', 'quotes'), categories=categories)\n",
    "docs, old_labels, classes = docs.data, docs.target, docs.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5317633e81214e5ab8af17b2fef04d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "datasize = 100\n",
    "max_document_length = None\n",
    "\n",
    "index = -1\n",
    "train_docs, labels = [], []\n",
    "\n",
    "sizes = [0]*len(categories)\n",
    "\n",
    "with tqdm(total=len(categories)*datasize) as pbar:\n",
    "    while sum(sizes) != len(categories)*datasize:\n",
    "        index += 1\n",
    "        size_index = categories.index(classes[old_labels[index]])\n",
    "        \n",
    "        if sizes[size_index] == datasize:\n",
    "            continue\n",
    "        \n",
    "        doc = docs[index]\n",
    "        status, doc, word_count = clean_doc(doc, True)\n",
    "        \n",
    "        if (not status) or (max_document_length is not None and len(doc) > max_document_length):\n",
    "            continue\n",
    "        \n",
    "        labels.append(categories[size_index])\n",
    "        train_docs.append(doc)\n",
    "        sizes[size_index] += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: alt.atheism\n",
      "==================================================\n",
      "i think that domestication will change behavior to a large degree domesticate animal exhibit behavior not found in the wild i don t think that they can be view a good representative of the wild animal kingdom since they have be breed for thousand of year to produce certain behavior etc\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "print(f\"Topic: {labels[index]}\\n{'='*50}\\n{train_docs[index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 100, 100, 100]\n"
     ]
    }
   ],
   "source": [
    "print(sizes)\n",
    "assert min(sizes) == max(sizes) == datasize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 400 docs\n"
     ]
    }
   ],
   "source": [
    "print(f\"there are {len(train_docs)} docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_count is 9116\n"
     ]
    }
   ],
   "source": [
    "# initialize the count vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# fit it to dataset\n",
    "vectorizer.fit(train_docs)\n",
    "\n",
    "vocabulary = vectorizer.get_feature_names()\n",
    "print(\"word_count is\", len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Datatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 train_docs\n"
     ]
    }
   ],
   "source": [
    "# create doc count vectors\n",
    "train_doc_vectors = vectorizer.transform(train_docs).toarray()\n",
    "\n",
    "total_num_of_documents = len(train_doc_vectors)\n",
    "print(f\"{total_num_of_documents} train_docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word-Word Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d57fa6988a045418aadad9925cccea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9116.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\pandas\\core\\series.py:679: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\christian\\Documents\\christian\\work\\python\\cyberspace\\semantic_segmentation\\utils.py:15: RuntimeWarning: overflow encountered in power\n",
      "  return 1 / (1 + (np.e**-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "word_word_co has shape (9116, 9116)\n"
     ]
    }
   ],
   "source": [
    "# reduce freq in doc to bin value of 1 or 0\n",
    "word_freq_in_doc = pd.DataFrame(train_doc_vectors, columns=vocabulary)\n",
    "word_word_co = pd.DataFrame(data=0.0, columns=vocabulary, index=vocabulary)\n",
    "\n",
    "word_doc_frequency = (word_freq_in_doc > 0).astype(int)\n",
    "probability = word_doc_frequency.sum(0) / len(train_doc_vectors)\n",
    "\n",
    "for word in tqdm(vocabulary):\n",
    "    pxy = word_doc_frequency[word_doc_frequency[word] == 1].sum(0) / total_num_of_documents\n",
    "#     word_word_co[word] = pxy / (probability[word] * probability)\n",
    "#     word_word_co[word][word_word_co[word] > 0] = word_word_co[word][word_word_co[word] > 0]**-1\n",
    "    word_word_co[word] = np.nan_to_num(sigmoid(np.nan_to_num(np.log2(pxy / (probability[word] * probability)))))\n",
    "\n",
    "# word_word_co = (word_word_co.T / word_word_co.sum(1)).T\n",
    "print(f\"word_word_co has shape {word_word_co.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>000th</th>\n",
       "      <th>0029</th>\n",
       "      <th>007</th>\n",
       "      <th>01</th>\n",
       "      <th>011</th>\n",
       "      <th>0119</th>\n",
       "      <th>013</th>\n",
       "      <th>02</th>\n",
       "      <th>0245</th>\n",
       "      <th>...</th>\n",
       "      <th>zillion</th>\n",
       "      <th>zimogliad</th>\n",
       "      <th>ziona</th>\n",
       "      <th>zionism</th>\n",
       "      <th>zionist</th>\n",
       "      <th>zman</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>0.990471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.990471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.886843</td>\n",
       "      <td>0.990471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000th</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0029</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>007</th>\n",
       "      <td>0.990471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999141</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            000     000th      0029       007        01  011  0119  013   02  \\\n",
       "000    0.990471  0.000000  0.000000  0.990471  0.000000  0.0   0.0  0.0  0.0   \n",
       "000th  0.000000  0.999824  0.000000  0.000000  0.000000  0.0   0.0  0.0  0.0   \n",
       "0029   0.000000  0.000000  0.999824  0.000000  0.999141  0.0   0.0  0.0  0.0   \n",
       "007    0.990471  0.000000  0.000000  0.999824  0.000000  0.0   0.0  0.0  0.0   \n",
       "01     0.000000  0.000000  0.999141  0.000000  0.999141  0.0   0.0  0.0  0.0   \n",
       "\n",
       "           0245  ...  zillion  zimogliad  ziona  zionism   zionist      zman  \\\n",
       "000    0.000000  ...      0.0   0.990471    0.0      0.0  0.886843  0.990471   \n",
       "000th  0.000000  ...      0.0   0.000000    0.0      0.0  0.000000  0.000000   \n",
       "0029   0.000000  ...      0.0   0.000000    0.0      0.0  0.000000  0.000000   \n",
       "007    0.000000  ...      0.0   0.999824    0.0      0.0  0.000000  0.000000   \n",
       "01     0.999141  ...      0.0   0.000000    0.0      0.0  0.000000  0.000000   \n",
       "\n",
       "       zone  zoo  zulu  zur  \n",
       "000     0.0  0.0   0.0  0.0  \n",
       "000th   0.0  0.0   0.0  0.0  \n",
       "0029    0.0  0.0   0.0  0.0  \n",
       "007     0.0  0.0   0.0  0.0  \n",
       "01      0.0  0.0   0.0  0.0  \n",
       "\n",
       "[5 rows x 9116 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_word_co.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Word Trust ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_entropy = pd.DataFrame(data=np.nan_to_num(calculate_entropy(word_word_co.T, base=2)), columns=[0], index=vocabulary)[0]\n",
    "word_trust_factor = pd.DataFrame(data=gaussian(abs(word_entropy - word_entropy.mean())), columns=[0], index=vocabulary)[0]\n",
    "\n",
    "word_trust_factor = word_trust_factor / word_trust_factor.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = [\"to\", \"the\", \"algorithm\", \"program\", \"and\"]\n",
    "# words = np.array(vocabulary)[np.random.randint(len(vocabulary), size=5)]\n",
    "\n",
    "fig = plt.figure(figsize=(15,3))\n",
    "ax1 = fig.add_subplot(131)\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax3 = fig.add_subplot(133)\n",
    "\n",
    "ax1.set_title(f\"Word Trust factor\")\n",
    "ax1.bar(words, word_trust_factor[words])\n",
    "\n",
    "ax2.set_title(f\"Entropy\")\n",
    "ax2.bar(words, word_entropy[words])\n",
    "\n",
    "ax3.set_title(f\"Word Frequency Normalized\")\n",
    "ax3.bar(words, probability[words])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe word_word_co ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "wwc = (word_word_co * word_trust_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Ploting software against ['to', 'the', 'algorithm', 'program', 'and'] ===\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "word = \"software\"\n",
    "\n",
    "fig = plt.figure(figsize=(10,3))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "print(f\"=== Ploting {word} against {words} ===\")\n",
    "\n",
    "ax1.set_title(f\"word_word_co\")\n",
    "ax1.bar(words, word_word_co.loc[word][words])\n",
    "\n",
    "ax2.set_title(f\"updated word_word_co\")\n",
    "ax2.bar(words, wwc.loc[word][words])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "racial         0.985954\n",
       "ii             0.977344\n",
       "prior          0.973940\n",
       "possession     0.973940\n",
       "supporter      0.972309\n",
       "fighter        0.969148\n",
       "ownership      0.967894\n",
       "espionage      0.965894\n",
       "revisionist    0.962728\n",
       "sdpa           0.962692\n",
       "Name: war, dtype: float64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wwc.loc[\"war\"].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zur                  0.985958\n",
       "interestingly        0.985958\n",
       "inhumane             0.985958\n",
       "ingredient           0.985958\n",
       "chancy               0.985958\n",
       "sergey               0.985958\n",
       "turbocharger         0.985958\n",
       "ineffective          0.985958\n",
       "indoors              0.985958\n",
       "indistinguishable    0.985958\n",
       "Name: war, dtype: float64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_word_co.loc[\"war\"].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_word_co = wwc\n",
    "del wwc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update word_word_co with word_word_co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequency_norm = ((word_doc_freqency > 0).sum(0) / len(train_doc_vectors))\n",
    "doc_word_distr = word_frequency_norm * (np.e**word_trust_factor)\n",
    "doc_word_distr = (doc_word_distr.T / doc_word_distr.sum(1)).T.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "directly     1.0\n",
       "of           1.0\n",
       "didn         1.0\n",
       "10           1.0\n",
       "maybe        1.0\n",
       "his          1.0\n",
       "missile      1.0\n",
       "get          1.0\n",
       "kill         1.0\n",
       "operation    1.0\n",
       "Name: 13, dtype: float64"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_index = 13\n",
    "word_doc_freqency.iloc[doc_index].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "desintegrated    0.038808\n",
       "surgical         0.038461\n",
       "directly         0.038448\n",
       "missile          0.038448\n",
       "operation        0.038447\n",
       "body             0.038447\n",
       "hit              0.038447\n",
       "destroy          0.038447\n",
       "someone          0.038447\n",
       "house            0.038447\n",
       "Name: 13, dtype: float64"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_word_distr.iloc[doc_index].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "talk.politics.mideast maybe the missile didn t hit directly such that his body get desintegrated of course destroy 10 house to kill someone be not a surgical operation or be it\n"
     ]
    }
   ],
   "source": [
    "print(labels[doc_index], train_docs[doc_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>000th</th>\n",
       "      <th>0029</th>\n",
       "      <th>007</th>\n",
       "      <th>01</th>\n",
       "      <th>011</th>\n",
       "      <th>0119</th>\n",
       "      <th>013</th>\n",
       "      <th>02</th>\n",
       "      <th>0245</th>\n",
       "      <th>...</th>\n",
       "      <th>zillion</th>\n",
       "      <th>zimogliad</th>\n",
       "      <th>ziona</th>\n",
       "      <th>zionism</th>\n",
       "      <th>zionist</th>\n",
       "      <th>zman</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  000th  0029  007   01  011  0119  013   02  0245  ...  zillion  \\\n",
       "0  0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  ...      0.0   \n",
       "1  0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  ...      0.0   \n",
       "2  0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  ...      0.0   \n",
       "3  0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  ...      0.0   \n",
       "4  0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  ...      0.0   \n",
       "\n",
       "   zimogliad  ziona  zionism  zionist  zman  zone  zoo  zulu  zur  \n",
       "0        0.0    0.0      0.0      0.0   0.0   0.0  0.0   0.0  0.0  \n",
       "1        0.0    0.0      0.0      0.0   0.0   0.0  0.0   0.0  0.0  \n",
       "2        0.0    0.0      0.0      0.0   0.0   0.0  0.0   0.0  0.0  \n",
       "3        0.0    0.0      0.0      0.0   0.0   0.0  0.0   0.0  0.0  \n",
       "4        0.0    0.0      0.0      0.0   0.0   0.0  0.0   0.0  0.0  \n",
       "\n",
       "[5 rows x 9116 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_word_distr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['breed', 'domesticate', 'domestication', 'wild', 'exhibit']\n"
     ]
    }
   ],
   "source": [
    "for di in range(len(doc_word_distr.index)):\n",
    "    print(doc_word_distr.iloc[di].sort_values(ascending=False).head(5).index.to_list())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ironic             0.000545\n",
       "humanist           0.000197\n",
       "birthday           0.000181\n",
       "45th               0.000181\n",
       "drl                0.000023\n",
       "nonononnononono    0.000010\n",
       "nile               0.000010\n",
       "incredibly         0.000008\n",
       "huh                0.000008\n",
       "photosynthetic     0.000007\n",
       "dtype: float64"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(doc_word_distr.mean(0) * word_trust_factor).sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Latent partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distr_params has shape (400, 4)\n"
     ]
    }
   ],
   "source": [
    "# reduction = None\n",
    "reduction = \"pca\"\n",
    "# reduction = \"normal\"\n",
    "\n",
    "if reduction is None:\n",
    "    columns = doc_word_distr.columns\n",
    "    param_values = doc_word_distr.values\n",
    "\n",
    "if reduction == \"pca\":\n",
    "    num_of_components = 4\n",
    "    columns = list(range(num_of_components))\n",
    "    \n",
    "    pca = PCA(n_components=num_of_components)\n",
    "    param_values = pca.fit_transform(doc_word_distr)\n",
    "\n",
    "if reduction == \"normal\":\n",
    "    columns = [\"mean\", \"std\"]\n",
    "    param_values = np.array([doc_word_distr.mean(1), doc_word_distr.std(1)]).T\n",
    "    \n",
    "distr_params = pd.DataFrame(data=param_values, columns=columns, index=list(range(len(doc_word_distr))))\n",
    "print(f\"distr_params has shape {distr_params.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.004163</td>\n",
       "      <td>-0.007101</td>\n",
       "      <td>-0.006560</td>\n",
       "      <td>-0.014602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.003256</td>\n",
       "      <td>-0.005113</td>\n",
       "      <td>-0.003928</td>\n",
       "      <td>0.002366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.003288</td>\n",
       "      <td>-0.004822</td>\n",
       "      <td>-0.004353</td>\n",
       "      <td>-0.010058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.001184</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.003075</td>\n",
       "      <td>0.003528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.002784</td>\n",
       "      <td>-0.003852</td>\n",
       "      <td>-0.002882</td>\n",
       "      <td>0.002375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "0 -0.004163 -0.007101 -0.006560 -0.014602\n",
       "1 -0.003256 -0.005113 -0.003928  0.002366\n",
       "2 -0.003288 -0.004822 -0.004353 -0.010058\n",
       "3 -0.001184  0.001934  0.003075  0.003528\n",
       "4 -0.002784 -0.003852 -0.002882  0.002375"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distr_params.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Kmeans MiniBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a902a23de484566a9bea779530b837d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=256.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num_of_topics = 4\n",
    "# kmeans_model = MiniBatchKMeans(n_clusters=num_of_topics, random_state=0)\n",
    "\n",
    "# num_of_iterations = 256\n",
    "\n",
    "# num_of_samples = len(distr_params)\n",
    "# batch_size = num_of_samples // 2\n",
    "\n",
    "# for i in tqdm(range(num_of_iterations)):\n",
    "#     indices = np.random.randint(num_of_samples, size=batch_size)\n",
    "    \n",
    "#     kmeans_model.partial_fit(distr_params.iloc[indices])\n",
    "\n",
    "# kmeans_model.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_model = KMeans(n_clusters=num_of_topics, random_state=0).fit(distr_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist has shape (400, 4), predicted_labels has shape (400,)\n"
     ]
    }
   ],
   "source": [
    "dist = kmeans_model.transform(distr_params)\n",
    "predicted_labels = kmeans_model.predict(distr_params)\n",
    "\n",
    "# wtf = normalize(dist, norm=\"l1\", axis=1)\n",
    "# wtf = normalize(wtf, norm=\"l1\", axis=0)\n",
    "\n",
    "wtf = gaussian(dist / dist.max(0))\n",
    "\n",
    "print(f\"dist has shape {dist.shape}, predicted_labels has shape {predicted_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99928197, 0.81438448, 0.99993749, 0.80319777],\n",
       "       [0.99980747, 0.81610347, 0.99989714, 0.81445361],\n",
       "       [0.99954305, 0.81598989, 0.99999414, 0.80625491],\n",
       "       ...,\n",
       "       [0.9999297 , 0.81812275, 0.99983119, 0.81467086],\n",
       "       [0.99923891, 0.8136871 , 0.99992277, 0.80278813],\n",
       "       [0.99986256, 0.81784861, 0.99990108, 0.81408237]])"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 225, 0: 172, 3: 1, 1: 2})"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "voc_array = np.array(vocabulary)\n",
    "\n",
    "def get_top2(topic):\n",
    "    indices = dist[:, topic].argsort()\n",
    "    print(labels[indices[:10]])\n",
    "\n",
    "def get_top2(topic):\n",
    "    indices = np.where(predicted_labels == topic)[0]\n",
    "    print((doc_word_distr.T * wtf[:, topic]).T.iloc[indices].mean(0).sort_values(ascending=False).head(10))\n",
    "\n",
    "def get_top2(topic):\n",
    "    indices = np.where(predicted_labels == topic)[0]\n",
    "    print(((doc_word_distr.T * wtf[:, topic]).T.iloc[indices].sum(0) * word_trust_factor).sort_values(ascending=False).head(10))\n",
    "    \n",
    "def get_top(topic):\n",
    "    indices = np.where(predicted_labels == topic)[0]\n",
    "    count = Counter()\n",
    "    for index in indices:\n",
    "        count[labels[index]] += wtf[index, topic]\n",
    "        \n",
    "    print(Counter(labels[indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be      0.002779\n",
      "the     0.002487\n",
      "to      0.001867\n",
      "of      0.001824\n",
      "and     0.001515\n",
      "you     0.001502\n",
      "that    0.001450\n",
      "have    0.001280\n",
      "it      0.001274\n",
      "in      0.001218\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "get_top(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zur            0.0\n",
      "enjoy          0.0\n",
      "ensure         0.0\n",
      "enrage         0.0\n",
      "enough         0.0\n",
      "enormous       0.0\n",
      "ennumerated    0.0\n",
      "enlighten      0.0\n",
      "enhancement    0.0\n",
      "entail         0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "get_top(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offender         5.450304e-11\n",
      "cozy             5.450304e-11\n",
      "theodore         5.450304e-11\n",
      "kkkaldis         5.450304e-11\n",
      "doublespeak      5.450304e-11\n",
      "contradictory    5.432806e-11\n",
      "disgust          5.431219e-11\n",
      "harsh            5.430888e-11\n",
      "justification    5.430882e-11\n",
      "punishment       5.430876e-11\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "get_top(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deletion       1.209994e-08\n",
      "zur            0.000000e+00\n",
      "enlighten      0.000000e+00\n",
      "ensures        0.000000e+00\n",
      "ensure         0.000000e+00\n",
      "enrage         0.000000e+00\n",
      "enough         0.000000e+00\n",
      "enormous       0.000000e+00\n",
      "ennumerated    0.000000e+00\n",
      "enjoy          0.000000e+00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "get_top(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Topic model with Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54029e101f0241e6bd32fc3234049bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=268.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> train-accuracy is 90.67%, 25 misclassified\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "misclassified_train = []\n",
    "print(\"Evaluating Topic Model...\")\n",
    "\n",
    "for doc_index in tqdm(range(len(train_labels))):\n",
    "    doc_vector = train_doc_vectors[doc_index]\n",
    "    \n",
    "    doc_topic_word_distr, doc_topic = infer_topic(label_classes, doc_vector, topic_word_distr)\n",
    "    score += int(doc_topic == label_classes[train_labels[doc_index]])\n",
    "    \n",
    "    if doc_topic != label_classes[train_labels[doc_index]]:\n",
    "        misclassified_train.append(doc_index)\n",
    "    \n",
    "train_accuracy = score / (doc_index + 1)\n",
    "print(f\"==> train-accuracy is {train_accuracy*100:.2f}%, {len(misclassified_train)} misclassified\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Topic Model with test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c629d68d6d47ce9cd469637fff64ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=132.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> test-accuracy is 54.55%, avg-accuarcy = 72.61%, 60 misclassified\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "print(\"Evaluating Topic Model...\")\n",
    "\n",
    "misclassified_test = []\n",
    "for doc_index in tqdm(range(len(test_labels))):\n",
    "    doc_vector = test_doc_vectors[doc_index]\n",
    "    \n",
    "    doc_topic_word_distr, doc_topic = infer_topic(label_classes, doc_vector, topic_word_distr)\n",
    "    score += int(doc_topic == label_classes[test_labels[doc_index]])\n",
    "    \n",
    "    if doc_topic != label_classes[test_labels[doc_index]]:\n",
    "        misclassified_test.append(doc_index)\n",
    "    \n",
    "\n",
    "test_accuracy = score / (doc_index + 1)\n",
    "print(f\"==> test-accuracy is {test_accuracy*100:.2f}%, avg-accuarcy = {.5*(train_accuracy + test_accuracy)*100:.2f}%, {len(misclassified_test)} misclassified\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating Misclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac0825f5c8984e1caeb6d5393e151907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              autos  religion  graphics     space\n",
      "ve         0.000334  0.000191  0.001622  0.000000\n",
      "sense      0.000426  0.001182  0.000000  0.000000\n",
      "maybe      0.000000  0.000906  0.000605  0.000000\n",
      "shot       0.000000  0.000677  0.000000  0.000371\n",
      "that       0.000299  0.000251  0.000241  0.000251\n",
      "kind       0.000000  0.000394  0.000588  0.000000\n",
      "cheap      0.000000  0.000954  0.000000  0.000000\n",
      "embarrass  0.000000  0.000954  0.000000  0.000000\n",
      "fundies    0.000000  0.000954  0.000000  0.000000\n",
      "josh       0.000000  0.000954  0.000000  0.000000\n",
      "mood       0.000000  0.000954  0.000000  0.000000\n",
      "mcdowell   0.000000  0.000954  0.000000  0.000000\n",
      "be         0.000165  0.000224  0.000176  0.000203\n",
      "of         0.000119  0.000248  0.000176  0.000181\n",
      "to         0.000140  0.000208  0.000155  0.000176\n",
      "okay       0.000000  0.000375  0.000293  0.000000\n",
      "except     0.000307  0.000350  0.000000  0.000000\n",
      "who        0.000148  0.000316  0.000030  0.000111\n",
      "but        0.000055  0.000224  0.000197  0.000128\n",
      "have       0.000203  0.000131  0.000132  0.000116\n",
      "enough     0.000163  0.000133  0.000000  0.000267\n",
      "in         0.000133  0.000127  0.000159  0.000141\n",
      "know       0.000111  0.000089  0.000153  0.000047\n",
      "by         0.000070  0.000057  0.000077  0.000072\n",
      "few        0.000034  0.000022  0.000042  0.000071\n",
      "true       0.000036  0.000038  0.000019  0.000019\n",
      "true except that i ve know few fundies who have enough sense to be embarrass by josh mcdowell okay maybe a cheap shot but i m in that kind of mood\n",
      "==> predicted_topic = graphics, actual_topic = religion \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "he          0.000000  0.003337  0.000000  0.000834\n",
      "the         0.000517  0.000530  0.000481  0.000611\n",
      "it          0.000522  0.000267  0.000718  0.000488\n",
      "71          0.000000  0.000000  0.000000  0.001833\n",
      "until       0.000000  0.000000  0.000000  0.000917\n",
      "dubbed      0.000000  0.000000  0.000000  0.000917\n",
      "fwiw        0.000000  0.000000  0.000000  0.000917\n",
      "lbj         0.000000  0.000000  0.000000  0.000917\n",
      "mippselled  0.000000  0.000000  0.000000  0.000917\n",
      "page        0.000000  0.000000  0.000000  0.000917\n",
      "sic         0.000000  0.000000  0.000000  0.000917\n",
      "sr          0.000000  0.000000  0.000000  0.000917\n",
      "be          0.000159  0.000215  0.000170  0.000195\n",
      "doug        0.000000  0.000000  0.000438  0.000255\n",
      "who         0.000142  0.000304  0.000029  0.000107\n",
      "also        0.000165  0.000166  0.000000  0.000127\n",
      "one         0.000100  0.000080  0.000046  0.000163\n",
      "he s also the one who dubbed it the sr 71 it be the r 71 until lbj mippselled sic it fwiw doug page\n",
      "==> predicted_topic = religion, actual_topic = space \n",
      "\n",
      "            autos  religion  graphics     space\n",
      "file     0.000000  0.000000  0.005275  0.001317\n",
      "yo       0.000000  0.000000  0.000000  0.004052\n",
      "every    0.000000  0.000000  0.000454  0.001607\n",
      "string   0.000000  0.000000  0.000000  0.002026\n",
      "sig      0.000000  0.000000  0.000000  0.002026\n",
      "look     0.000375  0.000033  0.000778  0.000320\n",
      "publish  0.000000  0.000000  0.000000  0.001088\n",
      "plenty   0.000000  0.000000  0.000000  0.001088\n",
      "kiddo    0.000000  0.000000  0.000000  0.001088\n",
      "be       0.000188  0.000255  0.000201  0.000232\n",
      "to       0.000159  0.000237  0.000177  0.000200\n",
      "you      0.000255  0.000192  0.000166  0.000113\n",
      "have     0.000232  0.000150  0.000150  0.000132\n",
      "get      0.000128  0.000051  0.000223  0.000219\n",
      "one      0.000118  0.000095  0.000055  0.000193\n",
      "like     0.000133  0.000072  0.000077  0.000159\n",
      "just     0.000116  0.000059  0.000069  0.000115\n",
      "we       0.000031  0.000075  0.000074  0.000174\n",
      "we publish plenty kiddo you just have to look sig file be like string every yo yo s get one\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "human      0.000000  0.002433  0.000000  0.000381\n",
      "be         0.000572  0.000774  0.000611  0.000703\n",
      "45g        0.000000  0.000000  0.000000  0.001651\n",
      "sure       0.000000  0.000000  0.000505  0.000851\n",
      "lan        0.000000  0.000000  0.000000  0.000826\n",
      "8g         0.000000  0.000000  0.000000  0.000826\n",
      "9g         0.000000  0.000000  0.000000  0.000826\n",
      "blackout   0.000000  0.000000  0.000000  0.000826\n",
      "clarify    0.000000  0.000000  0.000000  0.000826\n",
      "dive       0.000000  0.000000  0.000000  0.000826\n",
      "pilot      0.000000  0.000000  0.000000  0.000826\n",
      "exceed     0.000000  0.000000  0.000000  0.000826\n",
      "the        0.000155  0.000159  0.000144  0.000183\n",
      "of         0.000103  0.000214  0.000153  0.000157\n",
      "to         0.000121  0.000180  0.000135  0.000152\n",
      "number     0.000048  0.000103  0.000372  0.000053\n",
      "tolerance  0.000000  0.000274  0.000000  0.000293\n",
      "far        0.000276  0.000000  0.000000  0.000290\n",
      "you        0.000193  0.000146  0.000126  0.000086\n",
      "right      0.000249  0.000059  0.000029  0.000172\n",
      "in         0.000115  0.000110  0.000138  0.000122\n",
      "please     0.000023  0.000193  0.000170  0.000090\n",
      "that       0.000130  0.000108  0.000104  0.000109\n",
      "this       0.000081  0.000102  0.000093  0.000119\n",
      "would      0.000123  0.000046  0.000073  0.000128\n",
      "know       0.000096  0.000077  0.000133  0.000041\n",
      "seem       0.000000  0.000145  0.000070  0.000077\n",
      "anybody    0.000064  0.000041  0.000153  0.000030\n",
      "out        0.000067  0.000063  0.000048  0.000029\n",
      "be you sure 45g be the right number a far a i know pilot be blackout in dive that exceed 8g 9g 45g seem to be out of human tolerance would anybody clarify this please lan\n",
      "==> predicted_topic = religion, actual_topic = space \n",
      "\n",
      "                 autos  religion  graphics     space\n",
      "for           0.000393  0.000173  0.001017  0.000217\n",
      "day           0.000000  0.000588  0.000000  0.000864\n",
      "any           0.000239  0.000079  0.000694  0.000206\n",
      "do            0.000234  0.000224  0.000367  0.000203\n",
      "lizard        0.000000  0.000921  0.000000  0.000000\n",
      "thelema       0.000000  0.000921  0.000000  0.000000\n",
      "sf            0.000000  0.000921  0.000000  0.000000\n",
      "organization  0.000000  0.000921  0.000000  0.000000\n",
      "official      0.000000  0.000921  0.000000  0.000000\n",
      "lodge         0.000000  0.000921  0.000000  0.000000\n",
      "bay           0.000000  0.000921  0.000000  0.000000\n",
      "an            0.000347  0.000229  0.000239  0.000082\n",
      "the           0.000173  0.000178  0.000161  0.000205\n",
      "of            0.000115  0.000239  0.000170  0.000175\n",
      "93            0.000272  0.000388  0.000000  0.000000\n",
      "have          0.000196  0.000127  0.000127  0.000112\n",
      "address       0.000144  0.000178  0.000215  0.000000\n",
      "these         0.000140  0.000238  0.000097  0.000000\n",
      "this          0.000090  0.000114  0.000104  0.000133\n",
      "would         0.000137  0.000051  0.000081  0.000142\n",
      "mail          0.000026  0.000037  0.000130  0.000075\n",
      "area          0.000063  0.000075  0.000000  0.000063\n",
      "do this organization have an official e mail address these day an address for any of the sf bay area lodge e g thelema would do 93 a lizard\n",
      "==> predicted_topic = graphics, actual_topic = religion \n",
      "\n",
      "                 autos  religion  graphics     space\n",
      "for           0.000452  0.000199  0.001170  0.000250\n",
      "seriously     0.000890  0.000389  0.000000  0.000000\n",
      "4000          0.001060  0.000000  0.000000  0.000000\n",
      "account       0.001060  0.000000  0.000000  0.000000\n",
      "depreciation  0.001060  0.000000  0.000000  0.000000\n",
      "taurus        0.001060  0.000000  0.000000  0.000000\n",
      "repair        0.001060  0.000000  0.000000  0.000000\n",
      "rack          0.001060  0.000000  0.000000  0.000000\n",
      "doubt         0.001060  0.000000  0.000000  0.000000\n",
      "extra         0.001060  0.000000  0.000000  0.000000\n",
      "cost          0.000124  0.000000  0.000194  0.000477\n",
      "you           0.000248  0.000187  0.000162  0.000110\n",
      "in            0.000148  0.000141  0.000177  0.000157\n",
      "do            0.000135  0.000129  0.000211  0.000117\n",
      "that          0.000166  0.000139  0.000134  0.000139\n",
      "an            0.000200  0.000132  0.000137  0.000047\n",
      "would         0.000158  0.000058  0.000094  0.000164\n",
      "up            0.000212  0.000084  0.000034  0.000066\n",
      "year          0.000070  0.000039  0.000065  0.000173\n",
      "over          0.000097  0.000028  0.000034  0.000030\n",
      "do you account for depreciation i seriously doubt that a taurus would rack up an extra 4000 in repair cost over 5 year\n",
      "==> predicted_topic = graphics, actual_topic = autos \n",
      "\n",
      "            autos  religion  graphics     space\n",
      "be       0.000507  0.000687  0.000542  0.000624\n",
      "brought  0.000595  0.000441  0.000000  0.000000\n",
      "you      0.000343  0.000258  0.000223  0.000152\n",
      "ok       0.000604  0.000181  0.000000  0.000151\n",
      "right    0.000442  0.000104  0.000051  0.000304\n",
      "john     0.000433  0.000281  0.000111  0.000000\n",
      "that     0.000230  0.000193  0.000185  0.000193\n",
      "if       0.000137  0.000137  0.000217  0.000159\n",
      "up       0.000293  0.000116  0.000047  0.000091\n",
      "name     0.000191  0.000195  0.000038  0.000079\n",
      "so       0.000155  0.000119  0.000109  0.000064\n",
      "good     0.000121  0.000086  0.000137  0.000031\n",
      "few      0.000052  0.000034  0.000065  0.000110\n",
      "example  0.000051  0.000023  0.000054  0.000028\n",
      "ok if you be so right name a few good example that be brought up john\n",
      "==> predicted_topic = religion, actual_topic = autos \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "thanks      0.000873  0.000124  0.003023  0.000781\n",
      "help        0.000000  0.000330  0.001958  0.000345\n",
      "for         0.000504  0.000222  0.001304  0.000279\n",
      "several     0.000000  0.000000  0.001029  0.000786\n",
      "it          0.000448  0.000230  0.000617  0.000419\n",
      "via         0.000000  0.000000  0.001130  0.000575\n",
      "found       0.000000  0.000675  0.000000  0.000509\n",
      "be          0.000205  0.000277  0.000219  0.000251\n",
      "offer       0.000335  0.000000  0.000000  0.000541\n",
      "contact     0.000000  0.000417  0.000000  0.000393\n",
      "and         0.000163  0.000217  0.000204  0.000217\n",
      "will        0.000103  0.000330  0.000044  0.000206\n",
      "get         0.000139  0.000055  0.000243  0.000237\n",
      "those       0.000058  0.000402  0.000111  0.000089\n",
      "people      0.000134  0.000136  0.000024  0.000067\n",
      "mail        0.000033  0.000047  0.000167  0.000096\n",
      "appreciate  0.000023  0.000073  0.000105  0.000042\n",
      "again       0.000033  0.000031  0.000017  0.000023\n",
      "found it thanks i get several offer for help i appreciate it and will be contact those people via e mail thanks again\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "moon        0.000000  0.001101  0.000000  0.001325\n",
      "the         0.000544  0.000558  0.000506  0.000643\n",
      "of          0.000240  0.000501  0.000356  0.000367\n",
      "have        0.000411  0.000265  0.000267  0.000234\n",
      "worship     0.000000  0.000964  0.000000  0.000000\n",
      "element     0.000000  0.000964  0.000000  0.000000\n",
      "sabbath     0.000000  0.000964  0.000000  0.000000\n",
      "phase       0.000000  0.000964  0.000000  0.000000\n",
      "originally  0.000000  0.000964  0.000000  0.000000\n",
      "nature      0.000000  0.000964  0.000000  0.000000\n",
      "egyptian    0.000000  0.000964  0.000000  0.000000\n",
      "be          0.000167  0.000226  0.000178  0.000205\n",
      "determine   0.000000  0.000321  0.000341  0.000000\n",
      "and         0.000133  0.000177  0.000166  0.000177\n",
      "in          0.000135  0.000128  0.000161  0.000143\n",
      "that        0.000151  0.000127  0.000122  0.000127\n",
      "early       0.000150  0.000092  0.000000  0.000077\n",
      "by          0.000071  0.000058  0.000078  0.000073\n",
      "heard       0.000028  0.000091  0.000024  0.000098\n",
      "stuff       0.000035  0.000042  0.000019  0.000016\n",
      "i have heard that the sabbath be originally determine by the phase of the moon and have element of moon worship early stuff egyptian in nature\n",
      "==> predicted_topic = space, actual_topic = religion \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "file       0.000000  0.000000  0.005253  0.001311\n",
      "every      0.000000  0.000000  0.000452  0.001601\n",
      "feel       0.000000  0.000000  0.000000  0.002018\n",
      "be         0.000375  0.000508  0.000401  0.000461\n",
      "day        0.000000  0.000692  0.000000  0.001016\n",
      "could      0.000264  0.000000  0.000293  0.000662\n",
      "wonder     0.000000  0.000000  0.000714  0.000434\n",
      "monthly    0.000000  0.000000  0.000000  0.001083\n",
      "quarterly  0.000000  0.000000  0.000000  0.001083\n",
      "bloat      0.000000  0.000000  0.000000  0.001083\n",
      "28         0.000000  0.000000  0.000000  0.001083\n",
      "post       0.000401  0.000129  0.000000  0.000323\n",
      "the        0.000204  0.000209  0.000189  0.000241\n",
      "rather     0.000000  0.000128  0.000169  0.000380\n",
      "get        0.000128  0.000051  0.000223  0.000218\n",
      "this       0.000106  0.000134  0.000122  0.000157\n",
      "if         0.000101  0.000102  0.000160  0.000117\n",
      "30         0.000161  0.000000  0.000142  0.000094\n",
      "than       0.000041  0.000120  0.000050  0.000094\n",
      "faq        0.000000  0.000067  0.000080  0.000103\n",
      "i be wonder if the faq file could be post quarterly rather than monthly every 28 30 day i get this bloat feel\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "thanks     0.000397  0.000056  0.001375  0.000355\n",
      "be         0.000372  0.000504  0.000397  0.000457\n",
      "explain    0.000000  0.000358  0.000000  0.001189\n",
      "could      0.000262  0.000000  0.000290  0.000657\n",
      "activity   0.000000  0.000000  0.000000  0.001074\n",
      "loss       0.000000  0.000000  0.000000  0.001074\n",
      "alan       0.000000  0.000000  0.000000  0.001074\n",
      "ron        0.000000  0.000000  0.000000  0.001074\n",
      "regularly  0.000000  0.000000  0.000000  0.001074\n",
      "timer      0.000000  0.000000  0.000000  0.001074\n",
      "post       0.000397  0.000128  0.000000  0.000320\n",
      "the        0.000202  0.000207  0.000188  0.000239\n",
      "command    0.000000  0.000000  0.000315  0.000459\n",
      "report     0.000000  0.000000  0.000441  0.000321\n",
      "someone    0.000083  0.000319  0.000000  0.000306\n",
      "in         0.000150  0.000143  0.000179  0.000159\n",
      "this       0.000105  0.000133  0.000121  0.000155\n",
      "what       0.000085  0.000068  0.000085  0.000078\n",
      "interest   0.000000  0.000072  0.000079  0.000081\n",
      "this activity be regularly report in ron s interest post could someone explain what the command loss timer be thanks alan\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "image       0.000000  0.000000  0.003353  0.000625\n",
      "of          0.000269  0.000561  0.000399  0.000411\n",
      "thanks      0.000266  0.000038  0.000921  0.000238\n",
      "stereo      0.000000  0.000000  0.000000  0.001439\n",
      "planetary   0.000000  0.000000  0.000000  0.001439\n",
      "phobos      0.000000  0.000000  0.000000  0.001340\n",
      "satellite   0.000000  0.000000  0.000000  0.001340\n",
      "mar         0.000000  0.000000  0.000000  0.001340\n",
      "tell        0.000000  0.000000  0.000306  0.001020\n",
      "anyone      0.000262  0.000000  0.000733  0.000307\n",
      "might       0.000000  0.000000  0.000321  0.000896\n",
      "the         0.000271  0.000277  0.000252  0.000320\n",
      "surface     0.000000  0.000000  0.000495  0.000491\n",
      "and         0.000199  0.000265  0.000248  0.000265\n",
      "any         0.000187  0.000062  0.000542  0.000161\n",
      "moon        0.000000  0.000411  0.000000  0.000494\n",
      "in          0.000201  0.000191  0.000240  0.000213\n",
      "deimos      0.000000  0.000000  0.000000  0.000720\n",
      "gifs        0.000000  0.000000  0.000506  0.000175\n",
      "where       0.000135  0.000000  0.000286  0.000234\n",
      "me          0.000094  0.000182  0.000294  0.000036\n",
      "especially  0.000387  0.000000  0.000000  0.000192\n",
      "but         0.000042  0.000169  0.000149  0.000096\n",
      "will        0.000063  0.000201  0.000027  0.000126\n",
      "do          0.000091  0.000088  0.000143  0.000079\n",
      "that        0.000113  0.000095  0.000091  0.000095\n",
      "prefer      0.000071  0.000000  0.000235  0.000080\n",
      "can         0.000066  0.000054  0.000123  0.000099\n",
      "order       0.000193  0.000077  0.000000  0.000066\n",
      "find        0.000079  0.000030  0.000090  0.000019\n",
      "interested  0.000020  0.000014  0.000021  0.000020\n",
      "can anyone tell me where i might find stereo image of planetary and planetary satellite surface gifs prefer but any will do i m especially interested in stereo of the surface of phobos deimos mar and the moon in that order thanks\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "            autos  religion  graphics     space\n",
      "42       0.000502  0.000000  0.001259  0.000000\n",
      "thought  0.000000  0.000000  0.000329  0.001421\n",
      "be       0.000363  0.000492  0.000388  0.000447\n",
      "the      0.000395  0.000404  0.000367  0.000466\n",
      "help     0.000000  0.000195  0.001159  0.000204\n",
      "chip     0.000000  0.000000  0.001302  0.000000\n",
      "really   0.000268  0.000739  0.000237  0.000000\n",
      "that     0.000329  0.000276  0.000265  0.000276\n",
      "on       0.000145  0.000152  0.000413  0.000366\n",
      "it       0.000265  0.000136  0.000365  0.000248\n",
      "could    0.000170  0.000000  0.000189  0.000428\n",
      "hear     0.000000  0.000303  0.000365  0.000097\n",
      "24       0.000000  0.000282  0.000454  0.000000\n",
      "pete     0.000000  0.000000  0.000699  0.000000\n",
      "intel    0.000000  0.000000  0.000699  0.000000\n",
      "reason   0.000000  0.000000  0.000699  0.000000\n",
      "proper   0.000000  0.000000  0.000699  0.000000\n",
      "egg      0.000000  0.000000  0.000699  0.000000\n",
      "stomp    0.000000  0.000000  0.000699  0.000000\n",
      "endian   0.000000  0.000000  0.000699  0.000000\n",
      "war      0.000000  0.000471  0.000173  0.000000\n",
      "value    0.000000  0.000469  0.000173  0.000000\n",
      "break    0.000000  0.000000  0.000220  0.000265\n",
      "side     0.000262  0.000000  0.000222  0.000000\n",
      "you      0.000164  0.000123  0.000107  0.000073\n",
      "but      0.000040  0.000164  0.000145  0.000094\n",
      "get      0.000082  0.000033  0.000144  0.000140\n",
      "write    0.000000  0.000066  0.000196  0.000099\n",
      "some     0.000027  0.000045  0.000169  0.000119\n",
      "their    0.000187  0.000101  0.000028  0.000032\n",
      "so       0.000074  0.000057  0.000052  0.000030\n",
      "out      0.000057  0.000053  0.000041  0.000025\n",
      "hear hear really i thought that the reason it be 42 be that it be really 24 but write a 42 so that on intel chip you could get the proper value pete help stomp out the endian war break some egg on their side\n",
      "==> predicted_topic = space, actual_topic = graphics \n",
      "\n",
      "             autos  religion  graphics     space\n",
      "see       0.000979  0.001563  0.000139  0.000000\n",
      "you       0.000655  0.000493  0.000427  0.000290\n",
      "need      0.000262  0.000000  0.000793  0.000403\n",
      "unless    0.001399  0.000000  0.000000  0.000000\n",
      "hmmmmmmm  0.001399  0.000000  0.000000  0.000000\n",
      "accident  0.001399  0.000000  0.000000  0.000000\n",
      "me        0.000184  0.000354  0.000572  0.000070\n",
      "won       0.000645  0.000395  0.000000  0.000000\n",
      "have      0.000298  0.000192  0.000193  0.000170\n",
      "let       0.000224  0.000309  0.000200  0.000000\n",
      "an        0.000264  0.000174  0.000181  0.000062\n",
      "more      0.000097  0.000104  0.000052  0.000061\n",
      "let me see unless you have an accident you won t need more hmmmmmmm\n",
      "==> predicted_topic = religion, actual_topic = autos \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "for         0.000740  0.000326  0.001915  0.000409\n",
      "motorcycle  0.001734  0.000000  0.000000  0.000000\n",
      "mandatory   0.001734  0.000000  0.000000  0.000000\n",
      "drl         0.001734  0.000000  0.000000  0.000000\n",
      "already     0.001038  0.000000  0.000446  0.000000\n",
      "be          0.000300  0.000407  0.000321  0.000369\n",
      "well        0.000068  0.000065  0.000040  0.000045\n",
      "well drl s be already mandatory for motorcycle\n",
      "==> predicted_topic = graphics, actual_topic = autos \n",
      "\n",
      "             autos  religion  graphics     space\n",
      "god       0.000000  0.003608  0.000000  0.000499\n",
      "profit    0.000000  0.000000  0.000000  0.001706\n",
      "the       0.000345  0.000353  0.000320  0.000407\n",
      "twilight  0.000000  0.000000  0.000000  0.000916\n",
      "blare     0.000000  0.000000  0.000000  0.000916\n",
      "bless     0.000000  0.000000  0.000000  0.000916\n",
      "cacs      0.000000  0.000000  0.000000  0.000916\n",
      "caste     0.000000  0.000000  0.000000  0.000916\n",
      "fraering  0.000000  0.000000  0.000000  0.000916\n",
      "freely    0.000000  0.000000  0.000000  0.000916\n",
      "usl       0.000000  0.000000  0.000000  0.000916\n",
      "pgf       0.000000  0.000000  0.000000  0.000916\n",
      "presence  0.000000  0.000000  0.000000  0.000916\n",
      "srl03     0.000000  0.000000  0.000000  0.000916\n",
      "edu       0.000099  0.000000  0.000348  0.000377\n",
      "be        0.000159  0.000215  0.000169  0.000195\n",
      "phil      0.000000  0.000257  0.000000  0.000430\n",
      "it        0.000174  0.000089  0.000239  0.000163\n",
      "and       0.000127  0.000169  0.000158  0.000169\n",
      "right     0.000276  0.000065  0.000032  0.000190\n",
      "in        0.000128  0.000122  0.000153  0.000136\n",
      "from      0.000060  0.000069  0.000096  0.000115\n",
      "even      0.000027  0.000153  0.000054  0.000087\n",
      "by        0.000067  0.000055  0.000074  0.000069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "may       0.000021  0.000090  0.000056  0.000031\n",
      "from phil g fraering pgf srl03 cacs usl edu right the profit caste be bless by god and may freely blare it presence in the even twilight\n",
      "==> predicted_topic = religion, actual_topic = space \n",
      "\n",
      "            autos  religion  graphics     space\n",
      "help     0.000000  0.000315  0.001873  0.000330\n",
      "the      0.000425  0.000436  0.000395  0.000502\n",
      "rest     0.000000  0.000886  0.000000  0.000424\n",
      "shirt    0.000000  0.001130  0.000000  0.000000\n",
      "night    0.000000  0.001130  0.000000  0.000000\n",
      "delete   0.000000  0.001130  0.000000  0.000000\n",
      "brown    0.000000  0.001130  0.000000  0.000000\n",
      "of       0.000141  0.000293  0.000209  0.000215\n",
      "out      0.000276  0.000259  0.000199  0.000120\n",
      "in       0.000158  0.000150  0.000188  0.000167\n",
      "can      0.000104  0.000085  0.000193  0.000155\n",
      "about    0.000169  0.000113  0.000081  0.000073\n",
      "anybody  0.000088  0.000057  0.000209  0.000041\n",
      "find     0.000124  0.000046  0.000141  0.000030\n",
      "rest delete can anybody out in a p h help out find out about the night of the brown shirt\n",
      "==> predicted_topic = graphics, actual_topic = religion \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "for         0.000710  0.000312  0.001838  0.000393\n",
      "new         0.001201  0.000000  0.000375  0.000582\n",
      "23          0.000685  0.000000  0.000000  0.001035\n",
      "thermostat  0.001664  0.000000  0.000000  0.000000\n",
      "sound       0.000415  0.000000  0.000242  0.000819\n",
      "you         0.000389  0.000293  0.000254  0.000173\n",
      "do          0.000211  0.000202  0.000331  0.000183\n",
      "that        0.000261  0.000219  0.000211  0.000219\n",
      "can         0.000153  0.000125  0.000284  0.000228\n",
      "say         0.000156  0.000370  0.000136  0.000080\n",
      "how         0.000102  0.000131  0.000086  0.000072\n",
      "again       0.000047  0.000044  0.000024  0.000033\n",
      "you can say that again how do 23 for a new thermostat sound\n",
      "==> predicted_topic = graphics, actual_topic = autos \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "he          0.000000  0.002411  0.000000  0.000602\n",
      "land        0.000000  0.000000  0.000000  0.001753\n",
      "mach        0.000000  0.000000  0.000000  0.001325\n",
      "flight      0.000000  0.000000  0.000000  0.001234\n",
      "head        0.000000  0.000000  0.000000  0.001234\n",
      "military    0.000000  0.000000  0.000000  0.001234\n",
      "of          0.000165  0.000344  0.000245  0.000252\n",
      "new         0.000478  0.000000  0.000149  0.000232\n",
      "could       0.000161  0.000000  0.000179  0.000405\n",
      "handle      0.000000  0.000000  0.000257  0.000474\n",
      "month       0.000000  0.000000  0.000260  0.000459\n",
      "belive      0.000000  0.000000  0.000000  0.000662\n",
      "boom        0.000000  0.000000  0.000000  0.000662\n",
      "decent      0.000000  0.000000  0.000000  0.000662\n",
      "direction   0.000000  0.000000  0.000000  0.000662\n",
      "fran        0.000000  0.000000  0.000000  0.000662\n",
      "aircraft    0.000000  0.000000  0.000000  0.000662\n",
      "25aircraft  0.000000  0.000000  0.000000  0.000662\n",
      "int         0.000000  0.000000  0.000000  0.000662\n",
      "25          0.000000  0.000000  0.000000  0.000662\n",
      "san         0.000000  0.000000  0.000000  0.000662\n",
      "odd         0.000000  0.000000  0.000000  0.000662\n",
      "supersonic  0.000000  0.000000  0.000000  0.000662\n",
      "super       0.000000  0.000000  0.000436  0.000165\n",
      "be          0.000115  0.000155  0.000123  0.000141\n",
      "the         0.000125  0.000128  0.000116  0.000147\n",
      "on          0.000069  0.000072  0.000196  0.000173\n",
      "ago         0.000053  0.000071  0.000048  0.000323\n",
      "it          0.000126  0.000064  0.000173  0.000118\n",
      "question    0.000086  0.000294  0.000043  0.000035\n",
      "east        0.000000  0.000222  0.000000  0.000232\n",
      "what        0.000105  0.000084  0.000104  0.000096\n",
      "hear        0.000000  0.000144  0.000173  0.000046\n",
      "that        0.000104  0.000087  0.000084  0.000087\n",
      "there       0.000113  0.000040  0.000062  0.000139\n",
      "some        0.000026  0.000043  0.000160  0.000113\n",
      "speed       0.000118  0.000000  0.000069  0.000051\n",
      "heard       0.000019  0.000062  0.000017  0.000067\n",
      "base        0.000015  0.000048  0.000024  0.000065\n",
      "over        0.000061  0.000018  0.000021  0.000019\n",
      "few         0.000024  0.000015  0.000029  0.000050\n",
      "the supersonic boom hear a few month ago over i belive san fran head east of what i heard some new super speed mach 25 aircraft what military base int he direction of flight be there that could handle a mach 25aircraft on it land decent odd question\n",
      "==> predicted_topic = religion, actual_topic = space \n",
      "\n",
      "                  autos  religion  graphics     space\n",
      "try            0.000000  0.000329  0.004991  0.001203\n",
      "he             0.000000  0.002812  0.000000  0.000703\n",
      "thought        0.000000  0.000000  0.000363  0.001570\n",
      "be             0.000268  0.000362  0.000286  0.000329\n",
      "to             0.000226  0.000336  0.000252  0.000285\n",
      "win            0.000000  0.000000  0.000000  0.000773\n",
      "consideration  0.000000  0.000000  0.000000  0.000773\n",
      "sam            0.000000  0.000000  0.000000  0.000773\n",
      "ross           0.000000  0.000000  0.000000  0.000773\n",
      "perot          0.000000  0.000000  0.000000  0.000773\n",
      "disappoint     0.000000  0.000000  0.000000  0.000773\n",
      "further        0.000000  0.000000  0.000000  0.000773\n",
      "matt           0.000000  0.000000  0.000000  0.000773\n",
      "likely         0.000000  0.000000  0.000000  0.000773\n",
      "walton         0.000000  0.000000  0.000000  0.000773\n",
      "gate           0.000000  0.000000  0.000000  0.000773\n",
      "after          0.000414  0.000091  0.000000  0.000187\n",
      "it             0.000147  0.000075  0.000202  0.000137\n",
      "bill           0.000000  0.000301  0.000000  0.000239\n",
      "third          0.000282  0.000000  0.000000  0.000250\n",
      "kid            0.000000  0.000256  0.000000  0.000274\n",
      "but            0.000045  0.000182  0.000160  0.000103\n",
      "my             0.000224  0.000105  0.000045  0.000086\n",
      "in             0.000108  0.000103  0.000129  0.000114\n",
      "first          0.000076  0.000175  0.000041  0.000029\n",
      "think          0.000107  0.000054  0.000065  0.000018\n",
      "more           0.000054  0.000057  0.000029  0.000034\n",
      "come           0.000024  0.000019  0.000050  0.000060\n",
      "my first thought be ross perot after further consideration i think he d be more likely to try to win it but come in a disappoint third try bill gate try sam walton s kid matt\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "         autos  religion  graphics     space\n",
      "to    0.000505  0.000751  0.000563  0.000636\n",
      "know  0.000402  0.000322  0.000555  0.000171\n",
      "just  0.000370  0.000188  0.000218  0.000366\n",
      "want  0.000256  0.000173  0.000163  0.000111\n",
      "i just want to know\n",
      "==> predicted_topic = religion, actual_topic = autos \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "it         0.000610  0.000313  0.000839  0.000571\n",
      "be         0.000278  0.000377  0.000297  0.000342\n",
      "gee        0.000272  0.000000  0.000000  0.000856\n",
      "look       0.000277  0.000024  0.000574  0.000237\n",
      "you        0.000376  0.000283  0.000245  0.000167\n",
      "any        0.000209  0.000069  0.000605  0.000180\n",
      "release    0.000469  0.000000  0.000342  0.000000\n",
      "tion       0.000804  0.000000  0.000000  0.000000\n",
      "radia      0.000804  0.000000  0.000000  0.000000\n",
      "confuse    0.000804  0.000000  0.000000  0.000000\n",
      "genus      0.000804  0.000000  0.000000  0.000000\n",
      "hole       0.000804  0.000000  0.000000  0.000000\n",
      "locate     0.000804  0.000000  0.000000  0.000000\n",
      "tor        0.000804  0.000000  0.000000  0.000000\n",
      "radiation  0.000804  0.000000  0.000000  0.000000\n",
      "radiator   0.000804  0.000000  0.000000  0.000000\n",
      "punch      0.000804  0.000000  0.000000  0.000000\n",
      "where      0.000150  0.000000  0.000319  0.000262\n",
      "really     0.000154  0.000425  0.000136  0.000000\n",
      "sound      0.000200  0.000000  0.000117  0.000396\n",
      "me         0.000106  0.000204  0.000328  0.000040\n",
      "like       0.000197  0.000106  0.000114  0.000235\n",
      "what       0.000128  0.000102  0.000127  0.000117\n",
      "will       0.000070  0.000225  0.000030  0.000140\n",
      "do         0.000102  0.000098  0.000160  0.000088\n",
      "when       0.000041  0.000172  0.000039  0.000083\n",
      "since      0.000074  0.000065  0.000114  0.000000\n",
      "make       0.000051  0.000059  0.000031  0.000028\n",
      "gee you really make me confuse what be radiator where be it locate what do it look like will it release any radiation since it sound like radia tion genus tor when you punch hole\n",
      "==> predicted_topic = space, actual_topic = autos \n",
      "\n",
      "             autos  religion  graphics     space\n",
      "file      0.000000  0.000000  0.003935  0.000982\n",
      "yo        0.000000  0.000000  0.000000  0.003023\n",
      "assume    0.000000  0.000000  0.000000  0.002742\n",
      "be        0.000421  0.000571  0.000450  0.000518\n",
      "every     0.000000  0.000000  0.000339  0.001199\n",
      "string    0.000000  0.000000  0.000000  0.001512\n",
      "sig       0.000000  0.000000  0.000000  0.001512\n",
      "mining    0.000000  0.000000  0.000000  0.001512\n",
      "you       0.000380  0.000286  0.000248  0.000168\n",
      "cash      0.000000  0.000000  0.000000  0.000812\n",
      "limit     0.000000  0.000000  0.000000  0.000812\n",
      "award     0.000000  0.000000  0.000000  0.000812\n",
      "to        0.000119  0.000177  0.000132  0.000149\n",
      "away      0.000306  0.000000  0.000000  0.000257\n",
      "own       0.000000  0.000261  0.000000  0.000299\n",
      "ok        0.000335  0.000100  0.000000  0.000083\n",
      "right     0.000245  0.000058  0.000028  0.000169\n",
      "get       0.000096  0.000038  0.000167  0.000163\n",
      "there     0.000138  0.000049  0.000076  0.000170\n",
      "can       0.000075  0.000061  0.000138  0.000111\n",
      "them      0.000018  0.000142  0.000078  0.000142\n",
      "would     0.000121  0.000045  0.000072  0.000125\n",
      "one       0.000088  0.000071  0.000041  0.000144\n",
      "like      0.000099  0.000053  0.000058  0.000119\n",
      "because   0.000066  0.000122  0.000000  0.000130\n",
      "don       0.000044  0.000086  0.000057  0.000043\n",
      "anything  0.000030  0.000019  0.000036  0.000088\n",
      "give      0.000056  0.000046  0.000044  0.000014\n",
      "time      0.000023  0.000025  0.000046  0.000045\n",
      "mine      0.000022  0.000020  0.000024  0.000054\n",
      "nice      0.000013  0.000011  0.000013  0.000013\n",
      "a cash award be ok a time limit would be nice you can t give away mining right assume there s anything to mine because you don t own them sig file be like string every yo yo s get one\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "           autos  religion  graphics     space\n",
      "get     0.000358  0.000143  0.000625  0.000611\n",
      "life    0.000587  0.000170  0.000000  0.000775\n",
      "people  0.000346  0.000350  0.000062  0.000173\n",
      "people get a life\n",
      "==> predicted_topic = space, actual_topic = autos \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "image       0.000000  0.000000  0.004100  0.000764\n",
      "site        0.000000  0.000000  0.001891  0.000881\n",
      "ftp         0.000000  0.000000  0.001515  0.000650\n",
      "the         0.000497  0.000509  0.000461  0.000587\n",
      "thanks      0.000325  0.000046  0.001126  0.000291\n",
      "phobos      0.000000  0.000000  0.000000  0.001639\n",
      "spacecraft  0.000000  0.000000  0.000000  0.001639\n",
      "russian     0.000000  0.000000  0.000000  0.001639\n",
      "house       0.000000  0.000000  0.000000  0.001639\n",
      "anyone      0.000321  0.000000  0.000897  0.000375\n",
      "any         0.000229  0.000076  0.000663  0.000197\n",
      "moon        0.000000  0.000502  0.000000  0.000605\n",
      "do          0.000223  0.000214  0.000350  0.000194\n",
      "fat         0.000000  0.000000  0.000000  0.000880\n",
      "ill         0.000000  0.000000  0.000000  0.000880\n",
      "martian     0.000000  0.000000  0.000000  0.000880\n",
      "mission     0.000000  0.000000  0.000000  0.000880\n",
      "if          0.000164  0.000165  0.000260  0.000191\n",
      "on          0.000091  0.000096  0.000260  0.000230\n",
      "of          0.000110  0.000228  0.000163  0.000167\n",
      "ago         0.000070  0.000094  0.000064  0.000429\n",
      "back        0.000245  0.000093  0.000000  0.000139\n",
      "an          0.000166  0.000110  0.000114  0.000039\n",
      "they        0.000139  0.000066  0.000048  0.000130\n",
      "send        0.000176  0.000000  0.000076  0.000120\n",
      "know        0.000102  0.000082  0.000141  0.000044\n",
      "year        0.000058  0.000032  0.000054  0.000144\n",
      "so          0.000093  0.000071  0.000066  0.000038\n",
      "re          0.000049  0.000092  0.000018  0.000102\n",
      "at          0.000047  0.000048  0.000077  0.000062\n",
      "few         0.000031  0.000021  0.000039  0.000066\n",
      "do the russian spacecraft s on the ill fat phobos mission a few year ago send back any image of the martian moon if so do anyone know if they re house at an ftp site thanks\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training = True\n",
    "tlabels = train_labels if training else test_labels\n",
    "tdoc_vectors = train_doc_vectors if training else test_doc_vectors\n",
    "misclassified = misclassified_train if training else misclassified_test\n",
    "\n",
    "for doc_index in tqdm(misclassified):\n",
    "    doc_vector = tdoc_vectors[doc_index]\n",
    "    doc_topic_word_distr, doc_topic = infer_topic(label_classes, doc_vector, topic_word_distr)\n",
    "    \n",
    "    xv = doc_topic_word_distr.iloc[np.where(doc_topic_word_distr.sum(1) > 0)]\n",
    "    print(xv.loc[xv.sum(1).sort_values(ascending=False).index])\n",
    "    print(train_docs[doc_index])\n",
    "    print(f\"==> predicted_topic = {doc_topic}, actual_topic = {label_classes[tlabels[doc_index]]} \\n\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuarcy = 100.00%, test_accuarcy = 62.88%, avg-accuarcy = 81.44%\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=.01)\n",
    "clf.fit(train_doc_vectors, train_labels)\n",
    "\n",
    "train_accuracy = clf.score(train_doc_vectors, train_labels)\n",
    "test_accuracy = clf.score(test_doc_vectors, test_labels)\n",
    "\n",
    "print(f\"training_accuarcy = {train_accuracy*100:.2f}%, test_accuarcy = {test_accuracy*100:.2f}%, avg-accuarcy = {.5*(train_accuracy + test_accuracy)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next steps\n",
    "use softwmax on word_trust factor, apply it on word_doc_norm like in word_word_co to suppress the stop words and make the actual important words more pronounced. use this pronounced words to estimate the related topic in doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

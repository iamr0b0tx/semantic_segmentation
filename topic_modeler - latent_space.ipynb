{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In c:\\program files\\python37\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.frameon rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "In c:\\program files\\python37\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The verbose.level rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "In c:\\program files\\python37\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The verbose.fileo rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "from utils import *\n",
    "from word_network import WordNetwork\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import entropy as calculate_entropy\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of samples needed\n",
    "randomize = False\n",
    "\n",
    "# retrieve dataset\n",
    "categories = ['rec.autos', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "\n",
    "docs = fetch_20newsgroups(subset='train', shuffle=randomize, remove=('headers', 'footers', 'quotes'), categories=categories)\n",
    "docs, labels, classes = docs.data, docs.target, docs.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d12a9f1ba1e447a8a3c06440bc6753a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "apparently you re not a woman my husband hate the auto door lock feel safer in a car that lock easily in addition to watch around in a seclude spot etc have my key ready to open the door so i m\n"
     ]
    }
   ],
   "source": [
    "datasize = 100\n",
    "max_document_length = None\n",
    "\n",
    "index = -1\n",
    "clean_docs = []\n",
    "\n",
    "sizes = [0]*len(categories)\n",
    "\n",
    "with tqdm(total=len(categories)*datasize) as pbar:\n",
    "    while sum(sizes) != len(categories)*datasize:\n",
    "        index += 1\n",
    "        size_index = categories.index(classes[labels[index]])\n",
    "        \n",
    "        if sizes[size_index] == datasize:\n",
    "            continue\n",
    "        \n",
    "        doc = docs[index]\n",
    "        status, doc, word_count = clean_doc(doc, True)\n",
    "        \n",
    "        if (not status) or (max_document_length is not None and len(doc) > max_document_length):\n",
    "            continue\n",
    "\n",
    "        clean_docs.append(doc)\n",
    "        sizes[size_index] += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "print(clean_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 100, 100, 100]\n"
     ]
    }
   ],
   "source": [
    "print(sizes)\n",
    "assert min(sizes) == max(sizes) == datasize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 400 docs\n"
     ]
    }
   ],
   "source": [
    "print(f\"there are {len(clean_docs)} docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### count words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_count is 9341\n"
     ]
    }
   ],
   "source": [
    "# mode = \"tfidf\"\n",
    "# mode = \"binary\"\n",
    "# mode = \"normalize\"\n",
    "# mode = \"binary-normalize\"\n",
    "mode = \"pmi\"\n",
    "\n",
    "# initialize the count vectorizer\n",
    "vectorizer = TfidfVectorizer() if mode == \"tfidf\" else CountVectorizer()\n",
    "\n",
    "# fit it to dataset\n",
    "train_docs, test_docs = clean_docs, []\n",
    "# train_docs, test_docs = train_test_split(clean_docs, test_size=.33, random_state=42)\n",
    "\n",
    "vectorizer.fit(train_docs)\n",
    "vocabulary = vectorizer.get_feature_names()\n",
    "\n",
    "print(\"word_count is\", len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Datatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 train_docs, 0 test docs\n"
     ]
    }
   ],
   "source": [
    "# create doc count vectors\n",
    "train_doc_vectors = vectorizer.transform(train_docs).toarray()\n",
    "test_doc_vectors = vectorizer.transform(test_docs).toarray()\n",
    "\n",
    "if mode in [\"binary-normalize\", \"binary\", \"pmi\"]:\n",
    "    train_doc_vectors = (train_doc_vectors > 0).astype(float)\n",
    "    test_doc_vectors = (test_doc_vectors > 0).astype(float)\n",
    "    \n",
    "if mode == \"normalize\" or mode == \"binary-normalize\":\n",
    "    train_doc_vectors = normalize(train_doc_vectors, norm=\"l1\", axis=1)\n",
    "    test_doc_vectors = normalize(test_doc_vectors, norm=\"l1\", axis=1)\n",
    "\n",
    "print(f\"{len(train_doc_vectors)} train_docs, {len(test_doc_vectors)} test docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word-Word Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae96b8b3d6645e8bddc7d9eba3ce7b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9341.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\pandas\\core\\series.py:679: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\christian\\Documents\\christian\\work\\python\\cyberspace\\semantic_segmentation\\utils.py:15: RuntimeWarning: overflow encountered in power\n",
      "  return 1 / (1 + (np.e**-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "word_word_co has shape (9341, 9341)\n"
     ]
    }
   ],
   "source": [
    "#reduce freq in doc to bin value of 1 or 0\n",
    "word_doc_freqency = pd.DataFrame(train_doc_vectors, columns=vocabulary)\n",
    "\n",
    "#the sum vertically of bin freq\n",
    "word_doc_total_frequency = word_doc_freqency.sum(0)\n",
    "\n",
    "word_word_co = pd.DataFrame(data=0.0, columns=vocabulary, index=vocabulary)\n",
    "\n",
    "word_frequency_norm = ((word_doc_freqency > 0).sum(0) / len(train_doc_vectors))\n",
    "p = pd.DataFrame((train_doc_vectors.sum(0) / len(train_doc_vectors)), columns=[0], index=vocabulary)[0]\n",
    "\n",
    "for word in tqdm(vocabulary):\n",
    "    pxy = word_doc_freqency[word_doc_freqency[word] == 1].sum(0) / len(train_doc_vectors)\n",
    "    word_word_co[word] = sigmoid(np.nan_to_num(np.log2(pxy / (p[word] * p))))\n",
    "\n",
    "# word_word_co = (word_word_co.T / word_word_co.sum(1)).T\n",
    "print(f\"word_word_co has shape {word_word_co.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #reduce freq in doc to bin value of 1 or 0\n",
    "# word_doc_freqency = pd.DataFrame(train_doc_vectors, columns=vocabulary)\n",
    "\n",
    "# #the sum vertically of bin freq\n",
    "# word_doc_total_frequency = word_doc_freqency.sum(0)\n",
    "\n",
    "# word_word_co = pd.DataFrame(data=0.0, columns=vocabulary, index=vocabulary)\n",
    "# word_frequency_norm = ((word_doc_freqency > 0).sum(0) / len(train_doc_vectors))\n",
    "\n",
    "# for word in tqdm(vocabulary):\n",
    "#     word_word_frequency = word_doc_freqency[word_doc_freqency[word] > 0].sum(0)\n",
    "#     word_word_co[word] = ((word_word_frequency * word_frequency_norm) / word_doc_total_frequency).fillna(0)\n",
    "\n",
    "# # word_word_co = (word_word_co.T / word_word_co.sum(1)).T\n",
    "# print(f\"word_word_co has shape {word_word_co.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0007</th>\n",
       "      <th>0029</th>\n",
       "      <th>01</th>\n",
       "      <th>011</th>\n",
       "      <th>0119</th>\n",
       "      <th>01752</th>\n",
       "      <th>01821</th>\n",
       "      <th>01852</th>\n",
       "      <th>...</th>\n",
       "      <th>zenith</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeus</th>\n",
       "      <th>zion</th>\n",
       "      <th>zip</th>\n",
       "      <th>zippy</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zorn</th>\n",
       "      <th>zulu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>0.999521</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999521</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999521</td>\n",
       "      <td>0.999521</td>\n",
       "      <td>0.999521</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.993688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0007</th>\n",
       "      <td>0.999521</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999824</td>\n",
       "      <td>0.999824</td>\n",
       "      <td>0.999824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0029</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999824</td>\n",
       "      <td>0.999521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999521</td>\n",
       "      <td>0.999521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9341 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            00       000      0007      0029        01  011  0119     01752  \\\n",
       "00    0.999521  0.000000  0.999521  0.000000  0.000000  0.0   0.0  0.999521   \n",
       "000   0.000000  0.993688  0.000000  0.000000  0.000000  0.0   0.0  0.000000   \n",
       "0007  0.999521  0.000000  0.999824  0.000000  0.000000  0.0   0.0  0.999824   \n",
       "0029  0.000000  0.000000  0.000000  0.999824  0.999521  0.0   0.0  0.000000   \n",
       "01    0.000000  0.000000  0.000000  0.999521  0.999521  0.0   0.0  0.000000   \n",
       "\n",
       "         01821     01852  ...  zenith  zero  zeus  zion  zip     zippy  zoo  \\\n",
       "00    0.999521  0.999521  ...     0.0   0.0   0.0   0.0  0.0  0.999521  0.0   \n",
       "000   0.000000  0.000000  ...     0.0   0.0   0.0   0.0  0.0  0.000000  0.0   \n",
       "0007  0.999824  0.999824  ...     0.0   0.0   0.0   0.0  0.0  0.999824  0.0   \n",
       "0029  0.000000  0.000000  ...     0.0   0.0   0.0   0.0  0.0  0.000000  0.0   \n",
       "01    0.000000  0.000000  ...     0.0   0.0   0.0   0.0  0.0  0.000000  0.0   \n",
       "\n",
       "          zoom  zorn  zulu  \n",
       "00    0.998700   0.0   0.0  \n",
       "000   0.000000   0.0   0.0  \n",
       "0007  0.999521   0.0   0.0  \n",
       "0029  0.000000   0.0   0.0  \n",
       "01    0.000000   0.0   0.0  \n",
       "\n",
       "[5 rows x 9341 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_word_co.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Word Trust ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_entropy = pd.DataFrame(data=np.nan_to_num(calculate_entropy(word_word_co.T, base=2)), columns=[0], index=vocabulary)[0]\n",
    "word_trust_factor = pd.DataFrame(data=gaussian2(word_entropy), columns=[0], index=vocabulary)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = [\"look\", \"algorithm\", \"program\"]\n",
    "# words = [\"looking\", \"algorithm\", \"program\", \"the\", \"to\", \"of\"]\n",
    "\n",
    "fig = plt.figure(figsize=(10,3))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "ax1.set_title(f\"Word Trust factor {word} against TOPICS\")\n",
    "ax1.bar(words, (word_trust_factor)[words])\n",
    "\n",
    "ax2.set_title(f\"Word Frequency Normalized {word} against TOPICS\")\n",
    "ax2.bar(words, word_frequency_norm[words])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe word_word_co ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "word = \"software\"\n",
    "words = [\"car\", \"god\", \"file\", \"nasa\", \"the\", \"to\", \"of\"]\n",
    "\n",
    "plt.title(f\"word_word_co {word} against TOPICS\")\n",
    "plt.bar(words, word_word_co.loc[word][words])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "printer       0.990471\n",
       "calibrate     0.990471\n",
       "byteswap      0.990471\n",
       "bypassing     0.990471\n",
       "rename        0.990471\n",
       "renderer      0.990471\n",
       "rep           0.990471\n",
       "buford        0.990471\n",
       "buffer        0.990471\n",
       "budapest      0.990471\n",
       "bris          0.990471\n",
       "bret          0.990471\n",
       "rewrite       0.990471\n",
       "boyd          0.990471\n",
       "richardson    0.990471\n",
       "Name: software, dtype: float64"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_word_co.loc[word].sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update word_word_co with gaussian entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_word_co = (word_word_co + (word_word_co * word_word_co.T)) * word_trust_factor\n",
    "word_word_co = (word_word_co * word_trust_factor)\n",
    "word_word_co = (word_word_co.T / word_word_co.sum(1)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe word_word_co ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(f\"Updated word_word_co {word} against TOPICS\")\n",
    "plt.bar(words, word_word_co.loc[word][words])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "showing          0.024811\n",
       "apparantly       0.024811\n",
       "ce               0.024811\n",
       "3do              0.024811\n",
       "licensee         0.024811\n",
       "decompression    0.019568\n",
       "25mhz            0.019568\n",
       "tttddd           0.019544\n",
       "stereo           0.015056\n",
       "sys              0.015056\n",
       "piccy            0.013696\n",
       "ruu              0.013696\n",
       "jhwitten         0.013696\n",
       "dir              0.013696\n",
       "jpegs            0.013696\n",
       "Name: software, dtype: float64"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_word_co.loc[word].sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_entropy2 = pd.DataFrame(data=np.nan_to_num(calculate_entropy(word_word_co.T, base=2)), columns=[0], index=vocabulary)[0]\n",
    "word_trust_factor2 = pd.DataFrame(data=gaussian2(word_entropy2), columns=[0], index=vocabulary)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update word_word_co with word_word_co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wwc = pd.DataFrame(data=0.0, columns=vocabulary, index=vocabulary)\n",
    "\n",
    "# for word in tqdm(vocabulary):\n",
    "#     for other_word in vocabulary:\n",
    "#         ratios = word_word_co.loc[word][other_word] * word_word_co.loc[other_word]\n",
    "#         wwc.loc[word][ratios > wwc.loc[word]] = ratios[ratios > wwc.loc[word]]\n",
    "\n",
    "# print(f\"word_word_co has shape {word_word_co.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de40452284354f91baf2ec9a21c42a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "doc_word_distr has shape (400, 9341)\n"
     ]
    }
   ],
   "source": [
    "doc_word_distr = pd.DataFrame(data=0.0, columns=vocabulary, index=word_doc_freqency.index)\n",
    "update_factor = word_word_co.mean(1)\n",
    "\n",
    "for doc_index in tqdm(range(len(train_doc_vectors))):\n",
    "    doc_word_distr.loc[doc_index] = update_factor * train_doc_vectors[doc_index]\n",
    "\n",
    "print(f\"doc_word_distr has shape {doc_word_distr.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seclude    0.007530\n",
       "safer      0.000443\n",
       "husband    0.000125\n",
       "woman      0.000116\n",
       "hate       0.000051\n",
       "door       0.000035\n",
       "lock       0.000034\n",
       "watch      0.000015\n",
       "ready      0.000014\n",
       "key        0.000014\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(word_doc_freqency.iloc[0] * word_trust_factor).sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "addition    0.000107\n",
       "you         0.000107\n",
       "open        0.000107\n",
       "to          0.000107\n",
       "the         0.000107\n",
       "easily      0.000107\n",
       "etc         0.000107\n",
       "auto        0.000107\n",
       "in          0.000107\n",
       "re          0.000107\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_word_distr.iloc[0].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apparently you re not a woman my husband hate the auto door lock feel safer in a car that lock easily in addition to watch around in a seclude spot etc have my key ready to open the door so i m'"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0007</th>\n",
       "      <th>0029</th>\n",
       "      <th>01</th>\n",
       "      <th>011</th>\n",
       "      <th>0119</th>\n",
       "      <th>01752</th>\n",
       "      <th>01821</th>\n",
       "      <th>01852</th>\n",
       "      <th>...</th>\n",
       "      <th>zenith</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeus</th>\n",
       "      <th>zion</th>\n",
       "      <th>zip</th>\n",
       "      <th>zippy</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zorn</th>\n",
       "      <th>zulu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9341 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  0007  0029   01  011  0119  01752  01821  01852  ...  zenith  \\\n",
       "0  0.0  0.0   0.0   0.0  0.0  0.0   0.0    0.0    0.0    0.0  ...     0.0   \n",
       "1  0.0  0.0   0.0   0.0  0.0  0.0   0.0    0.0    0.0    0.0  ...     0.0   \n",
       "2  0.0  0.0   0.0   0.0  0.0  0.0   0.0    0.0    0.0    0.0  ...     0.0   \n",
       "3  0.0  0.0   0.0   0.0  0.0  0.0   0.0    0.0    0.0    0.0  ...     0.0   \n",
       "4  0.0  0.0   0.0   0.0  0.0  0.0   0.0    0.0    0.0    0.0  ...     0.0   \n",
       "\n",
       "   zero  zeus  zion  zip  zippy  zoo  zoom  zorn  zulu  \n",
       "0   0.0   0.0   0.0  0.0    0.0  0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0  0.0    0.0  0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0  0.0    0.0  0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0  0.0    0.0  0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0  0.0    0.0  0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 9341 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_word_distr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Latent partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distr_params has shape (400, 9341)\n"
     ]
    }
   ],
   "source": [
    "reduction = None\n",
    "# reduction = \"pca\"\n",
    "# reduction = \"normal\"\n",
    "\n",
    "if reduction is None:\n",
    "    columns = doc_word_distr.columns\n",
    "    param_values = doc_word_distr.values\n",
    "\n",
    "if reduction == \"pca\":\n",
    "    num_of_components = 126\n",
    "    columns = list(range(num_of_components))\n",
    "    \n",
    "    pca = PCA(n_components=num_of_components)\n",
    "    param_values = pca.fit_transform(doc_word_distr)\n",
    "\n",
    "if reduction == \"normal\":\n",
    "    columns = [\"mean\", \"std\"]\n",
    "    param_values = np.array([doc_word_distr.mean(1), doc_word_distr.std(1)]).T\n",
    "    \n",
    "distr_params = pd.DataFrame(data=param_values, columns=columns, index=list(range(len(doc_word_distr))))\n",
    "print(f\"distr_params has shape {distr_params.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0007</th>\n",
       "      <th>0029</th>\n",
       "      <th>01</th>\n",
       "      <th>011</th>\n",
       "      <th>0119</th>\n",
       "      <th>01752</th>\n",
       "      <th>01821</th>\n",
       "      <th>01852</th>\n",
       "      <th>...</th>\n",
       "      <th>zenith</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeus</th>\n",
       "      <th>zion</th>\n",
       "      <th>zip</th>\n",
       "      <th>zippy</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zorn</th>\n",
       "      <th>zulu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9341 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  0007  0029   01  011  0119  01752  01821  01852  ...  zenith  \\\n",
       "0  0.0  0.0   0.0   0.0  0.0  0.0   0.0    0.0    0.0    0.0  ...     0.0   \n",
       "1  0.0  0.0   0.0   0.0  0.0  0.0   0.0    0.0    0.0    0.0  ...     0.0   \n",
       "2  0.0  0.0   0.0   0.0  0.0  0.0   0.0    0.0    0.0    0.0  ...     0.0   \n",
       "3  0.0  0.0   0.0   0.0  0.0  0.0   0.0    0.0    0.0    0.0  ...     0.0   \n",
       "4  0.0  0.0   0.0   0.0  0.0  0.0   0.0    0.0    0.0    0.0  ...     0.0   \n",
       "\n",
       "   zero  zeus  zion  zip  zippy  zoo  zoom  zorn  zulu  \n",
       "0   0.0   0.0   0.0  0.0    0.0  0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0  0.0    0.0  0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0  0.0    0.0  0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0  0.0    0.0  0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0  0.0    0.0  0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 9341 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distr_params.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Kmeans MiniBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_topics = 4\n",
    "kmeans_model = MiniBatchKMeans(n_clusters=num_of_topics, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e0d283d73124ab1acee454611a66b8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1024.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, 9341)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_iterations = 1024\n",
    "\n",
    "num_of_samples = len(distr_params)\n",
    "batch_size = num_of_samples // 2\n",
    "\n",
    "for i in tqdm(range(num_of_iterations)):\n",
    "    indices = np.random.randint(num_of_samples, size=batch_size)\n",
    "    \n",
    "    kmeans_model.partial_fit(distr_params.iloc[indices])\n",
    "\n",
    "kmeans_model.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist has shape (400, 4), predicted_labels has shape (400,)\n"
     ]
    }
   ],
   "source": [
    "dist = kmeans_model.transform(distr_params)\n",
    "predicted_labels = kmeans_model.predict(distr_params)\n",
    "\n",
    "print(f\"dist has shape {dist.shape}, predicted_labels has shape {predicted_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "voc_array = np.array(vocabulary)\n",
    "\n",
    "def get_top2(topic):\n",
    "    indices = dist[:, topic].argsort()\n",
    "    print(labels[indices[:10]])\n",
    "\n",
    "def get_top2(topic):\n",
    "    indices = np.where(predicted_labels == topic)[0]\n",
    "    indices = distr_params.iloc[indices].mean(0).argsort()[::-1][:100]\n",
    "    print(voc_array[indices])\n",
    "\n",
    "def get_top(topic):\n",
    "    indices = np.where(predicted_labels == topic)[0]\n",
    "    print((doc_word_distr.iloc[indices].sum(0) * word_trust_factor).sort_values(ascending=False).head(10))\n",
    "    \n",
    "def get_top2(topic):\n",
    "    indices = np.where(predicted_labels == topic)[0]\n",
    "    print(Counter(labels[indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reduce        0.001893\n",
      "severe        0.001471\n",
      "white         0.001295\n",
      "buyer         0.001266\n",
      "slick         0.001207\n",
      "vent          0.001092\n",
      "sir           0.001021\n",
      "planetary     0.000953\n",
      "sufficient    0.000947\n",
      "hlv           0.000882\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "get_top(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reduce           0.002839\n",
      "compact          0.001340\n",
      "aliasing         0.001238\n",
      "suit             0.001042\n",
      "sufficient       0.000947\n",
      "delta            0.000900\n",
      "rom              0.000780\n",
      "significantly    0.000754\n",
      "ames             0.000704\n",
      "dryden           0.000678\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "get_top(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "viewer    0.000058\n",
      "rix       0.000017\n",
      "vpic      0.000017\n",
      "scf       0.000017\n",
      "768       0.000017\n",
      "7bytes    0.000017\n",
      "dont      0.000014\n",
      "rgb       0.000011\n",
      "info      0.000009\n",
      "sci       0.000006\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "get_top(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sufficient    0.001895\n",
      "suit          0.001563\n",
      "severe        0.001471\n",
      "white         0.001295\n",
      "slick         0.001207\n",
      "sir           0.001021\n",
      "reduce        0.000946\n",
      "hlv           0.000882\n",
      "rom           0.000780\n",
      "radiance      0.000779\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "get_top(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Topic model with Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54029e101f0241e6bd32fc3234049bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=268.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> train-accuracy is 90.67%, 25 misclassified\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "misclassified_train = []\n",
    "print(\"Evaluating Topic Model...\")\n",
    "\n",
    "for doc_index in tqdm(range(len(train_labels))):\n",
    "    doc_vector = train_doc_vectors[doc_index]\n",
    "    \n",
    "    doc_topic_word_distr, doc_topic = infer_topic(label_classes, doc_vector, topic_word_distr)\n",
    "    score += int(doc_topic == label_classes[train_labels[doc_index]])\n",
    "    \n",
    "    if doc_topic != label_classes[train_labels[doc_index]]:\n",
    "        misclassified_train.append(doc_index)\n",
    "    \n",
    "train_accuracy = score / (doc_index + 1)\n",
    "print(f\"==> train-accuracy is {train_accuracy*100:.2f}%, {len(misclassified_train)} misclassified\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Topic Model with test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c629d68d6d47ce9cd469637fff64ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=132.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> test-accuracy is 54.55%, avg-accuarcy = 72.61%, 60 misclassified\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "print(\"Evaluating Topic Model...\")\n",
    "\n",
    "misclassified_test = []\n",
    "for doc_index in tqdm(range(len(test_labels))):\n",
    "    doc_vector = test_doc_vectors[doc_index]\n",
    "    \n",
    "    doc_topic_word_distr, doc_topic = infer_topic(label_classes, doc_vector, topic_word_distr)\n",
    "    score += int(doc_topic == label_classes[test_labels[doc_index]])\n",
    "    \n",
    "    if doc_topic != label_classes[test_labels[doc_index]]:\n",
    "        misclassified_test.append(doc_index)\n",
    "    \n",
    "\n",
    "test_accuracy = score / (doc_index + 1)\n",
    "print(f\"==> test-accuracy is {test_accuracy*100:.2f}%, avg-accuarcy = {.5*(train_accuracy + test_accuracy)*100:.2f}%, {len(misclassified_test)} misclassified\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating Misclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac0825f5c8984e1caeb6d5393e151907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              autos  religion  graphics     space\n",
      "ve         0.000334  0.000191  0.001622  0.000000\n",
      "sense      0.000426  0.001182  0.000000  0.000000\n",
      "maybe      0.000000  0.000906  0.000605  0.000000\n",
      "shot       0.000000  0.000677  0.000000  0.000371\n",
      "that       0.000299  0.000251  0.000241  0.000251\n",
      "kind       0.000000  0.000394  0.000588  0.000000\n",
      "cheap      0.000000  0.000954  0.000000  0.000000\n",
      "embarrass  0.000000  0.000954  0.000000  0.000000\n",
      "fundies    0.000000  0.000954  0.000000  0.000000\n",
      "josh       0.000000  0.000954  0.000000  0.000000\n",
      "mood       0.000000  0.000954  0.000000  0.000000\n",
      "mcdowell   0.000000  0.000954  0.000000  0.000000\n",
      "be         0.000165  0.000224  0.000176  0.000203\n",
      "of         0.000119  0.000248  0.000176  0.000181\n",
      "to         0.000140  0.000208  0.000155  0.000176\n",
      "okay       0.000000  0.000375  0.000293  0.000000\n",
      "except     0.000307  0.000350  0.000000  0.000000\n",
      "who        0.000148  0.000316  0.000030  0.000111\n",
      "but        0.000055  0.000224  0.000197  0.000128\n",
      "have       0.000203  0.000131  0.000132  0.000116\n",
      "enough     0.000163  0.000133  0.000000  0.000267\n",
      "in         0.000133  0.000127  0.000159  0.000141\n",
      "know       0.000111  0.000089  0.000153  0.000047\n",
      "by         0.000070  0.000057  0.000077  0.000072\n",
      "few        0.000034  0.000022  0.000042  0.000071\n",
      "true       0.000036  0.000038  0.000019  0.000019\n",
      "true except that i ve know few fundies who have enough sense to be embarrass by josh mcdowell okay maybe a cheap shot but i m in that kind of mood\n",
      "==> predicted_topic = graphics, actual_topic = religion \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "he          0.000000  0.003337  0.000000  0.000834\n",
      "the         0.000517  0.000530  0.000481  0.000611\n",
      "it          0.000522  0.000267  0.000718  0.000488\n",
      "71          0.000000  0.000000  0.000000  0.001833\n",
      "until       0.000000  0.000000  0.000000  0.000917\n",
      "dubbed      0.000000  0.000000  0.000000  0.000917\n",
      "fwiw        0.000000  0.000000  0.000000  0.000917\n",
      "lbj         0.000000  0.000000  0.000000  0.000917\n",
      "mippselled  0.000000  0.000000  0.000000  0.000917\n",
      "page        0.000000  0.000000  0.000000  0.000917\n",
      "sic         0.000000  0.000000  0.000000  0.000917\n",
      "sr          0.000000  0.000000  0.000000  0.000917\n",
      "be          0.000159  0.000215  0.000170  0.000195\n",
      "doug        0.000000  0.000000  0.000438  0.000255\n",
      "who         0.000142  0.000304  0.000029  0.000107\n",
      "also        0.000165  0.000166  0.000000  0.000127\n",
      "one         0.000100  0.000080  0.000046  0.000163\n",
      "he s also the one who dubbed it the sr 71 it be the r 71 until lbj mippselled sic it fwiw doug page\n",
      "==> predicted_topic = religion, actual_topic = space \n",
      "\n",
      "            autos  religion  graphics     space\n",
      "file     0.000000  0.000000  0.005275  0.001317\n",
      "yo       0.000000  0.000000  0.000000  0.004052\n",
      "every    0.000000  0.000000  0.000454  0.001607\n",
      "string   0.000000  0.000000  0.000000  0.002026\n",
      "sig      0.000000  0.000000  0.000000  0.002026\n",
      "look     0.000375  0.000033  0.000778  0.000320\n",
      "publish  0.000000  0.000000  0.000000  0.001088\n",
      "plenty   0.000000  0.000000  0.000000  0.001088\n",
      "kiddo    0.000000  0.000000  0.000000  0.001088\n",
      "be       0.000188  0.000255  0.000201  0.000232\n",
      "to       0.000159  0.000237  0.000177  0.000200\n",
      "you      0.000255  0.000192  0.000166  0.000113\n",
      "have     0.000232  0.000150  0.000150  0.000132\n",
      "get      0.000128  0.000051  0.000223  0.000219\n",
      "one      0.000118  0.000095  0.000055  0.000193\n",
      "like     0.000133  0.000072  0.000077  0.000159\n",
      "just     0.000116  0.000059  0.000069  0.000115\n",
      "we       0.000031  0.000075  0.000074  0.000174\n",
      "we publish plenty kiddo you just have to look sig file be like string every yo yo s get one\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "human      0.000000  0.002433  0.000000  0.000381\n",
      "be         0.000572  0.000774  0.000611  0.000703\n",
      "45g        0.000000  0.000000  0.000000  0.001651\n",
      "sure       0.000000  0.000000  0.000505  0.000851\n",
      "lan        0.000000  0.000000  0.000000  0.000826\n",
      "8g         0.000000  0.000000  0.000000  0.000826\n",
      "9g         0.000000  0.000000  0.000000  0.000826\n",
      "blackout   0.000000  0.000000  0.000000  0.000826\n",
      "clarify    0.000000  0.000000  0.000000  0.000826\n",
      "dive       0.000000  0.000000  0.000000  0.000826\n",
      "pilot      0.000000  0.000000  0.000000  0.000826\n",
      "exceed     0.000000  0.000000  0.000000  0.000826\n",
      "the        0.000155  0.000159  0.000144  0.000183\n",
      "of         0.000103  0.000214  0.000153  0.000157\n",
      "to         0.000121  0.000180  0.000135  0.000152\n",
      "number     0.000048  0.000103  0.000372  0.000053\n",
      "tolerance  0.000000  0.000274  0.000000  0.000293\n",
      "far        0.000276  0.000000  0.000000  0.000290\n",
      "you        0.000193  0.000146  0.000126  0.000086\n",
      "right      0.000249  0.000059  0.000029  0.000172\n",
      "in         0.000115  0.000110  0.000138  0.000122\n",
      "please     0.000023  0.000193  0.000170  0.000090\n",
      "that       0.000130  0.000108  0.000104  0.000109\n",
      "this       0.000081  0.000102  0.000093  0.000119\n",
      "would      0.000123  0.000046  0.000073  0.000128\n",
      "know       0.000096  0.000077  0.000133  0.000041\n",
      "seem       0.000000  0.000145  0.000070  0.000077\n",
      "anybody    0.000064  0.000041  0.000153  0.000030\n",
      "out        0.000067  0.000063  0.000048  0.000029\n",
      "be you sure 45g be the right number a far a i know pilot be blackout in dive that exceed 8g 9g 45g seem to be out of human tolerance would anybody clarify this please lan\n",
      "==> predicted_topic = religion, actual_topic = space \n",
      "\n",
      "                 autos  religion  graphics     space\n",
      "for           0.000393  0.000173  0.001017  0.000217\n",
      "day           0.000000  0.000588  0.000000  0.000864\n",
      "any           0.000239  0.000079  0.000694  0.000206\n",
      "do            0.000234  0.000224  0.000367  0.000203\n",
      "lizard        0.000000  0.000921  0.000000  0.000000\n",
      "thelema       0.000000  0.000921  0.000000  0.000000\n",
      "sf            0.000000  0.000921  0.000000  0.000000\n",
      "organization  0.000000  0.000921  0.000000  0.000000\n",
      "official      0.000000  0.000921  0.000000  0.000000\n",
      "lodge         0.000000  0.000921  0.000000  0.000000\n",
      "bay           0.000000  0.000921  0.000000  0.000000\n",
      "an            0.000347  0.000229  0.000239  0.000082\n",
      "the           0.000173  0.000178  0.000161  0.000205\n",
      "of            0.000115  0.000239  0.000170  0.000175\n",
      "93            0.000272  0.000388  0.000000  0.000000\n",
      "have          0.000196  0.000127  0.000127  0.000112\n",
      "address       0.000144  0.000178  0.000215  0.000000\n",
      "these         0.000140  0.000238  0.000097  0.000000\n",
      "this          0.000090  0.000114  0.000104  0.000133\n",
      "would         0.000137  0.000051  0.000081  0.000142\n",
      "mail          0.000026  0.000037  0.000130  0.000075\n",
      "area          0.000063  0.000075  0.000000  0.000063\n",
      "do this organization have an official e mail address these day an address for any of the sf bay area lodge e g thelema would do 93 a lizard\n",
      "==> predicted_topic = graphics, actual_topic = religion \n",
      "\n",
      "                 autos  religion  graphics     space\n",
      "for           0.000452  0.000199  0.001170  0.000250\n",
      "seriously     0.000890  0.000389  0.000000  0.000000\n",
      "4000          0.001060  0.000000  0.000000  0.000000\n",
      "account       0.001060  0.000000  0.000000  0.000000\n",
      "depreciation  0.001060  0.000000  0.000000  0.000000\n",
      "taurus        0.001060  0.000000  0.000000  0.000000\n",
      "repair        0.001060  0.000000  0.000000  0.000000\n",
      "rack          0.001060  0.000000  0.000000  0.000000\n",
      "doubt         0.001060  0.000000  0.000000  0.000000\n",
      "extra         0.001060  0.000000  0.000000  0.000000\n",
      "cost          0.000124  0.000000  0.000194  0.000477\n",
      "you           0.000248  0.000187  0.000162  0.000110\n",
      "in            0.000148  0.000141  0.000177  0.000157\n",
      "do            0.000135  0.000129  0.000211  0.000117\n",
      "that          0.000166  0.000139  0.000134  0.000139\n",
      "an            0.000200  0.000132  0.000137  0.000047\n",
      "would         0.000158  0.000058  0.000094  0.000164\n",
      "up            0.000212  0.000084  0.000034  0.000066\n",
      "year          0.000070  0.000039  0.000065  0.000173\n",
      "over          0.000097  0.000028  0.000034  0.000030\n",
      "do you account for depreciation i seriously doubt that a taurus would rack up an extra 4000 in repair cost over 5 year\n",
      "==> predicted_topic = graphics, actual_topic = autos \n",
      "\n",
      "            autos  religion  graphics     space\n",
      "be       0.000507  0.000687  0.000542  0.000624\n",
      "brought  0.000595  0.000441  0.000000  0.000000\n",
      "you      0.000343  0.000258  0.000223  0.000152\n",
      "ok       0.000604  0.000181  0.000000  0.000151\n",
      "right    0.000442  0.000104  0.000051  0.000304\n",
      "john     0.000433  0.000281  0.000111  0.000000\n",
      "that     0.000230  0.000193  0.000185  0.000193\n",
      "if       0.000137  0.000137  0.000217  0.000159\n",
      "up       0.000293  0.000116  0.000047  0.000091\n",
      "name     0.000191  0.000195  0.000038  0.000079\n",
      "so       0.000155  0.000119  0.000109  0.000064\n",
      "good     0.000121  0.000086  0.000137  0.000031\n",
      "few      0.000052  0.000034  0.000065  0.000110\n",
      "example  0.000051  0.000023  0.000054  0.000028\n",
      "ok if you be so right name a few good example that be brought up john\n",
      "==> predicted_topic = religion, actual_topic = autos \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "thanks      0.000873  0.000124  0.003023  0.000781\n",
      "help        0.000000  0.000330  0.001958  0.000345\n",
      "for         0.000504  0.000222  0.001304  0.000279\n",
      "several     0.000000  0.000000  0.001029  0.000786\n",
      "it          0.000448  0.000230  0.000617  0.000419\n",
      "via         0.000000  0.000000  0.001130  0.000575\n",
      "found       0.000000  0.000675  0.000000  0.000509\n",
      "be          0.000205  0.000277  0.000219  0.000251\n",
      "offer       0.000335  0.000000  0.000000  0.000541\n",
      "contact     0.000000  0.000417  0.000000  0.000393\n",
      "and         0.000163  0.000217  0.000204  0.000217\n",
      "will        0.000103  0.000330  0.000044  0.000206\n",
      "get         0.000139  0.000055  0.000243  0.000237\n",
      "those       0.000058  0.000402  0.000111  0.000089\n",
      "people      0.000134  0.000136  0.000024  0.000067\n",
      "mail        0.000033  0.000047  0.000167  0.000096\n",
      "appreciate  0.000023  0.000073  0.000105  0.000042\n",
      "again       0.000033  0.000031  0.000017  0.000023\n",
      "found it thanks i get several offer for help i appreciate it and will be contact those people via e mail thanks again\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "moon        0.000000  0.001101  0.000000  0.001325\n",
      "the         0.000544  0.000558  0.000506  0.000643\n",
      "of          0.000240  0.000501  0.000356  0.000367\n",
      "have        0.000411  0.000265  0.000267  0.000234\n",
      "worship     0.000000  0.000964  0.000000  0.000000\n",
      "element     0.000000  0.000964  0.000000  0.000000\n",
      "sabbath     0.000000  0.000964  0.000000  0.000000\n",
      "phase       0.000000  0.000964  0.000000  0.000000\n",
      "originally  0.000000  0.000964  0.000000  0.000000\n",
      "nature      0.000000  0.000964  0.000000  0.000000\n",
      "egyptian    0.000000  0.000964  0.000000  0.000000\n",
      "be          0.000167  0.000226  0.000178  0.000205\n",
      "determine   0.000000  0.000321  0.000341  0.000000\n",
      "and         0.000133  0.000177  0.000166  0.000177\n",
      "in          0.000135  0.000128  0.000161  0.000143\n",
      "that        0.000151  0.000127  0.000122  0.000127\n",
      "early       0.000150  0.000092  0.000000  0.000077\n",
      "by          0.000071  0.000058  0.000078  0.000073\n",
      "heard       0.000028  0.000091  0.000024  0.000098\n",
      "stuff       0.000035  0.000042  0.000019  0.000016\n",
      "i have heard that the sabbath be originally determine by the phase of the moon and have element of moon worship early stuff egyptian in nature\n",
      "==> predicted_topic = space, actual_topic = religion \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "file       0.000000  0.000000  0.005253  0.001311\n",
      "every      0.000000  0.000000  0.000452  0.001601\n",
      "feel       0.000000  0.000000  0.000000  0.002018\n",
      "be         0.000375  0.000508  0.000401  0.000461\n",
      "day        0.000000  0.000692  0.000000  0.001016\n",
      "could      0.000264  0.000000  0.000293  0.000662\n",
      "wonder     0.000000  0.000000  0.000714  0.000434\n",
      "monthly    0.000000  0.000000  0.000000  0.001083\n",
      "quarterly  0.000000  0.000000  0.000000  0.001083\n",
      "bloat      0.000000  0.000000  0.000000  0.001083\n",
      "28         0.000000  0.000000  0.000000  0.001083\n",
      "post       0.000401  0.000129  0.000000  0.000323\n",
      "the        0.000204  0.000209  0.000189  0.000241\n",
      "rather     0.000000  0.000128  0.000169  0.000380\n",
      "get        0.000128  0.000051  0.000223  0.000218\n",
      "this       0.000106  0.000134  0.000122  0.000157\n",
      "if         0.000101  0.000102  0.000160  0.000117\n",
      "30         0.000161  0.000000  0.000142  0.000094\n",
      "than       0.000041  0.000120  0.000050  0.000094\n",
      "faq        0.000000  0.000067  0.000080  0.000103\n",
      "i be wonder if the faq file could be post quarterly rather than monthly every 28 30 day i get this bloat feel\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "thanks     0.000397  0.000056  0.001375  0.000355\n",
      "be         0.000372  0.000504  0.000397  0.000457\n",
      "explain    0.000000  0.000358  0.000000  0.001189\n",
      "could      0.000262  0.000000  0.000290  0.000657\n",
      "activity   0.000000  0.000000  0.000000  0.001074\n",
      "loss       0.000000  0.000000  0.000000  0.001074\n",
      "alan       0.000000  0.000000  0.000000  0.001074\n",
      "ron        0.000000  0.000000  0.000000  0.001074\n",
      "regularly  0.000000  0.000000  0.000000  0.001074\n",
      "timer      0.000000  0.000000  0.000000  0.001074\n",
      "post       0.000397  0.000128  0.000000  0.000320\n",
      "the        0.000202  0.000207  0.000188  0.000239\n",
      "command    0.000000  0.000000  0.000315  0.000459\n",
      "report     0.000000  0.000000  0.000441  0.000321\n",
      "someone    0.000083  0.000319  0.000000  0.000306\n",
      "in         0.000150  0.000143  0.000179  0.000159\n",
      "this       0.000105  0.000133  0.000121  0.000155\n",
      "what       0.000085  0.000068  0.000085  0.000078\n",
      "interest   0.000000  0.000072  0.000079  0.000081\n",
      "this activity be regularly report in ron s interest post could someone explain what the command loss timer be thanks alan\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "image       0.000000  0.000000  0.003353  0.000625\n",
      "of          0.000269  0.000561  0.000399  0.000411\n",
      "thanks      0.000266  0.000038  0.000921  0.000238\n",
      "stereo      0.000000  0.000000  0.000000  0.001439\n",
      "planetary   0.000000  0.000000  0.000000  0.001439\n",
      "phobos      0.000000  0.000000  0.000000  0.001340\n",
      "satellite   0.000000  0.000000  0.000000  0.001340\n",
      "mar         0.000000  0.000000  0.000000  0.001340\n",
      "tell        0.000000  0.000000  0.000306  0.001020\n",
      "anyone      0.000262  0.000000  0.000733  0.000307\n",
      "might       0.000000  0.000000  0.000321  0.000896\n",
      "the         0.000271  0.000277  0.000252  0.000320\n",
      "surface     0.000000  0.000000  0.000495  0.000491\n",
      "and         0.000199  0.000265  0.000248  0.000265\n",
      "any         0.000187  0.000062  0.000542  0.000161\n",
      "moon        0.000000  0.000411  0.000000  0.000494\n",
      "in          0.000201  0.000191  0.000240  0.000213\n",
      "deimos      0.000000  0.000000  0.000000  0.000720\n",
      "gifs        0.000000  0.000000  0.000506  0.000175\n",
      "where       0.000135  0.000000  0.000286  0.000234\n",
      "me          0.000094  0.000182  0.000294  0.000036\n",
      "especially  0.000387  0.000000  0.000000  0.000192\n",
      "but         0.000042  0.000169  0.000149  0.000096\n",
      "will        0.000063  0.000201  0.000027  0.000126\n",
      "do          0.000091  0.000088  0.000143  0.000079\n",
      "that        0.000113  0.000095  0.000091  0.000095\n",
      "prefer      0.000071  0.000000  0.000235  0.000080\n",
      "can         0.000066  0.000054  0.000123  0.000099\n",
      "order       0.000193  0.000077  0.000000  0.000066\n",
      "find        0.000079  0.000030  0.000090  0.000019\n",
      "interested  0.000020  0.000014  0.000021  0.000020\n",
      "can anyone tell me where i might find stereo image of planetary and planetary satellite surface gifs prefer but any will do i m especially interested in stereo of the surface of phobos deimos mar and the moon in that order thanks\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "            autos  religion  graphics     space\n",
      "42       0.000502  0.000000  0.001259  0.000000\n",
      "thought  0.000000  0.000000  0.000329  0.001421\n",
      "be       0.000363  0.000492  0.000388  0.000447\n",
      "the      0.000395  0.000404  0.000367  0.000466\n",
      "help     0.000000  0.000195  0.001159  0.000204\n",
      "chip     0.000000  0.000000  0.001302  0.000000\n",
      "really   0.000268  0.000739  0.000237  0.000000\n",
      "that     0.000329  0.000276  0.000265  0.000276\n",
      "on       0.000145  0.000152  0.000413  0.000366\n",
      "it       0.000265  0.000136  0.000365  0.000248\n",
      "could    0.000170  0.000000  0.000189  0.000428\n",
      "hear     0.000000  0.000303  0.000365  0.000097\n",
      "24       0.000000  0.000282  0.000454  0.000000\n",
      "pete     0.000000  0.000000  0.000699  0.000000\n",
      "intel    0.000000  0.000000  0.000699  0.000000\n",
      "reason   0.000000  0.000000  0.000699  0.000000\n",
      "proper   0.000000  0.000000  0.000699  0.000000\n",
      "egg      0.000000  0.000000  0.000699  0.000000\n",
      "stomp    0.000000  0.000000  0.000699  0.000000\n",
      "endian   0.000000  0.000000  0.000699  0.000000\n",
      "war      0.000000  0.000471  0.000173  0.000000\n",
      "value    0.000000  0.000469  0.000173  0.000000\n",
      "break    0.000000  0.000000  0.000220  0.000265\n",
      "side     0.000262  0.000000  0.000222  0.000000\n",
      "you      0.000164  0.000123  0.000107  0.000073\n",
      "but      0.000040  0.000164  0.000145  0.000094\n",
      "get      0.000082  0.000033  0.000144  0.000140\n",
      "write    0.000000  0.000066  0.000196  0.000099\n",
      "some     0.000027  0.000045  0.000169  0.000119\n",
      "their    0.000187  0.000101  0.000028  0.000032\n",
      "so       0.000074  0.000057  0.000052  0.000030\n",
      "out      0.000057  0.000053  0.000041  0.000025\n",
      "hear hear really i thought that the reason it be 42 be that it be really 24 but write a 42 so that on intel chip you could get the proper value pete help stomp out the endian war break some egg on their side\n",
      "==> predicted_topic = space, actual_topic = graphics \n",
      "\n",
      "             autos  religion  graphics     space\n",
      "see       0.000979  0.001563  0.000139  0.000000\n",
      "you       0.000655  0.000493  0.000427  0.000290\n",
      "need      0.000262  0.000000  0.000793  0.000403\n",
      "unless    0.001399  0.000000  0.000000  0.000000\n",
      "hmmmmmmm  0.001399  0.000000  0.000000  0.000000\n",
      "accident  0.001399  0.000000  0.000000  0.000000\n",
      "me        0.000184  0.000354  0.000572  0.000070\n",
      "won       0.000645  0.000395  0.000000  0.000000\n",
      "have      0.000298  0.000192  0.000193  0.000170\n",
      "let       0.000224  0.000309  0.000200  0.000000\n",
      "an        0.000264  0.000174  0.000181  0.000062\n",
      "more      0.000097  0.000104  0.000052  0.000061\n",
      "let me see unless you have an accident you won t need more hmmmmmmm\n",
      "==> predicted_topic = religion, actual_topic = autos \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "for         0.000740  0.000326  0.001915  0.000409\n",
      "motorcycle  0.001734  0.000000  0.000000  0.000000\n",
      "mandatory   0.001734  0.000000  0.000000  0.000000\n",
      "drl         0.001734  0.000000  0.000000  0.000000\n",
      "already     0.001038  0.000000  0.000446  0.000000\n",
      "be          0.000300  0.000407  0.000321  0.000369\n",
      "well        0.000068  0.000065  0.000040  0.000045\n",
      "well drl s be already mandatory for motorcycle\n",
      "==> predicted_topic = graphics, actual_topic = autos \n",
      "\n",
      "             autos  religion  graphics     space\n",
      "god       0.000000  0.003608  0.000000  0.000499\n",
      "profit    0.000000  0.000000  0.000000  0.001706\n",
      "the       0.000345  0.000353  0.000320  0.000407\n",
      "twilight  0.000000  0.000000  0.000000  0.000916\n",
      "blare     0.000000  0.000000  0.000000  0.000916\n",
      "bless     0.000000  0.000000  0.000000  0.000916\n",
      "cacs      0.000000  0.000000  0.000000  0.000916\n",
      "caste     0.000000  0.000000  0.000000  0.000916\n",
      "fraering  0.000000  0.000000  0.000000  0.000916\n",
      "freely    0.000000  0.000000  0.000000  0.000916\n",
      "usl       0.000000  0.000000  0.000000  0.000916\n",
      "pgf       0.000000  0.000000  0.000000  0.000916\n",
      "presence  0.000000  0.000000  0.000000  0.000916\n",
      "srl03     0.000000  0.000000  0.000000  0.000916\n",
      "edu       0.000099  0.000000  0.000348  0.000377\n",
      "be        0.000159  0.000215  0.000169  0.000195\n",
      "phil      0.000000  0.000257  0.000000  0.000430\n",
      "it        0.000174  0.000089  0.000239  0.000163\n",
      "and       0.000127  0.000169  0.000158  0.000169\n",
      "right     0.000276  0.000065  0.000032  0.000190\n",
      "in        0.000128  0.000122  0.000153  0.000136\n",
      "from      0.000060  0.000069  0.000096  0.000115\n",
      "even      0.000027  0.000153  0.000054  0.000087\n",
      "by        0.000067  0.000055  0.000074  0.000069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "may       0.000021  0.000090  0.000056  0.000031\n",
      "from phil g fraering pgf srl03 cacs usl edu right the profit caste be bless by god and may freely blare it presence in the even twilight\n",
      "==> predicted_topic = religion, actual_topic = space \n",
      "\n",
      "            autos  religion  graphics     space\n",
      "help     0.000000  0.000315  0.001873  0.000330\n",
      "the      0.000425  0.000436  0.000395  0.000502\n",
      "rest     0.000000  0.000886  0.000000  0.000424\n",
      "shirt    0.000000  0.001130  0.000000  0.000000\n",
      "night    0.000000  0.001130  0.000000  0.000000\n",
      "delete   0.000000  0.001130  0.000000  0.000000\n",
      "brown    0.000000  0.001130  0.000000  0.000000\n",
      "of       0.000141  0.000293  0.000209  0.000215\n",
      "out      0.000276  0.000259  0.000199  0.000120\n",
      "in       0.000158  0.000150  0.000188  0.000167\n",
      "can      0.000104  0.000085  0.000193  0.000155\n",
      "about    0.000169  0.000113  0.000081  0.000073\n",
      "anybody  0.000088  0.000057  0.000209  0.000041\n",
      "find     0.000124  0.000046  0.000141  0.000030\n",
      "rest delete can anybody out in a p h help out find out about the night of the brown shirt\n",
      "==> predicted_topic = graphics, actual_topic = religion \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "for         0.000710  0.000312  0.001838  0.000393\n",
      "new         0.001201  0.000000  0.000375  0.000582\n",
      "23          0.000685  0.000000  0.000000  0.001035\n",
      "thermostat  0.001664  0.000000  0.000000  0.000000\n",
      "sound       0.000415  0.000000  0.000242  0.000819\n",
      "you         0.000389  0.000293  0.000254  0.000173\n",
      "do          0.000211  0.000202  0.000331  0.000183\n",
      "that        0.000261  0.000219  0.000211  0.000219\n",
      "can         0.000153  0.000125  0.000284  0.000228\n",
      "say         0.000156  0.000370  0.000136  0.000080\n",
      "how         0.000102  0.000131  0.000086  0.000072\n",
      "again       0.000047  0.000044  0.000024  0.000033\n",
      "you can say that again how do 23 for a new thermostat sound\n",
      "==> predicted_topic = graphics, actual_topic = autos \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "he          0.000000  0.002411  0.000000  0.000602\n",
      "land        0.000000  0.000000  0.000000  0.001753\n",
      "mach        0.000000  0.000000  0.000000  0.001325\n",
      "flight      0.000000  0.000000  0.000000  0.001234\n",
      "head        0.000000  0.000000  0.000000  0.001234\n",
      "military    0.000000  0.000000  0.000000  0.001234\n",
      "of          0.000165  0.000344  0.000245  0.000252\n",
      "new         0.000478  0.000000  0.000149  0.000232\n",
      "could       0.000161  0.000000  0.000179  0.000405\n",
      "handle      0.000000  0.000000  0.000257  0.000474\n",
      "month       0.000000  0.000000  0.000260  0.000459\n",
      "belive      0.000000  0.000000  0.000000  0.000662\n",
      "boom        0.000000  0.000000  0.000000  0.000662\n",
      "decent      0.000000  0.000000  0.000000  0.000662\n",
      "direction   0.000000  0.000000  0.000000  0.000662\n",
      "fran        0.000000  0.000000  0.000000  0.000662\n",
      "aircraft    0.000000  0.000000  0.000000  0.000662\n",
      "25aircraft  0.000000  0.000000  0.000000  0.000662\n",
      "int         0.000000  0.000000  0.000000  0.000662\n",
      "25          0.000000  0.000000  0.000000  0.000662\n",
      "san         0.000000  0.000000  0.000000  0.000662\n",
      "odd         0.000000  0.000000  0.000000  0.000662\n",
      "supersonic  0.000000  0.000000  0.000000  0.000662\n",
      "super       0.000000  0.000000  0.000436  0.000165\n",
      "be          0.000115  0.000155  0.000123  0.000141\n",
      "the         0.000125  0.000128  0.000116  0.000147\n",
      "on          0.000069  0.000072  0.000196  0.000173\n",
      "ago         0.000053  0.000071  0.000048  0.000323\n",
      "it          0.000126  0.000064  0.000173  0.000118\n",
      "question    0.000086  0.000294  0.000043  0.000035\n",
      "east        0.000000  0.000222  0.000000  0.000232\n",
      "what        0.000105  0.000084  0.000104  0.000096\n",
      "hear        0.000000  0.000144  0.000173  0.000046\n",
      "that        0.000104  0.000087  0.000084  0.000087\n",
      "there       0.000113  0.000040  0.000062  0.000139\n",
      "some        0.000026  0.000043  0.000160  0.000113\n",
      "speed       0.000118  0.000000  0.000069  0.000051\n",
      "heard       0.000019  0.000062  0.000017  0.000067\n",
      "base        0.000015  0.000048  0.000024  0.000065\n",
      "over        0.000061  0.000018  0.000021  0.000019\n",
      "few         0.000024  0.000015  0.000029  0.000050\n",
      "the supersonic boom hear a few month ago over i belive san fran head east of what i heard some new super speed mach 25 aircraft what military base int he direction of flight be there that could handle a mach 25aircraft on it land decent odd question\n",
      "==> predicted_topic = religion, actual_topic = space \n",
      "\n",
      "                  autos  religion  graphics     space\n",
      "try            0.000000  0.000329  0.004991  0.001203\n",
      "he             0.000000  0.002812  0.000000  0.000703\n",
      "thought        0.000000  0.000000  0.000363  0.001570\n",
      "be             0.000268  0.000362  0.000286  0.000329\n",
      "to             0.000226  0.000336  0.000252  0.000285\n",
      "win            0.000000  0.000000  0.000000  0.000773\n",
      "consideration  0.000000  0.000000  0.000000  0.000773\n",
      "sam            0.000000  0.000000  0.000000  0.000773\n",
      "ross           0.000000  0.000000  0.000000  0.000773\n",
      "perot          0.000000  0.000000  0.000000  0.000773\n",
      "disappoint     0.000000  0.000000  0.000000  0.000773\n",
      "further        0.000000  0.000000  0.000000  0.000773\n",
      "matt           0.000000  0.000000  0.000000  0.000773\n",
      "likely         0.000000  0.000000  0.000000  0.000773\n",
      "walton         0.000000  0.000000  0.000000  0.000773\n",
      "gate           0.000000  0.000000  0.000000  0.000773\n",
      "after          0.000414  0.000091  0.000000  0.000187\n",
      "it             0.000147  0.000075  0.000202  0.000137\n",
      "bill           0.000000  0.000301  0.000000  0.000239\n",
      "third          0.000282  0.000000  0.000000  0.000250\n",
      "kid            0.000000  0.000256  0.000000  0.000274\n",
      "but            0.000045  0.000182  0.000160  0.000103\n",
      "my             0.000224  0.000105  0.000045  0.000086\n",
      "in             0.000108  0.000103  0.000129  0.000114\n",
      "first          0.000076  0.000175  0.000041  0.000029\n",
      "think          0.000107  0.000054  0.000065  0.000018\n",
      "more           0.000054  0.000057  0.000029  0.000034\n",
      "come           0.000024  0.000019  0.000050  0.000060\n",
      "my first thought be ross perot after further consideration i think he d be more likely to try to win it but come in a disappoint third try bill gate try sam walton s kid matt\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "         autos  religion  graphics     space\n",
      "to    0.000505  0.000751  0.000563  0.000636\n",
      "know  0.000402  0.000322  0.000555  0.000171\n",
      "just  0.000370  0.000188  0.000218  0.000366\n",
      "want  0.000256  0.000173  0.000163  0.000111\n",
      "i just want to know\n",
      "==> predicted_topic = religion, actual_topic = autos \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "it         0.000610  0.000313  0.000839  0.000571\n",
      "be         0.000278  0.000377  0.000297  0.000342\n",
      "gee        0.000272  0.000000  0.000000  0.000856\n",
      "look       0.000277  0.000024  0.000574  0.000237\n",
      "you        0.000376  0.000283  0.000245  0.000167\n",
      "any        0.000209  0.000069  0.000605  0.000180\n",
      "release    0.000469  0.000000  0.000342  0.000000\n",
      "tion       0.000804  0.000000  0.000000  0.000000\n",
      "radia      0.000804  0.000000  0.000000  0.000000\n",
      "confuse    0.000804  0.000000  0.000000  0.000000\n",
      "genus      0.000804  0.000000  0.000000  0.000000\n",
      "hole       0.000804  0.000000  0.000000  0.000000\n",
      "locate     0.000804  0.000000  0.000000  0.000000\n",
      "tor        0.000804  0.000000  0.000000  0.000000\n",
      "radiation  0.000804  0.000000  0.000000  0.000000\n",
      "radiator   0.000804  0.000000  0.000000  0.000000\n",
      "punch      0.000804  0.000000  0.000000  0.000000\n",
      "where      0.000150  0.000000  0.000319  0.000262\n",
      "really     0.000154  0.000425  0.000136  0.000000\n",
      "sound      0.000200  0.000000  0.000117  0.000396\n",
      "me         0.000106  0.000204  0.000328  0.000040\n",
      "like       0.000197  0.000106  0.000114  0.000235\n",
      "what       0.000128  0.000102  0.000127  0.000117\n",
      "will       0.000070  0.000225  0.000030  0.000140\n",
      "do         0.000102  0.000098  0.000160  0.000088\n",
      "when       0.000041  0.000172  0.000039  0.000083\n",
      "since      0.000074  0.000065  0.000114  0.000000\n",
      "make       0.000051  0.000059  0.000031  0.000028\n",
      "gee you really make me confuse what be radiator where be it locate what do it look like will it release any radiation since it sound like radia tion genus tor when you punch hole\n",
      "==> predicted_topic = space, actual_topic = autos \n",
      "\n",
      "             autos  religion  graphics     space\n",
      "file      0.000000  0.000000  0.003935  0.000982\n",
      "yo        0.000000  0.000000  0.000000  0.003023\n",
      "assume    0.000000  0.000000  0.000000  0.002742\n",
      "be        0.000421  0.000571  0.000450  0.000518\n",
      "every     0.000000  0.000000  0.000339  0.001199\n",
      "string    0.000000  0.000000  0.000000  0.001512\n",
      "sig       0.000000  0.000000  0.000000  0.001512\n",
      "mining    0.000000  0.000000  0.000000  0.001512\n",
      "you       0.000380  0.000286  0.000248  0.000168\n",
      "cash      0.000000  0.000000  0.000000  0.000812\n",
      "limit     0.000000  0.000000  0.000000  0.000812\n",
      "award     0.000000  0.000000  0.000000  0.000812\n",
      "to        0.000119  0.000177  0.000132  0.000149\n",
      "away      0.000306  0.000000  0.000000  0.000257\n",
      "own       0.000000  0.000261  0.000000  0.000299\n",
      "ok        0.000335  0.000100  0.000000  0.000083\n",
      "right     0.000245  0.000058  0.000028  0.000169\n",
      "get       0.000096  0.000038  0.000167  0.000163\n",
      "there     0.000138  0.000049  0.000076  0.000170\n",
      "can       0.000075  0.000061  0.000138  0.000111\n",
      "them      0.000018  0.000142  0.000078  0.000142\n",
      "would     0.000121  0.000045  0.000072  0.000125\n",
      "one       0.000088  0.000071  0.000041  0.000144\n",
      "like      0.000099  0.000053  0.000058  0.000119\n",
      "because   0.000066  0.000122  0.000000  0.000130\n",
      "don       0.000044  0.000086  0.000057  0.000043\n",
      "anything  0.000030  0.000019  0.000036  0.000088\n",
      "give      0.000056  0.000046  0.000044  0.000014\n",
      "time      0.000023  0.000025  0.000046  0.000045\n",
      "mine      0.000022  0.000020  0.000024  0.000054\n",
      "nice      0.000013  0.000011  0.000013  0.000013\n",
      "a cash award be ok a time limit would be nice you can t give away mining right assume there s anything to mine because you don t own them sig file be like string every yo yo s get one\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "           autos  religion  graphics     space\n",
      "get     0.000358  0.000143  0.000625  0.000611\n",
      "life    0.000587  0.000170  0.000000  0.000775\n",
      "people  0.000346  0.000350  0.000062  0.000173\n",
      "people get a life\n",
      "==> predicted_topic = space, actual_topic = autos \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "image       0.000000  0.000000  0.004100  0.000764\n",
      "site        0.000000  0.000000  0.001891  0.000881\n",
      "ftp         0.000000  0.000000  0.001515  0.000650\n",
      "the         0.000497  0.000509  0.000461  0.000587\n",
      "thanks      0.000325  0.000046  0.001126  0.000291\n",
      "phobos      0.000000  0.000000  0.000000  0.001639\n",
      "spacecraft  0.000000  0.000000  0.000000  0.001639\n",
      "russian     0.000000  0.000000  0.000000  0.001639\n",
      "house       0.000000  0.000000  0.000000  0.001639\n",
      "anyone      0.000321  0.000000  0.000897  0.000375\n",
      "any         0.000229  0.000076  0.000663  0.000197\n",
      "moon        0.000000  0.000502  0.000000  0.000605\n",
      "do          0.000223  0.000214  0.000350  0.000194\n",
      "fat         0.000000  0.000000  0.000000  0.000880\n",
      "ill         0.000000  0.000000  0.000000  0.000880\n",
      "martian     0.000000  0.000000  0.000000  0.000880\n",
      "mission     0.000000  0.000000  0.000000  0.000880\n",
      "if          0.000164  0.000165  0.000260  0.000191\n",
      "on          0.000091  0.000096  0.000260  0.000230\n",
      "of          0.000110  0.000228  0.000163  0.000167\n",
      "ago         0.000070  0.000094  0.000064  0.000429\n",
      "back        0.000245  0.000093  0.000000  0.000139\n",
      "an          0.000166  0.000110  0.000114  0.000039\n",
      "they        0.000139  0.000066  0.000048  0.000130\n",
      "send        0.000176  0.000000  0.000076  0.000120\n",
      "know        0.000102  0.000082  0.000141  0.000044\n",
      "year        0.000058  0.000032  0.000054  0.000144\n",
      "so          0.000093  0.000071  0.000066  0.000038\n",
      "re          0.000049  0.000092  0.000018  0.000102\n",
      "at          0.000047  0.000048  0.000077  0.000062\n",
      "few         0.000031  0.000021  0.000039  0.000066\n",
      "do the russian spacecraft s on the ill fat phobos mission a few year ago send back any image of the martian moon if so do anyone know if they re house at an ftp site thanks\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training = True\n",
    "tlabels = train_labels if training else test_labels\n",
    "tdoc_vectors = train_doc_vectors if training else test_doc_vectors\n",
    "misclassified = misclassified_train if training else misclassified_test\n",
    "\n",
    "for doc_index in tqdm(misclassified):\n",
    "    doc_vector = tdoc_vectors[doc_index]\n",
    "    doc_topic_word_distr, doc_topic = infer_topic(label_classes, doc_vector, topic_word_distr)\n",
    "    \n",
    "    xv = doc_topic_word_distr.iloc[np.where(doc_topic_word_distr.sum(1) > 0)]\n",
    "    print(xv.loc[xv.sum(1).sort_values(ascending=False).index])\n",
    "    print(train_docs[doc_index])\n",
    "    print(f\"==> predicted_topic = {doc_topic}, actual_topic = {label_classes[tlabels[doc_index]]} \\n\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuarcy = 100.00%, test_accuarcy = 62.88%, avg-accuarcy = 81.44%\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=.01)\n",
    "clf.fit(train_doc_vectors, train_labels)\n",
    "\n",
    "train_accuracy = clf.score(train_doc_vectors, train_labels)\n",
    "test_accuracy = clf.score(test_doc_vectors, test_labels)\n",
    "\n",
    "print(f\"training_accuarcy = {train_accuracy*100:.2f}%, test_accuarcy = {test_accuracy*100:.2f}%, avg-accuarcy = {.5*(train_accuracy + test_accuracy)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

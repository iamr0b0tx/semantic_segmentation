{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "from utils import *\n",
    "from word_network import WordNetwork\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.special import softmax\n",
    "from scipy.stats import entropy as calculate_entropy\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of samples needed\n",
    "randomize = False\n",
    "\n",
    "# retrieve dataset\n",
    "categories = ['rec.autos', 'talk.politics.mideast', 'alt.atheism', 'sci.space']\n",
    "\n",
    "docs = fetch_20newsgroups(subset='train', shuffle=randomize, remove=('headers', 'footers', 'quotes'), categories=categories)\n",
    "docs, old_labels, classes = docs.data, docs.target, docs.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5317633e81214e5ab8af17b2fef04d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "datasize = 100\n",
    "max_document_length = None\n",
    "\n",
    "index = -1\n",
    "train_docs, labels = [], []\n",
    "\n",
    "sizes = [0]*len(categories)\n",
    "\n",
    "with tqdm(total=len(categories)*datasize) as pbar:\n",
    "    while sum(sizes) != len(categories)*datasize:\n",
    "        index += 1\n",
    "        size_index = categories.index(classes[old_labels[index]])\n",
    "        \n",
    "        if sizes[size_index] == datasize:\n",
    "            continue\n",
    "        \n",
    "        doc = docs[index]\n",
    "        status, doc, word_count = clean_doc(doc, True)\n",
    "        \n",
    "        if (not status) or (max_document_length is not None and len(doc) > max_document_length):\n",
    "            continue\n",
    "        \n",
    "        labels.append(categories[size_index])\n",
    "        train_docs.append(doc)\n",
    "        sizes[size_index] += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: alt.atheism\n",
      "==================================================\n",
      "i think that domestication will change behavior to a large degree domesticate animal exhibit behavior not found in the wild i don t think that they can be view a good representative of the wild animal kingdom since they have be breed for thousand of year to produce certain behavior etc\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "print(f\"Topic: {labels[index]}\\n{'='*50}\\n{train_docs[index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 100, 100, 100]\n"
     ]
    }
   ],
   "source": [
    "print(sizes)\n",
    "assert min(sizes) == max(sizes) == datasize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 400 docs\n"
     ]
    }
   ],
   "source": [
    "print(f\"there are {len(train_docs)} docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_count is 9116\n"
     ]
    }
   ],
   "source": [
    "# initialize the count vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# fit it to dataset\n",
    "vectorizer.fit(train_docs)\n",
    "\n",
    "vocabulary = vectorizer.get_feature_names()\n",
    "print(\"word_count is\", len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Datatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 train_docs\n"
     ]
    }
   ],
   "source": [
    "# create doc count vectors\n",
    "train_doc_vectors = vectorizer.transform(train_docs).toarray()\n",
    "\n",
    "total_num_of_documents = len(train_doc_vectors)\n",
    "print(f\"{total_num_of_documents} train_docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word-Word Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9be9bbfa4194db5a205e11b7e4f24c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9116.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "word_word_co has shape (9116, 9116)\n"
     ]
    }
   ],
   "source": [
    "#reduce freq in doc to bin value of 1 or 0\n",
    "word_freq_in_doc = pd.DataFrame(train_doc_vectors, columns=vocabulary)\n",
    "word_word_co = pd.DataFrame(data=0.0, columns=vocabulary, index=vocabulary)\n",
    "\n",
    "word_doc_frequency = (word_freq_in_doc > 0).astype(int)\n",
    "probability = word_doc_frequency.sum(0) / len(train_doc_vectors)\n",
    "\n",
    "for word in tqdm(vocabulary):\n",
    "    pxy = word_doc_frequency[word_doc_frequency[word] == 1].sum(0) / total_num_of_documents\n",
    "    word_word_co[word] = pxy / (probability[word] * probability)\n",
    "    word_word_co[word][word_word_co[word] > 0] = word_word_co[word][word_word_co[word] > 0]**-1\n",
    "#     word_word_co[word] = np.nan_to_num(sigmoid(np.nan_to_num(np.log2(pxy / (probability[word] * probability)))))\n",
    "\n",
    "# word_word_co = (word_word_co.T / word_word_co.sum(1)).T\n",
    "print(f\"word_word_co has shape {word_word_co.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>000th</th>\n",
       "      <th>0029</th>\n",
       "      <th>007</th>\n",
       "      <th>01</th>\n",
       "      <th>011</th>\n",
       "      <th>0119</th>\n",
       "      <th>013</th>\n",
       "      <th>02</th>\n",
       "      <th>0245</th>\n",
       "      <th>...</th>\n",
       "      <th>zillion</th>\n",
       "      <th>zimogliad</th>\n",
       "      <th>ziona</th>\n",
       "      <th>zionism</th>\n",
       "      <th>zionist</th>\n",
       "      <th>zman</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>0.990471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.990471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.886843</td>\n",
       "      <td>0.990471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000th</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0029</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>007</th>\n",
       "      <td>0.990471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999141</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            000     000th      0029       007        01  011  0119  013   02  \\\n",
       "000    0.990471  0.000000  0.000000  0.990471  0.000000  0.0   0.0  0.0  0.0   \n",
       "000th  0.000000  0.999824  0.000000  0.000000  0.000000  0.0   0.0  0.0  0.0   \n",
       "0029   0.000000  0.000000  0.999824  0.000000  0.999141  0.0   0.0  0.0  0.0   \n",
       "007    0.990471  0.000000  0.000000  0.999824  0.000000  0.0   0.0  0.0  0.0   \n",
       "01     0.000000  0.000000  0.999141  0.000000  0.999141  0.0   0.0  0.0  0.0   \n",
       "\n",
       "           0245  ...  zillion  zimogliad  ziona  zionism   zionist      zman  \\\n",
       "000    0.000000  ...      0.0   0.990471    0.0      0.0  0.886843  0.990471   \n",
       "000th  0.000000  ...      0.0   0.000000    0.0      0.0  0.000000  0.000000   \n",
       "0029   0.000000  ...      0.0   0.000000    0.0      0.0  0.000000  0.000000   \n",
       "007    0.000000  ...      0.0   0.999824    0.0      0.0  0.000000  0.000000   \n",
       "01     0.999141  ...      0.0   0.000000    0.0      0.0  0.000000  0.000000   \n",
       "\n",
       "       zone  zoo  zulu  zur  \n",
       "000     0.0  0.0   0.0  0.0  \n",
       "000th   0.0  0.0   0.0  0.0  \n",
       "0029    0.0  0.0   0.0  0.0  \n",
       "007     0.0  0.0   0.0  0.0  \n",
       "01      0.0  0.0   0.0  0.0  \n",
       "\n",
       "[5 rows x 9116 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_word_co.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Word Trust ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_entropy = pd.DataFrame(data=np.nan_to_num(calculate_entropy(word_word_co.T, base=2)), columns=[0], index=vocabulary)[0]\n",
    "word_trust_factor = pd.DataFrame(data=gaussian2(word_entropy), columns=[0], index=vocabulary)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.3890560989306495"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.e**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"ironic\", \"humanist\", \"45th\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.014059707742938446, 0.0952955920769799, 0.4426707245123334)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_word_co.loc[\"ironic\"].std(), word_word_co.loc[\"the\"].std(), word_word_co.loc[\"program\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ironic      0.368679\n",
       "humanist    0.206846\n",
       "45th        0.135344\n",
       "birthday    0.135344\n",
       "drl         0.062149\n",
       "              ...   \n",
       "to          0.000002\n",
       "and         0.000002\n",
       "of          0.000002\n",
       "the         0.000002\n",
       "be          0.000002\n",
       "Name: 0, Length: 9116, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_trust_factor.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = [\"ironic\", \"the\", \"algorithm\", \"program\", \"and\"]\n",
    "# words = np.array(vocabulary)[np.random.randint(len(vocabulary), size=5)]\n",
    "\n",
    "fig = plt.figure(figsize=(10,3))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "ax1.set_title(f\"Word Trust factor\")\n",
    "ax1.bar(words, (word_word_co.std(1))[words])\n",
    "\n",
    "ax2.set_title(f\"Word Frequency Normalized\")\n",
    "ax2.bar(words, probability[words])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe word_word_co ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "govt against ['look', 'the', 'algorithm', 'program', 'and']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "word = \"govt\"\n",
    "\n",
    "fig = plt.figure(figsize=(10,3))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "print(f\"=== Ploting {word} against {words} ===\")\n",
    "\n",
    "ax1.set_title(f\"word_word_co\")\n",
    "ax1.bar(words, word_word_co.loc[word][words])\n",
    "\n",
    "ax2.set_title(f\"updated word_word_co\")\n",
    "ax2.bar(words, (word_word_co * word_trust_factor).loc[word][words])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>000th</th>\n",
       "      <th>0029</th>\n",
       "      <th>007</th>\n",
       "      <th>01</th>\n",
       "      <th>011</th>\n",
       "      <th>0119</th>\n",
       "      <th>013</th>\n",
       "      <th>02</th>\n",
       "      <th>0245</th>\n",
       "      <th>...</th>\n",
       "      <th>zillion</th>\n",
       "      <th>zimogliad</th>\n",
       "      <th>ziona</th>\n",
       "      <th>zionism</th>\n",
       "      <th>zionist</th>\n",
       "      <th>zman</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>look</th>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algorithm</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>program</th>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                000     000th      0029       007        01       011  \\\n",
       "look       0.000009  0.000000  0.000195  0.000034  0.000039  0.000000   \n",
       "the        0.000005  0.000839  0.000112  0.000020  0.000024  0.000752   \n",
       "algorithm  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "program    0.000009  0.000000  0.000203  0.000000  0.000042  0.000000   \n",
       "and        0.000006  0.000944  0.000126  0.000022  0.000027  0.000846   \n",
       "\n",
       "               0119       013        02      0245  ...   zillion  zimogliad  \\\n",
       "look       0.000000  0.000081  0.000000  0.000111  ...  0.000320   0.000034   \n",
       "the        0.000752  0.000047  0.000709  0.000064  ...  0.000184   0.000020   \n",
       "algorithm  0.000000  0.000000  0.000000  0.000000  ...  0.000000   0.000000   \n",
       "program    0.000000  0.000000  0.000000  0.000116  ...  0.000000   0.000000   \n",
       "and        0.000846  0.000053  0.000798  0.000072  ...  0.000207   0.000022   \n",
       "\n",
       "              ziona   zionism   zionist      zman      zone       zoo  \\\n",
       "look       0.000000  0.000153  0.000045  0.000144  0.000000  0.000000   \n",
       "the        0.000242  0.000089  0.000029  0.000083  0.000045  0.000743   \n",
       "algorithm  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "program    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "and        0.000273  0.000100  0.000032  0.000093  0.000051  0.000835   \n",
       "\n",
       "               zulu       zur  \n",
       "look       0.000036  0.000000  \n",
       "the        0.000021  0.000603  \n",
       "algorithm  0.000000  0.000000  \n",
       "program    0.000037  0.000000  \n",
       "and        0.000023  0.000678  \n",
       "\n",
       "[5 rows x 9116 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_word_co.loc[words] * word_trust_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tz           0.029944\n",
       "spencer      0.029944\n",
       "dependent    0.029944\n",
       "vnet         0.029944\n",
       "ureply       0.029944\n",
       "Name: software, dtype: float64"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_word_co.loc[word].sort_values(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update word_word_co with word_word_co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequency_norm = ((word_doc_freqency > 0).sum(0) / len(train_doc_vectors))\n",
    "doc_word_distr = word_frequency_norm * (np.e**word_trust_factor)\n",
    "doc_word_distr = (doc_word_distr.T / doc_word_distr.sum(1)).T.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "directly     1.0\n",
       "of           1.0\n",
       "didn         1.0\n",
       "10           1.0\n",
       "maybe        1.0\n",
       "his          1.0\n",
       "missile      1.0\n",
       "get          1.0\n",
       "kill         1.0\n",
       "operation    1.0\n",
       "Name: 13, dtype: float64"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_index = 13\n",
    "word_doc_freqency.iloc[doc_index].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "desintegrated    0.038808\n",
       "surgical         0.038461\n",
       "directly         0.038448\n",
       "missile          0.038448\n",
       "operation        0.038447\n",
       "body             0.038447\n",
       "hit              0.038447\n",
       "destroy          0.038447\n",
       "someone          0.038447\n",
       "house            0.038447\n",
       "Name: 13, dtype: float64"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_word_distr.iloc[doc_index].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "talk.politics.mideast maybe the missile didn t hit directly such that his body get desintegrated of course destroy 10 house to kill someone be not a surgical operation or be it\n"
     ]
    }
   ],
   "source": [
    "print(labels[doc_index], train_docs[doc_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>000th</th>\n",
       "      <th>0029</th>\n",
       "      <th>007</th>\n",
       "      <th>01</th>\n",
       "      <th>011</th>\n",
       "      <th>0119</th>\n",
       "      <th>013</th>\n",
       "      <th>02</th>\n",
       "      <th>0245</th>\n",
       "      <th>...</th>\n",
       "      <th>zillion</th>\n",
       "      <th>zimogliad</th>\n",
       "      <th>ziona</th>\n",
       "      <th>zionism</th>\n",
       "      <th>zionist</th>\n",
       "      <th>zman</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  000th  0029  007   01  011  0119  013   02  0245  ...  zillion  \\\n",
       "0  0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  ...      0.0   \n",
       "1  0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  ...      0.0   \n",
       "2  0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  ...      0.0   \n",
       "3  0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  ...      0.0   \n",
       "4  0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  ...      0.0   \n",
       "\n",
       "   zimogliad  ziona  zionism  zionist  zman  zone  zoo  zulu  zur  \n",
       "0        0.0    0.0      0.0      0.0   0.0   0.0  0.0   0.0  0.0  \n",
       "1        0.0    0.0      0.0      0.0   0.0   0.0  0.0   0.0  0.0  \n",
       "2        0.0    0.0      0.0      0.0   0.0   0.0  0.0   0.0  0.0  \n",
       "3        0.0    0.0      0.0      0.0   0.0   0.0  0.0   0.0  0.0  \n",
       "4        0.0    0.0      0.0      0.0   0.0   0.0  0.0   0.0  0.0  \n",
       "\n",
       "[5 rows x 9116 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_word_distr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['breed', 'domesticate', 'domestication', 'wild', 'exhibit']\n"
     ]
    }
   ],
   "source": [
    "for di in range(len(doc_word_distr.index)):\n",
    "    print(doc_word_distr.iloc[di].sort_values(ascending=False).head(5).index.to_list())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ironic             0.000545\n",
       "humanist           0.000197\n",
       "birthday           0.000181\n",
       "45th               0.000181\n",
       "drl                0.000023\n",
       "nonononnononono    0.000010\n",
       "nile               0.000010\n",
       "incredibly         0.000008\n",
       "huh                0.000008\n",
       "photosynthetic     0.000007\n",
       "dtype: float64"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(doc_word_distr.mean(0) * word_trust_factor).sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Latent partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distr_params has shape (400, 4)\n"
     ]
    }
   ],
   "source": [
    "# reduction = None\n",
    "reduction = \"pca\"\n",
    "# reduction = \"normal\"\n",
    "\n",
    "if reduction is None:\n",
    "    columns = doc_word_distr.columns\n",
    "    param_values = doc_word_distr.values\n",
    "\n",
    "if reduction == \"pca\":\n",
    "    num_of_components = 4\n",
    "    columns = list(range(num_of_components))\n",
    "    \n",
    "    pca = PCA(n_components=num_of_components)\n",
    "    param_values = pca.fit_transform(doc_word_distr)\n",
    "\n",
    "if reduction == \"normal\":\n",
    "    columns = [\"mean\", \"std\"]\n",
    "    param_values = np.array([doc_word_distr.mean(1), doc_word_distr.std(1)]).T\n",
    "    \n",
    "distr_params = pd.DataFrame(data=param_values, columns=columns, index=list(range(len(doc_word_distr))))\n",
    "print(f\"distr_params has shape {distr_params.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.004163</td>\n",
       "      <td>-0.007101</td>\n",
       "      <td>-0.006560</td>\n",
       "      <td>-0.014602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.003256</td>\n",
       "      <td>-0.005113</td>\n",
       "      <td>-0.003928</td>\n",
       "      <td>0.002366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.003288</td>\n",
       "      <td>-0.004822</td>\n",
       "      <td>-0.004353</td>\n",
       "      <td>-0.010058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.001184</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.003075</td>\n",
       "      <td>0.003528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.002784</td>\n",
       "      <td>-0.003852</td>\n",
       "      <td>-0.002882</td>\n",
       "      <td>0.002375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "0 -0.004163 -0.007101 -0.006560 -0.014602\n",
       "1 -0.003256 -0.005113 -0.003928  0.002366\n",
       "2 -0.003288 -0.004822 -0.004353 -0.010058\n",
       "3 -0.001184  0.001934  0.003075  0.003528\n",
       "4 -0.002784 -0.003852 -0.002882  0.002375"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distr_params.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Kmeans MiniBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a902a23de484566a9bea779530b837d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=256.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num_of_topics = 4\n",
    "# kmeans_model = MiniBatchKMeans(n_clusters=num_of_topics, random_state=0)\n",
    "\n",
    "# num_of_iterations = 256\n",
    "\n",
    "# num_of_samples = len(distr_params)\n",
    "# batch_size = num_of_samples // 2\n",
    "\n",
    "# for i in tqdm(range(num_of_iterations)):\n",
    "#     indices = np.random.randint(num_of_samples, size=batch_size)\n",
    "    \n",
    "#     kmeans_model.partial_fit(distr_params.iloc[indices])\n",
    "\n",
    "# kmeans_model.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_model = KMeans(n_clusters=num_of_topics, random_state=0).fit(distr_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist has shape (400, 4), predicted_labels has shape (400,)\n"
     ]
    }
   ],
   "source": [
    "dist = kmeans_model.transform(distr_params)\n",
    "predicted_labels = kmeans_model.predict(distr_params)\n",
    "\n",
    "# wtf = normalize(dist, norm=\"l1\", axis=1)\n",
    "# wtf = normalize(wtf, norm=\"l1\", axis=0)\n",
    "\n",
    "wtf = gaussian(dist / dist.max(0))\n",
    "\n",
    "print(f\"dist has shape {dist.shape}, predicted_labels has shape {predicted_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99928197, 0.81438448, 0.99993749, 0.80319777],\n",
       "       [0.99980747, 0.81610347, 0.99989714, 0.81445361],\n",
       "       [0.99954305, 0.81598989, 0.99999414, 0.80625491],\n",
       "       ...,\n",
       "       [0.9999297 , 0.81812275, 0.99983119, 0.81467086],\n",
       "       [0.99923891, 0.8136871 , 0.99992277, 0.80278813],\n",
       "       [0.99986256, 0.81784861, 0.99990108, 0.81408237]])"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 225, 0: 172, 3: 1, 1: 2})"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "voc_array = np.array(vocabulary)\n",
    "\n",
    "def get_top2(topic):\n",
    "    indices = dist[:, topic].argsort()\n",
    "    print(labels[indices[:10]])\n",
    "\n",
    "def get_top2(topic):\n",
    "    indices = np.where(predicted_labels == topic)[0]\n",
    "    print((doc_word_distr.T * wtf[:, topic]).T.iloc[indices].mean(0).sort_values(ascending=False).head(10))\n",
    "\n",
    "def get_top2(topic):\n",
    "    indices = np.where(predicted_labels == topic)[0]\n",
    "    print(((doc_word_distr.T * wtf[:, topic]).T.iloc[indices].sum(0) * word_trust_factor).sort_values(ascending=False).head(10))\n",
    "    \n",
    "def get_top(topic):\n",
    "    indices = np.where(predicted_labels == topic)[0]\n",
    "    count = Counter()\n",
    "    for index in indices:\n",
    "        count[labels[index]] += wtf[index, topic]\n",
    "        \n",
    "    print(Counter(labels[indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be      0.002779\n",
      "the     0.002487\n",
      "to      0.001867\n",
      "of      0.001824\n",
      "and     0.001515\n",
      "you     0.001502\n",
      "that    0.001450\n",
      "have    0.001280\n",
      "it      0.001274\n",
      "in      0.001218\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "get_top(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zur            0.0\n",
      "enjoy          0.0\n",
      "ensure         0.0\n",
      "enrage         0.0\n",
      "enough         0.0\n",
      "enormous       0.0\n",
      "ennumerated    0.0\n",
      "enlighten      0.0\n",
      "enhancement    0.0\n",
      "entail         0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "get_top(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offender         5.450304e-11\n",
      "cozy             5.450304e-11\n",
      "theodore         5.450304e-11\n",
      "kkkaldis         5.450304e-11\n",
      "doublespeak      5.450304e-11\n",
      "contradictory    5.432806e-11\n",
      "disgust          5.431219e-11\n",
      "harsh            5.430888e-11\n",
      "justification    5.430882e-11\n",
      "punishment       5.430876e-11\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "get_top(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deletion       1.209994e-08\n",
      "zur            0.000000e+00\n",
      "enlighten      0.000000e+00\n",
      "ensures        0.000000e+00\n",
      "ensure         0.000000e+00\n",
      "enrage         0.000000e+00\n",
      "enough         0.000000e+00\n",
      "enormous       0.000000e+00\n",
      "ennumerated    0.000000e+00\n",
      "enjoy          0.000000e+00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "get_top(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Topic model with Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54029e101f0241e6bd32fc3234049bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=268.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> train-accuracy is 90.67%, 25 misclassified\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "misclassified_train = []\n",
    "print(\"Evaluating Topic Model...\")\n",
    "\n",
    "for doc_index in tqdm(range(len(train_labels))):\n",
    "    doc_vector = train_doc_vectors[doc_index]\n",
    "    \n",
    "    doc_topic_word_distr, doc_topic = infer_topic(label_classes, doc_vector, topic_word_distr)\n",
    "    score += int(doc_topic == label_classes[train_labels[doc_index]])\n",
    "    \n",
    "    if doc_topic != label_classes[train_labels[doc_index]]:\n",
    "        misclassified_train.append(doc_index)\n",
    "    \n",
    "train_accuracy = score / (doc_index + 1)\n",
    "print(f\"==> train-accuracy is {train_accuracy*100:.2f}%, {len(misclassified_train)} misclassified\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Topic Model with test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c629d68d6d47ce9cd469637fff64ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=132.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> test-accuracy is 54.55%, avg-accuarcy = 72.61%, 60 misclassified\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "print(\"Evaluating Topic Model...\")\n",
    "\n",
    "misclassified_test = []\n",
    "for doc_index in tqdm(range(len(test_labels))):\n",
    "    doc_vector = test_doc_vectors[doc_index]\n",
    "    \n",
    "    doc_topic_word_distr, doc_topic = infer_topic(label_classes, doc_vector, topic_word_distr)\n",
    "    score += int(doc_topic == label_classes[test_labels[doc_index]])\n",
    "    \n",
    "    if doc_topic != label_classes[test_labels[doc_index]]:\n",
    "        misclassified_test.append(doc_index)\n",
    "    \n",
    "\n",
    "test_accuracy = score / (doc_index + 1)\n",
    "print(f\"==> test-accuracy is {test_accuracy*100:.2f}%, avg-accuarcy = {.5*(train_accuracy + test_accuracy)*100:.2f}%, {len(misclassified_test)} misclassified\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating Misclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac0825f5c8984e1caeb6d5393e151907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              autos  religion  graphics     space\n",
      "ve         0.000334  0.000191  0.001622  0.000000\n",
      "sense      0.000426  0.001182  0.000000  0.000000\n",
      "maybe      0.000000  0.000906  0.000605  0.000000\n",
      "shot       0.000000  0.000677  0.000000  0.000371\n",
      "that       0.000299  0.000251  0.000241  0.000251\n",
      "kind       0.000000  0.000394  0.000588  0.000000\n",
      "cheap      0.000000  0.000954  0.000000  0.000000\n",
      "embarrass  0.000000  0.000954  0.000000  0.000000\n",
      "fundies    0.000000  0.000954  0.000000  0.000000\n",
      "josh       0.000000  0.000954  0.000000  0.000000\n",
      "mood       0.000000  0.000954  0.000000  0.000000\n",
      "mcdowell   0.000000  0.000954  0.000000  0.000000\n",
      "be         0.000165  0.000224  0.000176  0.000203\n",
      "of         0.000119  0.000248  0.000176  0.000181\n",
      "to         0.000140  0.000208  0.000155  0.000176\n",
      "okay       0.000000  0.000375  0.000293  0.000000\n",
      "except     0.000307  0.000350  0.000000  0.000000\n",
      "who        0.000148  0.000316  0.000030  0.000111\n",
      "but        0.000055  0.000224  0.000197  0.000128\n",
      "have       0.000203  0.000131  0.000132  0.000116\n",
      "enough     0.000163  0.000133  0.000000  0.000267\n",
      "in         0.000133  0.000127  0.000159  0.000141\n",
      "know       0.000111  0.000089  0.000153  0.000047\n",
      "by         0.000070  0.000057  0.000077  0.000072\n",
      "few        0.000034  0.000022  0.000042  0.000071\n",
      "true       0.000036  0.000038  0.000019  0.000019\n",
      "true except that i ve know few fundies who have enough sense to be embarrass by josh mcdowell okay maybe a cheap shot but i m in that kind of mood\n",
      "==> predicted_topic = graphics, actual_topic = religion \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "he          0.000000  0.003337  0.000000  0.000834\n",
      "the         0.000517  0.000530  0.000481  0.000611\n",
      "it          0.000522  0.000267  0.000718  0.000488\n",
      "71          0.000000  0.000000  0.000000  0.001833\n",
      "until       0.000000  0.000000  0.000000  0.000917\n",
      "dubbed      0.000000  0.000000  0.000000  0.000917\n",
      "fwiw        0.000000  0.000000  0.000000  0.000917\n",
      "lbj         0.000000  0.000000  0.000000  0.000917\n",
      "mippselled  0.000000  0.000000  0.000000  0.000917\n",
      "page        0.000000  0.000000  0.000000  0.000917\n",
      "sic         0.000000  0.000000  0.000000  0.000917\n",
      "sr          0.000000  0.000000  0.000000  0.000917\n",
      "be          0.000159  0.000215  0.000170  0.000195\n",
      "doug        0.000000  0.000000  0.000438  0.000255\n",
      "who         0.000142  0.000304  0.000029  0.000107\n",
      "also        0.000165  0.000166  0.000000  0.000127\n",
      "one         0.000100  0.000080  0.000046  0.000163\n",
      "he s also the one who dubbed it the sr 71 it be the r 71 until lbj mippselled sic it fwiw doug page\n",
      "==> predicted_topic = religion, actual_topic = space \n",
      "\n",
      "            autos  religion  graphics     space\n",
      "file     0.000000  0.000000  0.005275  0.001317\n",
      "yo       0.000000  0.000000  0.000000  0.004052\n",
      "every    0.000000  0.000000  0.000454  0.001607\n",
      "string   0.000000  0.000000  0.000000  0.002026\n",
      "sig      0.000000  0.000000  0.000000  0.002026\n",
      "look     0.000375  0.000033  0.000778  0.000320\n",
      "publish  0.000000  0.000000  0.000000  0.001088\n",
      "plenty   0.000000  0.000000  0.000000  0.001088\n",
      "kiddo    0.000000  0.000000  0.000000  0.001088\n",
      "be       0.000188  0.000255  0.000201  0.000232\n",
      "to       0.000159  0.000237  0.000177  0.000200\n",
      "you      0.000255  0.000192  0.000166  0.000113\n",
      "have     0.000232  0.000150  0.000150  0.000132\n",
      "get      0.000128  0.000051  0.000223  0.000219\n",
      "one      0.000118  0.000095  0.000055  0.000193\n",
      "like     0.000133  0.000072  0.000077  0.000159\n",
      "just     0.000116  0.000059  0.000069  0.000115\n",
      "we       0.000031  0.000075  0.000074  0.000174\n",
      "we publish plenty kiddo you just have to look sig file be like string every yo yo s get one\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "human      0.000000  0.002433  0.000000  0.000381\n",
      "be         0.000572  0.000774  0.000611  0.000703\n",
      "45g        0.000000  0.000000  0.000000  0.001651\n",
      "sure       0.000000  0.000000  0.000505  0.000851\n",
      "lan        0.000000  0.000000  0.000000  0.000826\n",
      "8g         0.000000  0.000000  0.000000  0.000826\n",
      "9g         0.000000  0.000000  0.000000  0.000826\n",
      "blackout   0.000000  0.000000  0.000000  0.000826\n",
      "clarify    0.000000  0.000000  0.000000  0.000826\n",
      "dive       0.000000  0.000000  0.000000  0.000826\n",
      "pilot      0.000000  0.000000  0.000000  0.000826\n",
      "exceed     0.000000  0.000000  0.000000  0.000826\n",
      "the        0.000155  0.000159  0.000144  0.000183\n",
      "of         0.000103  0.000214  0.000153  0.000157\n",
      "to         0.000121  0.000180  0.000135  0.000152\n",
      "number     0.000048  0.000103  0.000372  0.000053\n",
      "tolerance  0.000000  0.000274  0.000000  0.000293\n",
      "far        0.000276  0.000000  0.000000  0.000290\n",
      "you        0.000193  0.000146  0.000126  0.000086\n",
      "right      0.000249  0.000059  0.000029  0.000172\n",
      "in         0.000115  0.000110  0.000138  0.000122\n",
      "please     0.000023  0.000193  0.000170  0.000090\n",
      "that       0.000130  0.000108  0.000104  0.000109\n",
      "this       0.000081  0.000102  0.000093  0.000119\n",
      "would      0.000123  0.000046  0.000073  0.000128\n",
      "know       0.000096  0.000077  0.000133  0.000041\n",
      "seem       0.000000  0.000145  0.000070  0.000077\n",
      "anybody    0.000064  0.000041  0.000153  0.000030\n",
      "out        0.000067  0.000063  0.000048  0.000029\n",
      "be you sure 45g be the right number a far a i know pilot be blackout in dive that exceed 8g 9g 45g seem to be out of human tolerance would anybody clarify this please lan\n",
      "==> predicted_topic = religion, actual_topic = space \n",
      "\n",
      "                 autos  religion  graphics     space\n",
      "for           0.000393  0.000173  0.001017  0.000217\n",
      "day           0.000000  0.000588  0.000000  0.000864\n",
      "any           0.000239  0.000079  0.000694  0.000206\n",
      "do            0.000234  0.000224  0.000367  0.000203\n",
      "lizard        0.000000  0.000921  0.000000  0.000000\n",
      "thelema       0.000000  0.000921  0.000000  0.000000\n",
      "sf            0.000000  0.000921  0.000000  0.000000\n",
      "organization  0.000000  0.000921  0.000000  0.000000\n",
      "official      0.000000  0.000921  0.000000  0.000000\n",
      "lodge         0.000000  0.000921  0.000000  0.000000\n",
      "bay           0.000000  0.000921  0.000000  0.000000\n",
      "an            0.000347  0.000229  0.000239  0.000082\n",
      "the           0.000173  0.000178  0.000161  0.000205\n",
      "of            0.000115  0.000239  0.000170  0.000175\n",
      "93            0.000272  0.000388  0.000000  0.000000\n",
      "have          0.000196  0.000127  0.000127  0.000112\n",
      "address       0.000144  0.000178  0.000215  0.000000\n",
      "these         0.000140  0.000238  0.000097  0.000000\n",
      "this          0.000090  0.000114  0.000104  0.000133\n",
      "would         0.000137  0.000051  0.000081  0.000142\n",
      "mail          0.000026  0.000037  0.000130  0.000075\n",
      "area          0.000063  0.000075  0.000000  0.000063\n",
      "do this organization have an official e mail address these day an address for any of the sf bay area lodge e g thelema would do 93 a lizard\n",
      "==> predicted_topic = graphics, actual_topic = religion \n",
      "\n",
      "                 autos  religion  graphics     space\n",
      "for           0.000452  0.000199  0.001170  0.000250\n",
      "seriously     0.000890  0.000389  0.000000  0.000000\n",
      "4000          0.001060  0.000000  0.000000  0.000000\n",
      "account       0.001060  0.000000  0.000000  0.000000\n",
      "depreciation  0.001060  0.000000  0.000000  0.000000\n",
      "taurus        0.001060  0.000000  0.000000  0.000000\n",
      "repair        0.001060  0.000000  0.000000  0.000000\n",
      "rack          0.001060  0.000000  0.000000  0.000000\n",
      "doubt         0.001060  0.000000  0.000000  0.000000\n",
      "extra         0.001060  0.000000  0.000000  0.000000\n",
      "cost          0.000124  0.000000  0.000194  0.000477\n",
      "you           0.000248  0.000187  0.000162  0.000110\n",
      "in            0.000148  0.000141  0.000177  0.000157\n",
      "do            0.000135  0.000129  0.000211  0.000117\n",
      "that          0.000166  0.000139  0.000134  0.000139\n",
      "an            0.000200  0.000132  0.000137  0.000047\n",
      "would         0.000158  0.000058  0.000094  0.000164\n",
      "up            0.000212  0.000084  0.000034  0.000066\n",
      "year          0.000070  0.000039  0.000065  0.000173\n",
      "over          0.000097  0.000028  0.000034  0.000030\n",
      "do you account for depreciation i seriously doubt that a taurus would rack up an extra 4000 in repair cost over 5 year\n",
      "==> predicted_topic = graphics, actual_topic = autos \n",
      "\n",
      "            autos  religion  graphics     space\n",
      "be       0.000507  0.000687  0.000542  0.000624\n",
      "brought  0.000595  0.000441  0.000000  0.000000\n",
      "you      0.000343  0.000258  0.000223  0.000152\n",
      "ok       0.000604  0.000181  0.000000  0.000151\n",
      "right    0.000442  0.000104  0.000051  0.000304\n",
      "john     0.000433  0.000281  0.000111  0.000000\n",
      "that     0.000230  0.000193  0.000185  0.000193\n",
      "if       0.000137  0.000137  0.000217  0.000159\n",
      "up       0.000293  0.000116  0.000047  0.000091\n",
      "name     0.000191  0.000195  0.000038  0.000079\n",
      "so       0.000155  0.000119  0.000109  0.000064\n",
      "good     0.000121  0.000086  0.000137  0.000031\n",
      "few      0.000052  0.000034  0.000065  0.000110\n",
      "example  0.000051  0.000023  0.000054  0.000028\n",
      "ok if you be so right name a few good example that be brought up john\n",
      "==> predicted_topic = religion, actual_topic = autos \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "thanks      0.000873  0.000124  0.003023  0.000781\n",
      "help        0.000000  0.000330  0.001958  0.000345\n",
      "for         0.000504  0.000222  0.001304  0.000279\n",
      "several     0.000000  0.000000  0.001029  0.000786\n",
      "it          0.000448  0.000230  0.000617  0.000419\n",
      "via         0.000000  0.000000  0.001130  0.000575\n",
      "found       0.000000  0.000675  0.000000  0.000509\n",
      "be          0.000205  0.000277  0.000219  0.000251\n",
      "offer       0.000335  0.000000  0.000000  0.000541\n",
      "contact     0.000000  0.000417  0.000000  0.000393\n",
      "and         0.000163  0.000217  0.000204  0.000217\n",
      "will        0.000103  0.000330  0.000044  0.000206\n",
      "get         0.000139  0.000055  0.000243  0.000237\n",
      "those       0.000058  0.000402  0.000111  0.000089\n",
      "people      0.000134  0.000136  0.000024  0.000067\n",
      "mail        0.000033  0.000047  0.000167  0.000096\n",
      "appreciate  0.000023  0.000073  0.000105  0.000042\n",
      "again       0.000033  0.000031  0.000017  0.000023\n",
      "found it thanks i get several offer for help i appreciate it and will be contact those people via e mail thanks again\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "moon        0.000000  0.001101  0.000000  0.001325\n",
      "the         0.000544  0.000558  0.000506  0.000643\n",
      "of          0.000240  0.000501  0.000356  0.000367\n",
      "have        0.000411  0.000265  0.000267  0.000234\n",
      "worship     0.000000  0.000964  0.000000  0.000000\n",
      "element     0.000000  0.000964  0.000000  0.000000\n",
      "sabbath     0.000000  0.000964  0.000000  0.000000\n",
      "phase       0.000000  0.000964  0.000000  0.000000\n",
      "originally  0.000000  0.000964  0.000000  0.000000\n",
      "nature      0.000000  0.000964  0.000000  0.000000\n",
      "egyptian    0.000000  0.000964  0.000000  0.000000\n",
      "be          0.000167  0.000226  0.000178  0.000205\n",
      "determine   0.000000  0.000321  0.000341  0.000000\n",
      "and         0.000133  0.000177  0.000166  0.000177\n",
      "in          0.000135  0.000128  0.000161  0.000143\n",
      "that        0.000151  0.000127  0.000122  0.000127\n",
      "early       0.000150  0.000092  0.000000  0.000077\n",
      "by          0.000071  0.000058  0.000078  0.000073\n",
      "heard       0.000028  0.000091  0.000024  0.000098\n",
      "stuff       0.000035  0.000042  0.000019  0.000016\n",
      "i have heard that the sabbath be originally determine by the phase of the moon and have element of moon worship early stuff egyptian in nature\n",
      "==> predicted_topic = space, actual_topic = religion \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "file       0.000000  0.000000  0.005253  0.001311\n",
      "every      0.000000  0.000000  0.000452  0.001601\n",
      "feel       0.000000  0.000000  0.000000  0.002018\n",
      "be         0.000375  0.000508  0.000401  0.000461\n",
      "day        0.000000  0.000692  0.000000  0.001016\n",
      "could      0.000264  0.000000  0.000293  0.000662\n",
      "wonder     0.000000  0.000000  0.000714  0.000434\n",
      "monthly    0.000000  0.000000  0.000000  0.001083\n",
      "quarterly  0.000000  0.000000  0.000000  0.001083\n",
      "bloat      0.000000  0.000000  0.000000  0.001083\n",
      "28         0.000000  0.000000  0.000000  0.001083\n",
      "post       0.000401  0.000129  0.000000  0.000323\n",
      "the        0.000204  0.000209  0.000189  0.000241\n",
      "rather     0.000000  0.000128  0.000169  0.000380\n",
      "get        0.000128  0.000051  0.000223  0.000218\n",
      "this       0.000106  0.000134  0.000122  0.000157\n",
      "if         0.000101  0.000102  0.000160  0.000117\n",
      "30         0.000161  0.000000  0.000142  0.000094\n",
      "than       0.000041  0.000120  0.000050  0.000094\n",
      "faq        0.000000  0.000067  0.000080  0.000103\n",
      "i be wonder if the faq file could be post quarterly rather than monthly every 28 30 day i get this bloat feel\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "thanks     0.000397  0.000056  0.001375  0.000355\n",
      "be         0.000372  0.000504  0.000397  0.000457\n",
      "explain    0.000000  0.000358  0.000000  0.001189\n",
      "could      0.000262  0.000000  0.000290  0.000657\n",
      "activity   0.000000  0.000000  0.000000  0.001074\n",
      "loss       0.000000  0.000000  0.000000  0.001074\n",
      "alan       0.000000  0.000000  0.000000  0.001074\n",
      "ron        0.000000  0.000000  0.000000  0.001074\n",
      "regularly  0.000000  0.000000  0.000000  0.001074\n",
      "timer      0.000000  0.000000  0.000000  0.001074\n",
      "post       0.000397  0.000128  0.000000  0.000320\n",
      "the        0.000202  0.000207  0.000188  0.000239\n",
      "command    0.000000  0.000000  0.000315  0.000459\n",
      "report     0.000000  0.000000  0.000441  0.000321\n",
      "someone    0.000083  0.000319  0.000000  0.000306\n",
      "in         0.000150  0.000143  0.000179  0.000159\n",
      "this       0.000105  0.000133  0.000121  0.000155\n",
      "what       0.000085  0.000068  0.000085  0.000078\n",
      "interest   0.000000  0.000072  0.000079  0.000081\n",
      "this activity be regularly report in ron s interest post could someone explain what the command loss timer be thanks alan\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "image       0.000000  0.000000  0.003353  0.000625\n",
      "of          0.000269  0.000561  0.000399  0.000411\n",
      "thanks      0.000266  0.000038  0.000921  0.000238\n",
      "stereo      0.000000  0.000000  0.000000  0.001439\n",
      "planetary   0.000000  0.000000  0.000000  0.001439\n",
      "phobos      0.000000  0.000000  0.000000  0.001340\n",
      "satellite   0.000000  0.000000  0.000000  0.001340\n",
      "mar         0.000000  0.000000  0.000000  0.001340\n",
      "tell        0.000000  0.000000  0.000306  0.001020\n",
      "anyone      0.000262  0.000000  0.000733  0.000307\n",
      "might       0.000000  0.000000  0.000321  0.000896\n",
      "the         0.000271  0.000277  0.000252  0.000320\n",
      "surface     0.000000  0.000000  0.000495  0.000491\n",
      "and         0.000199  0.000265  0.000248  0.000265\n",
      "any         0.000187  0.000062  0.000542  0.000161\n",
      "moon        0.000000  0.000411  0.000000  0.000494\n",
      "in          0.000201  0.000191  0.000240  0.000213\n",
      "deimos      0.000000  0.000000  0.000000  0.000720\n",
      "gifs        0.000000  0.000000  0.000506  0.000175\n",
      "where       0.000135  0.000000  0.000286  0.000234\n",
      "me          0.000094  0.000182  0.000294  0.000036\n",
      "especially  0.000387  0.000000  0.000000  0.000192\n",
      "but         0.000042  0.000169  0.000149  0.000096\n",
      "will        0.000063  0.000201  0.000027  0.000126\n",
      "do          0.000091  0.000088  0.000143  0.000079\n",
      "that        0.000113  0.000095  0.000091  0.000095\n",
      "prefer      0.000071  0.000000  0.000235  0.000080\n",
      "can         0.000066  0.000054  0.000123  0.000099\n",
      "order       0.000193  0.000077  0.000000  0.000066\n",
      "find        0.000079  0.000030  0.000090  0.000019\n",
      "interested  0.000020  0.000014  0.000021  0.000020\n",
      "can anyone tell me where i might find stereo image of planetary and planetary satellite surface gifs prefer but any will do i m especially interested in stereo of the surface of phobos deimos mar and the moon in that order thanks\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "            autos  religion  graphics     space\n",
      "42       0.000502  0.000000  0.001259  0.000000\n",
      "thought  0.000000  0.000000  0.000329  0.001421\n",
      "be       0.000363  0.000492  0.000388  0.000447\n",
      "the      0.000395  0.000404  0.000367  0.000466\n",
      "help     0.000000  0.000195  0.001159  0.000204\n",
      "chip     0.000000  0.000000  0.001302  0.000000\n",
      "really   0.000268  0.000739  0.000237  0.000000\n",
      "that     0.000329  0.000276  0.000265  0.000276\n",
      "on       0.000145  0.000152  0.000413  0.000366\n",
      "it       0.000265  0.000136  0.000365  0.000248\n",
      "could    0.000170  0.000000  0.000189  0.000428\n",
      "hear     0.000000  0.000303  0.000365  0.000097\n",
      "24       0.000000  0.000282  0.000454  0.000000\n",
      "pete     0.000000  0.000000  0.000699  0.000000\n",
      "intel    0.000000  0.000000  0.000699  0.000000\n",
      "reason   0.000000  0.000000  0.000699  0.000000\n",
      "proper   0.000000  0.000000  0.000699  0.000000\n",
      "egg      0.000000  0.000000  0.000699  0.000000\n",
      "stomp    0.000000  0.000000  0.000699  0.000000\n",
      "endian   0.000000  0.000000  0.000699  0.000000\n",
      "war      0.000000  0.000471  0.000173  0.000000\n",
      "value    0.000000  0.000469  0.000173  0.000000\n",
      "break    0.000000  0.000000  0.000220  0.000265\n",
      "side     0.000262  0.000000  0.000222  0.000000\n",
      "you      0.000164  0.000123  0.000107  0.000073\n",
      "but      0.000040  0.000164  0.000145  0.000094\n",
      "get      0.000082  0.000033  0.000144  0.000140\n",
      "write    0.000000  0.000066  0.000196  0.000099\n",
      "some     0.000027  0.000045  0.000169  0.000119\n",
      "their    0.000187  0.000101  0.000028  0.000032\n",
      "so       0.000074  0.000057  0.000052  0.000030\n",
      "out      0.000057  0.000053  0.000041  0.000025\n",
      "hear hear really i thought that the reason it be 42 be that it be really 24 but write a 42 so that on intel chip you could get the proper value pete help stomp out the endian war break some egg on their side\n",
      "==> predicted_topic = space, actual_topic = graphics \n",
      "\n",
      "             autos  religion  graphics     space\n",
      "see       0.000979  0.001563  0.000139  0.000000\n",
      "you       0.000655  0.000493  0.000427  0.000290\n",
      "need      0.000262  0.000000  0.000793  0.000403\n",
      "unless    0.001399  0.000000  0.000000  0.000000\n",
      "hmmmmmmm  0.001399  0.000000  0.000000  0.000000\n",
      "accident  0.001399  0.000000  0.000000  0.000000\n",
      "me        0.000184  0.000354  0.000572  0.000070\n",
      "won       0.000645  0.000395  0.000000  0.000000\n",
      "have      0.000298  0.000192  0.000193  0.000170\n",
      "let       0.000224  0.000309  0.000200  0.000000\n",
      "an        0.000264  0.000174  0.000181  0.000062\n",
      "more      0.000097  0.000104  0.000052  0.000061\n",
      "let me see unless you have an accident you won t need more hmmmmmmm\n",
      "==> predicted_topic = religion, actual_topic = autos \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "for         0.000740  0.000326  0.001915  0.000409\n",
      "motorcycle  0.001734  0.000000  0.000000  0.000000\n",
      "mandatory   0.001734  0.000000  0.000000  0.000000\n",
      "drl         0.001734  0.000000  0.000000  0.000000\n",
      "already     0.001038  0.000000  0.000446  0.000000\n",
      "be          0.000300  0.000407  0.000321  0.000369\n",
      "well        0.000068  0.000065  0.000040  0.000045\n",
      "well drl s be already mandatory for motorcycle\n",
      "==> predicted_topic = graphics, actual_topic = autos \n",
      "\n",
      "             autos  religion  graphics     space\n",
      "god       0.000000  0.003608  0.000000  0.000499\n",
      "profit    0.000000  0.000000  0.000000  0.001706\n",
      "the       0.000345  0.000353  0.000320  0.000407\n",
      "twilight  0.000000  0.000000  0.000000  0.000916\n",
      "blare     0.000000  0.000000  0.000000  0.000916\n",
      "bless     0.000000  0.000000  0.000000  0.000916\n",
      "cacs      0.000000  0.000000  0.000000  0.000916\n",
      "caste     0.000000  0.000000  0.000000  0.000916\n",
      "fraering  0.000000  0.000000  0.000000  0.000916\n",
      "freely    0.000000  0.000000  0.000000  0.000916\n",
      "usl       0.000000  0.000000  0.000000  0.000916\n",
      "pgf       0.000000  0.000000  0.000000  0.000916\n",
      "presence  0.000000  0.000000  0.000000  0.000916\n",
      "srl03     0.000000  0.000000  0.000000  0.000916\n",
      "edu       0.000099  0.000000  0.000348  0.000377\n",
      "be        0.000159  0.000215  0.000169  0.000195\n",
      "phil      0.000000  0.000257  0.000000  0.000430\n",
      "it        0.000174  0.000089  0.000239  0.000163\n",
      "and       0.000127  0.000169  0.000158  0.000169\n",
      "right     0.000276  0.000065  0.000032  0.000190\n",
      "in        0.000128  0.000122  0.000153  0.000136\n",
      "from      0.000060  0.000069  0.000096  0.000115\n",
      "even      0.000027  0.000153  0.000054  0.000087\n",
      "by        0.000067  0.000055  0.000074  0.000069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "may       0.000021  0.000090  0.000056  0.000031\n",
      "from phil g fraering pgf srl03 cacs usl edu right the profit caste be bless by god and may freely blare it presence in the even twilight\n",
      "==> predicted_topic = religion, actual_topic = space \n",
      "\n",
      "            autos  religion  graphics     space\n",
      "help     0.000000  0.000315  0.001873  0.000330\n",
      "the      0.000425  0.000436  0.000395  0.000502\n",
      "rest     0.000000  0.000886  0.000000  0.000424\n",
      "shirt    0.000000  0.001130  0.000000  0.000000\n",
      "night    0.000000  0.001130  0.000000  0.000000\n",
      "delete   0.000000  0.001130  0.000000  0.000000\n",
      "brown    0.000000  0.001130  0.000000  0.000000\n",
      "of       0.000141  0.000293  0.000209  0.000215\n",
      "out      0.000276  0.000259  0.000199  0.000120\n",
      "in       0.000158  0.000150  0.000188  0.000167\n",
      "can      0.000104  0.000085  0.000193  0.000155\n",
      "about    0.000169  0.000113  0.000081  0.000073\n",
      "anybody  0.000088  0.000057  0.000209  0.000041\n",
      "find     0.000124  0.000046  0.000141  0.000030\n",
      "rest delete can anybody out in a p h help out find out about the night of the brown shirt\n",
      "==> predicted_topic = graphics, actual_topic = religion \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "for         0.000710  0.000312  0.001838  0.000393\n",
      "new         0.001201  0.000000  0.000375  0.000582\n",
      "23          0.000685  0.000000  0.000000  0.001035\n",
      "thermostat  0.001664  0.000000  0.000000  0.000000\n",
      "sound       0.000415  0.000000  0.000242  0.000819\n",
      "you         0.000389  0.000293  0.000254  0.000173\n",
      "do          0.000211  0.000202  0.000331  0.000183\n",
      "that        0.000261  0.000219  0.000211  0.000219\n",
      "can         0.000153  0.000125  0.000284  0.000228\n",
      "say         0.000156  0.000370  0.000136  0.000080\n",
      "how         0.000102  0.000131  0.000086  0.000072\n",
      "again       0.000047  0.000044  0.000024  0.000033\n",
      "you can say that again how do 23 for a new thermostat sound\n",
      "==> predicted_topic = graphics, actual_topic = autos \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "he          0.000000  0.002411  0.000000  0.000602\n",
      "land        0.000000  0.000000  0.000000  0.001753\n",
      "mach        0.000000  0.000000  0.000000  0.001325\n",
      "flight      0.000000  0.000000  0.000000  0.001234\n",
      "head        0.000000  0.000000  0.000000  0.001234\n",
      "military    0.000000  0.000000  0.000000  0.001234\n",
      "of          0.000165  0.000344  0.000245  0.000252\n",
      "new         0.000478  0.000000  0.000149  0.000232\n",
      "could       0.000161  0.000000  0.000179  0.000405\n",
      "handle      0.000000  0.000000  0.000257  0.000474\n",
      "month       0.000000  0.000000  0.000260  0.000459\n",
      "belive      0.000000  0.000000  0.000000  0.000662\n",
      "boom        0.000000  0.000000  0.000000  0.000662\n",
      "decent      0.000000  0.000000  0.000000  0.000662\n",
      "direction   0.000000  0.000000  0.000000  0.000662\n",
      "fran        0.000000  0.000000  0.000000  0.000662\n",
      "aircraft    0.000000  0.000000  0.000000  0.000662\n",
      "25aircraft  0.000000  0.000000  0.000000  0.000662\n",
      "int         0.000000  0.000000  0.000000  0.000662\n",
      "25          0.000000  0.000000  0.000000  0.000662\n",
      "san         0.000000  0.000000  0.000000  0.000662\n",
      "odd         0.000000  0.000000  0.000000  0.000662\n",
      "supersonic  0.000000  0.000000  0.000000  0.000662\n",
      "super       0.000000  0.000000  0.000436  0.000165\n",
      "be          0.000115  0.000155  0.000123  0.000141\n",
      "the         0.000125  0.000128  0.000116  0.000147\n",
      "on          0.000069  0.000072  0.000196  0.000173\n",
      "ago         0.000053  0.000071  0.000048  0.000323\n",
      "it          0.000126  0.000064  0.000173  0.000118\n",
      "question    0.000086  0.000294  0.000043  0.000035\n",
      "east        0.000000  0.000222  0.000000  0.000232\n",
      "what        0.000105  0.000084  0.000104  0.000096\n",
      "hear        0.000000  0.000144  0.000173  0.000046\n",
      "that        0.000104  0.000087  0.000084  0.000087\n",
      "there       0.000113  0.000040  0.000062  0.000139\n",
      "some        0.000026  0.000043  0.000160  0.000113\n",
      "speed       0.000118  0.000000  0.000069  0.000051\n",
      "heard       0.000019  0.000062  0.000017  0.000067\n",
      "base        0.000015  0.000048  0.000024  0.000065\n",
      "over        0.000061  0.000018  0.000021  0.000019\n",
      "few         0.000024  0.000015  0.000029  0.000050\n",
      "the supersonic boom hear a few month ago over i belive san fran head east of what i heard some new super speed mach 25 aircraft what military base int he direction of flight be there that could handle a mach 25aircraft on it land decent odd question\n",
      "==> predicted_topic = religion, actual_topic = space \n",
      "\n",
      "                  autos  religion  graphics     space\n",
      "try            0.000000  0.000329  0.004991  0.001203\n",
      "he             0.000000  0.002812  0.000000  0.000703\n",
      "thought        0.000000  0.000000  0.000363  0.001570\n",
      "be             0.000268  0.000362  0.000286  0.000329\n",
      "to             0.000226  0.000336  0.000252  0.000285\n",
      "win            0.000000  0.000000  0.000000  0.000773\n",
      "consideration  0.000000  0.000000  0.000000  0.000773\n",
      "sam            0.000000  0.000000  0.000000  0.000773\n",
      "ross           0.000000  0.000000  0.000000  0.000773\n",
      "perot          0.000000  0.000000  0.000000  0.000773\n",
      "disappoint     0.000000  0.000000  0.000000  0.000773\n",
      "further        0.000000  0.000000  0.000000  0.000773\n",
      "matt           0.000000  0.000000  0.000000  0.000773\n",
      "likely         0.000000  0.000000  0.000000  0.000773\n",
      "walton         0.000000  0.000000  0.000000  0.000773\n",
      "gate           0.000000  0.000000  0.000000  0.000773\n",
      "after          0.000414  0.000091  0.000000  0.000187\n",
      "it             0.000147  0.000075  0.000202  0.000137\n",
      "bill           0.000000  0.000301  0.000000  0.000239\n",
      "third          0.000282  0.000000  0.000000  0.000250\n",
      "kid            0.000000  0.000256  0.000000  0.000274\n",
      "but            0.000045  0.000182  0.000160  0.000103\n",
      "my             0.000224  0.000105  0.000045  0.000086\n",
      "in             0.000108  0.000103  0.000129  0.000114\n",
      "first          0.000076  0.000175  0.000041  0.000029\n",
      "think          0.000107  0.000054  0.000065  0.000018\n",
      "more           0.000054  0.000057  0.000029  0.000034\n",
      "come           0.000024  0.000019  0.000050  0.000060\n",
      "my first thought be ross perot after further consideration i think he d be more likely to try to win it but come in a disappoint third try bill gate try sam walton s kid matt\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "         autos  religion  graphics     space\n",
      "to    0.000505  0.000751  0.000563  0.000636\n",
      "know  0.000402  0.000322  0.000555  0.000171\n",
      "just  0.000370  0.000188  0.000218  0.000366\n",
      "want  0.000256  0.000173  0.000163  0.000111\n",
      "i just want to know\n",
      "==> predicted_topic = religion, actual_topic = autos \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "it         0.000610  0.000313  0.000839  0.000571\n",
      "be         0.000278  0.000377  0.000297  0.000342\n",
      "gee        0.000272  0.000000  0.000000  0.000856\n",
      "look       0.000277  0.000024  0.000574  0.000237\n",
      "you        0.000376  0.000283  0.000245  0.000167\n",
      "any        0.000209  0.000069  0.000605  0.000180\n",
      "release    0.000469  0.000000  0.000342  0.000000\n",
      "tion       0.000804  0.000000  0.000000  0.000000\n",
      "radia      0.000804  0.000000  0.000000  0.000000\n",
      "confuse    0.000804  0.000000  0.000000  0.000000\n",
      "genus      0.000804  0.000000  0.000000  0.000000\n",
      "hole       0.000804  0.000000  0.000000  0.000000\n",
      "locate     0.000804  0.000000  0.000000  0.000000\n",
      "tor        0.000804  0.000000  0.000000  0.000000\n",
      "radiation  0.000804  0.000000  0.000000  0.000000\n",
      "radiator   0.000804  0.000000  0.000000  0.000000\n",
      "punch      0.000804  0.000000  0.000000  0.000000\n",
      "where      0.000150  0.000000  0.000319  0.000262\n",
      "really     0.000154  0.000425  0.000136  0.000000\n",
      "sound      0.000200  0.000000  0.000117  0.000396\n",
      "me         0.000106  0.000204  0.000328  0.000040\n",
      "like       0.000197  0.000106  0.000114  0.000235\n",
      "what       0.000128  0.000102  0.000127  0.000117\n",
      "will       0.000070  0.000225  0.000030  0.000140\n",
      "do         0.000102  0.000098  0.000160  0.000088\n",
      "when       0.000041  0.000172  0.000039  0.000083\n",
      "since      0.000074  0.000065  0.000114  0.000000\n",
      "make       0.000051  0.000059  0.000031  0.000028\n",
      "gee you really make me confuse what be radiator where be it locate what do it look like will it release any radiation since it sound like radia tion genus tor when you punch hole\n",
      "==> predicted_topic = space, actual_topic = autos \n",
      "\n",
      "             autos  religion  graphics     space\n",
      "file      0.000000  0.000000  0.003935  0.000982\n",
      "yo        0.000000  0.000000  0.000000  0.003023\n",
      "assume    0.000000  0.000000  0.000000  0.002742\n",
      "be        0.000421  0.000571  0.000450  0.000518\n",
      "every     0.000000  0.000000  0.000339  0.001199\n",
      "string    0.000000  0.000000  0.000000  0.001512\n",
      "sig       0.000000  0.000000  0.000000  0.001512\n",
      "mining    0.000000  0.000000  0.000000  0.001512\n",
      "you       0.000380  0.000286  0.000248  0.000168\n",
      "cash      0.000000  0.000000  0.000000  0.000812\n",
      "limit     0.000000  0.000000  0.000000  0.000812\n",
      "award     0.000000  0.000000  0.000000  0.000812\n",
      "to        0.000119  0.000177  0.000132  0.000149\n",
      "away      0.000306  0.000000  0.000000  0.000257\n",
      "own       0.000000  0.000261  0.000000  0.000299\n",
      "ok        0.000335  0.000100  0.000000  0.000083\n",
      "right     0.000245  0.000058  0.000028  0.000169\n",
      "get       0.000096  0.000038  0.000167  0.000163\n",
      "there     0.000138  0.000049  0.000076  0.000170\n",
      "can       0.000075  0.000061  0.000138  0.000111\n",
      "them      0.000018  0.000142  0.000078  0.000142\n",
      "would     0.000121  0.000045  0.000072  0.000125\n",
      "one       0.000088  0.000071  0.000041  0.000144\n",
      "like      0.000099  0.000053  0.000058  0.000119\n",
      "because   0.000066  0.000122  0.000000  0.000130\n",
      "don       0.000044  0.000086  0.000057  0.000043\n",
      "anything  0.000030  0.000019  0.000036  0.000088\n",
      "give      0.000056  0.000046  0.000044  0.000014\n",
      "time      0.000023  0.000025  0.000046  0.000045\n",
      "mine      0.000022  0.000020  0.000024  0.000054\n",
      "nice      0.000013  0.000011  0.000013  0.000013\n",
      "a cash award be ok a time limit would be nice you can t give away mining right assume there s anything to mine because you don t own them sig file be like string every yo yo s get one\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "           autos  religion  graphics     space\n",
      "get     0.000358  0.000143  0.000625  0.000611\n",
      "life    0.000587  0.000170  0.000000  0.000775\n",
      "people  0.000346  0.000350  0.000062  0.000173\n",
      "people get a life\n",
      "==> predicted_topic = space, actual_topic = autos \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "image       0.000000  0.000000  0.004100  0.000764\n",
      "site        0.000000  0.000000  0.001891  0.000881\n",
      "ftp         0.000000  0.000000  0.001515  0.000650\n",
      "the         0.000497  0.000509  0.000461  0.000587\n",
      "thanks      0.000325  0.000046  0.001126  0.000291\n",
      "phobos      0.000000  0.000000  0.000000  0.001639\n",
      "spacecraft  0.000000  0.000000  0.000000  0.001639\n",
      "russian     0.000000  0.000000  0.000000  0.001639\n",
      "house       0.000000  0.000000  0.000000  0.001639\n",
      "anyone      0.000321  0.000000  0.000897  0.000375\n",
      "any         0.000229  0.000076  0.000663  0.000197\n",
      "moon        0.000000  0.000502  0.000000  0.000605\n",
      "do          0.000223  0.000214  0.000350  0.000194\n",
      "fat         0.000000  0.000000  0.000000  0.000880\n",
      "ill         0.000000  0.000000  0.000000  0.000880\n",
      "martian     0.000000  0.000000  0.000000  0.000880\n",
      "mission     0.000000  0.000000  0.000000  0.000880\n",
      "if          0.000164  0.000165  0.000260  0.000191\n",
      "on          0.000091  0.000096  0.000260  0.000230\n",
      "of          0.000110  0.000228  0.000163  0.000167\n",
      "ago         0.000070  0.000094  0.000064  0.000429\n",
      "back        0.000245  0.000093  0.000000  0.000139\n",
      "an          0.000166  0.000110  0.000114  0.000039\n",
      "they        0.000139  0.000066  0.000048  0.000130\n",
      "send        0.000176  0.000000  0.000076  0.000120\n",
      "know        0.000102  0.000082  0.000141  0.000044\n",
      "year        0.000058  0.000032  0.000054  0.000144\n",
      "so          0.000093  0.000071  0.000066  0.000038\n",
      "re          0.000049  0.000092  0.000018  0.000102\n",
      "at          0.000047  0.000048  0.000077  0.000062\n",
      "few         0.000031  0.000021  0.000039  0.000066\n",
      "do the russian spacecraft s on the ill fat phobos mission a few year ago send back any image of the martian moon if so do anyone know if they re house at an ftp site thanks\n",
      "==> predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training = True\n",
    "tlabels = train_labels if training else test_labels\n",
    "tdoc_vectors = train_doc_vectors if training else test_doc_vectors\n",
    "misclassified = misclassified_train if training else misclassified_test\n",
    "\n",
    "for doc_index in tqdm(misclassified):\n",
    "    doc_vector = tdoc_vectors[doc_index]\n",
    "    doc_topic_word_distr, doc_topic = infer_topic(label_classes, doc_vector, topic_word_distr)\n",
    "    \n",
    "    xv = doc_topic_word_distr.iloc[np.where(doc_topic_word_distr.sum(1) > 0)]\n",
    "    print(xv.loc[xv.sum(1).sort_values(ascending=False).index])\n",
    "    print(train_docs[doc_index])\n",
    "    print(f\"==> predicted_topic = {doc_topic}, actual_topic = {label_classes[tlabels[doc_index]]} \\n\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuarcy = 100.00%, test_accuarcy = 62.88%, avg-accuarcy = 81.44%\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=.01)\n",
    "clf.fit(train_doc_vectors, train_labels)\n",
    "\n",
    "train_accuracy = clf.score(train_doc_vectors, train_labels)\n",
    "test_accuracy = clf.score(test_doc_vectors, test_labels)\n",
    "\n",
    "print(f\"training_accuarcy = {train_accuracy*100:.2f}%, test_accuarcy = {test_accuracy*100:.2f}%, avg-accuarcy = {.5*(train_accuracy + test_accuracy)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next steps\n",
    "use softwmax on word_trust factor, apply it on word_doc_norm like in word_word_co to suppress the stop words and make the actual important words more pronounced. use this pronounced words to estimate the related topic in doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

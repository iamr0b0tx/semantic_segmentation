{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from word_network import WordNetwork\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import entropy as calculate_entropy\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 1000 docs\n"
     ]
    }
   ],
   "source": [
    "# fetch data\n",
    "docs = load_data(1000)\n",
    "print(f\"there are {len(docs)} docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                         | 0/2148 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2148/2148 [00:59<00:00, 36.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discovered 58959 words!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# initialize network\n",
    "word_network = WordNetwork()\n",
    "\n",
    "# train the network\n",
    "print(\"\\nTraining\\n\" + \"=\"*30)\n",
    "word_network.train(docs)\n",
    "print(f\"discovered {len(word_network.word_nodes)} words!\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_node is [COMPUTER]\n",
      "==============================\n",
      "computing        0.4988\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show topwords related to computer\n",
    "show_topwords(word_network, \"computer\", [\"computing\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of samples needed\n",
    "datasize = 300\n",
    "randomize = False\n",
    "\n",
    "# retrieve dataset\n",
    "categories = ['rec.autos', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "label_classes = ['autos', 'religion', 'graphics', 'space']\n",
    "\n",
    "assert len(label_classes) == len(categories)\n",
    "\n",
    "docs = fetch_20newsgroups(subset='train', shuffle=randomize, remove=('headers', 'footers', 'quotes'), categories=categories)\n",
    "docs, old_labels, classes = docs.data, docs.target, docs.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apparently you re not a woman   my husband hates the auto door locks\n",
      " feels safer in a car that locks easily  in addition to watching around\n",
      " in a secluded spot  etc   have my keys ready to open the door so i m\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "clean_docs = []\n",
    "max_document_length = None\n",
    "\n",
    "# the new classes\n",
    "sizes = [0] * len(label_classes)\n",
    "assert len(label_classes) == len(sizes)\n",
    "\n",
    "for index, doc in enumerate(docs):\n",
    "    if len(clean_docs) == datasize*len(label_classes):\n",
    "        break\n",
    "        \n",
    "    cd = clean_doc(doc)\n",
    "    \n",
    "    if len(cd) == 0 or cd.isspace() or (max_document_length is not None and len(cd) <= max_document_length):\n",
    "        continue\n",
    "        \n",
    "    label_class = classes[old_labels[index]]\n",
    "    label = categories.index(label_class)\n",
    "\n",
    "    if sizes[label] < datasize:\n",
    "        clean_docs.append(cd)\n",
    "        labels.append(label)\n",
    "\n",
    "        sizes[label] += 1\n",
    "\n",
    "labels = np.array(labels)\n",
    "print(clean_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 1200 docs and 4 classes: ['autos', 'religion', 'graphics', 'space'] of size min:300, max:300\n"
     ]
    }
   ],
   "source": [
    "print(f\"there are {len(clean_docs)} docs and {len(label_classes)} classes: {label_classes} of size min:{min(sizes)}, max:{max(sizes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### count words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_count is 17742\n"
     ]
    }
   ],
   "source": [
    "# initialize the count vectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "# count_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# fit it to dataset\n",
    "train_docs, test_docs, train_labels, test_labels = train_test_split(clean_docs, labels, test_size=.33, random_state=42)\n",
    "\n",
    "count_vectorizer.fit(train_docs)\n",
    "vocabulary = count_vectorizer.get_feature_names()\n",
    "\n",
    "print(\"word_count is\", len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Datatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804 train_docs, 396 test docs\n"
     ]
    }
   ],
   "source": [
    "# create doc count vectors\n",
    "train_doc_vectors = count_vectorizer.transform(train_docs).toarray()\n",
    "train_doc_vectors = (train_doc_vectors > 0).astype(float)\n",
    "train_doc_vectors = normalize(train_doc_vectors, norm=\"l1\", axis=1)\n",
    "\n",
    "test_doc_vectors = count_vectorizer.transform(test_docs).toarray()\n",
    "test_doc_vectors = (test_doc_vectors > 0).astype(float)\n",
    "test_doc_vectors = normalize(test_doc_vectors, norm=\"l1\", axis=1)\n",
    "\n",
    "print(f\"{len(train_labels)} train_docs, {len(test_labels)} test docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document_word_frequency shape is (804, 17743)\n"
     ]
    }
   ],
   "source": [
    "document_word_frequency = pd.DataFrame(train_doc_vectors, columns=count_vectorizer.get_feature_names())\n",
    "document_word_frequency[\"__labels__\"] = train_labels\n",
    "\n",
    "print(\"document_word_frequency shape is\", document_word_frequency.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 1200 docs and 4 classes\n"
     ]
    }
   ],
   "source": [
    "print(f\"there are {len(clean_docs)} docs and {len(label_classes)} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>00000</th>\n",
       "      <th>0001</th>\n",
       "      <th>000100255pixel</th>\n",
       "      <th>00041032</th>\n",
       "      <th>0004136</th>\n",
       "      <th>0004246</th>\n",
       "      <th>0004422</th>\n",
       "      <th>...</th>\n",
       "      <th>zullen</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zurbrin</th>\n",
       "      <th>zurvanism</th>\n",
       "      <th>zwaartepunten</th>\n",
       "      <th>zwak</th>\n",
       "      <th>zwakke</th>\n",
       "      <th>zware</th>\n",
       "      <th>zwarte</th>\n",
       "      <th>__labels__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 17743 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         00       000  0000  00000  0001  000100255pixel  00041032  0004136  \\\n",
       "0  0.000000  0.000000   0.0    0.0   0.0             0.0       0.0      0.0   \n",
       "1  0.000000  0.000000   0.0    0.0   0.0             0.0       0.0      0.0   \n",
       "2  0.000388  0.000388   0.0    0.0   0.0             0.0       0.0      0.0   \n",
       "3  0.000000  0.000000   0.0    0.0   0.0             0.0       0.0      0.0   \n",
       "4  0.000000  0.000000   0.0    0.0   0.0             0.0       0.0      0.0   \n",
       "\n",
       "   0004246  0004422  ...  zullen  zulu  zurbrin  zurvanism  zwaartepunten  \\\n",
       "0      0.0      0.0  ...     0.0   0.0      0.0        0.0            0.0   \n",
       "1      0.0      0.0  ...     0.0   0.0      0.0        0.0            0.0   \n",
       "2      0.0      0.0  ...     0.0   0.0      0.0        0.0            0.0   \n",
       "3      0.0      0.0  ...     0.0   0.0      0.0        0.0            0.0   \n",
       "4      0.0      0.0  ...     0.0   0.0      0.0        0.0            0.0   \n",
       "\n",
       "   zwak  zwakke  zware  zwarte  __labels__  \n",
       "0   0.0     0.0    0.0     0.0           3  \n",
       "1   0.0     0.0    0.0     0.0           0  \n",
       "2   0.0     0.0    0.0     0.0           2  \n",
       "3   0.0     0.0    0.0     0.0           3  \n",
       "4   0.0     0.0    0.0     0.0           1  \n",
       "\n",
       "[5 rows x 17743 columns]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_word_frequency.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Binary Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#reduce freq in doc to bin value of 1 or 0\n",
    "word_doc_freqency = document_word_frequency.drop([\"__labels__\"], axis='columns')\n",
    "\n",
    "#the sum vertically of bin freq\n",
    "word_doc_total_frequency = word_doc_freqency.sum(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word-Word Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6b22fa1e2344fe8a90d848cbd239614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17742.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-293-b7449db4bc4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mword_word_co\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_network\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_co_occurence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mw2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"word_word_co has shape {word_word_co.shape}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\christian\\work\\python\\cyberspace\\semantic_segmentation\\word_network.py\u001b[0m in \u001b[0;36mget_co_occurence\u001b[1;34m(self, word, words)\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mtrust_factor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[0mco_occurence_ratio\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mother_word\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mword_node\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother_word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtrust_factor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfreq\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mfreq\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mco_occurence_ratio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "word_word_co = pd.DataFrame(data=0.0, columns=vocabulary, index=vocabulary)\n",
    "\n",
    "for i in tqdm(range(len(vocabulary))):\n",
    "    w1 = vocabulary[i]\n",
    "    \n",
    "    for j, w2 in enumerate(vocabulary[:10]):\n",
    "        word_word_co[w1][w2] = word_network.get_co_occurence(w1, [w2]).get(w2, 0)\n",
    "          \n",
    "print(f\"word_word_co has shape {word_word_co.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_word_co.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic and word corelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Passing list-likes to .loc or [] with any missing labels is no longer supported, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-286-28065aeea1e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtopic_word_distr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"computer\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"adebola\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\christian\\documents\\christian\\work\\python\\cyberspace\\semantic_segmentation\\venv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1767\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1768\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1769\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1770\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\christian\\documents\\christian\\work\\python\\cyberspace\\semantic_segmentation\\venv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1952\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1953\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1954\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1956\u001b[0m             \u001b[1;31m# nested tuple slicing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\christian\\documents\\christian\\work\\python\\cyberspace\\semantic_segmentation\\venv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1593\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1594\u001b[0m             \u001b[1;31m# A collection of keys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1595\u001b[1;33m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1596\u001b[0m             return self.obj._reindex_with_indexers(\n\u001b[0;32m   1597\u001b[0m                 \u001b[1;33m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\christian\\documents\\christian\\work\\python\\cyberspace\\semantic_segmentation\\venv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1552\u001b[0m         self._validate_read_indexer(\n\u001b[1;32m-> 1553\u001b[1;33m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1554\u001b[0m         )\n\u001b[0;32m   1555\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\christian\\documents\\christian\\work\\python\\cyberspace\\semantic_segmentation\\venv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1653\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_interval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1654\u001b[0m                 raise KeyError(\n\u001b[1;32m-> 1655\u001b[1;33m                     \u001b[1;34m\"Passing list-likes to .loc or [] with any missing labels \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1656\u001b[0m                     \u001b[1;34m\"is no longer supported, see \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1657\u001b[0m                     \u001b[1;34m\"https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\"\u001b[0m  \u001b[1;31m# noqa:E501\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Passing list-likes to .loc or [] with any missing labels is no longer supported, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike'"
     ]
    }
   ],
   "source": [
    "topic_word_distr.loc[[\"computer\", \"adebola\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_word_distr has shape (17523, 4)\n"
     ]
    }
   ],
   "source": [
    "topic_word_distr = pd.DataFrame(data=0.0, columns=label_classes, index=vocabulary)\n",
    "\n",
    "for topic, label in enumerate(label_classes):\n",
    "    word_topic_frequency = word_doc_freqency[document_word_frequency['__labels__'] == topic].sum(0)\n",
    "#     trust_factor = (word_doc_freqency > 0).sum(0)\n",
    "#     trust_factor = trust_factor / (trust_factor + 1)\n",
    "    trust_factor = sigmoid((word_doc_freqency > 0).sum(0))\n",
    "    \n",
    "    topic_word_distr[label] = ((word_topic_frequency * trust_factor) / word_doc_total_frequency).fillna(0)\n",
    "\n",
    "# entropy = topic_word_distr.std(1)\n",
    "entropy = sigmoid(np.nan_to_num(calculate_entropy(topic_word_distr.T, base=2)))\n",
    "skew_factor = gaussian(entropy)\n",
    "\n",
    "topic_word_distr = (topic_word_distr.T * skew_factor).T\n",
    "print(f\"topic_word_distr has shape {topic_word_distr.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>autos</th>\n",
       "      <th>religion</th>\n",
       "      <th>graphics</th>\n",
       "      <th>space</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>0.036319</td>\n",
       "      <td>0.009206</td>\n",
       "      <td>0.376589</td>\n",
       "      <td>0.128523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>0.341298</td>\n",
       "      <td>0.038339</td>\n",
       "      <td>0.086055</td>\n",
       "      <td>0.053895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.685965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00000</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.685965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.569349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          autos  religion  graphics     space\n",
       "00     0.036319  0.009206  0.376589  0.128523\n",
       "000    0.341298  0.038339  0.086055  0.053895\n",
       "0000   0.000000  0.000000  0.000000  0.685965\n",
       "00000  0.000000  0.000000  0.000000  0.685965\n",
       "0001   0.000000  0.569349  0.000000  0.000000"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word_distr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['autos', 'religion', 'graphics', 'space']"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3d             0.778801\n",
       "vga            0.778800\n",
       "animation      0.778799\n",
       "formats        0.778796\n",
       "programming    0.778796\n",
       "                 ...   \n",
       "moon           0.000765\n",
       "government     0.000758\n",
       "days           0.000739\n",
       "man            0.000627\n",
       "cars           0.000500\n",
       "Name: graphics, Length: 6721, dtype: float64"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_class = 'graphics'\n",
    "topic_word_distr[label_class][topic_word_distr[label_class] > 0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "autos       0.127230\n",
       "graphics    0.116414\n",
       "religion    0.114527\n",
       "space       0.102520\n",
       "Name: the, dtype: float64"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word=\"the\"\n",
    "topic_word_distr.loc[word].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(f\"{word} against TOPICS\")\n",
    "plt.bar(topic_word_distr.loc[word].index, topic_word_distr.loc[word])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Topic model with Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "883ca2bc3c854d718f9b765608bbdd43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=804.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> train-accuracy is 99.75%, 2 misclassified\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "misclassified_train = []\n",
    "print(\"Evaluating Topic Model...\")\n",
    "\n",
    "for doc_index in tqdm(range(len(train_labels))):\n",
    "    doc_vector = train_doc_vectors[doc_index]\n",
    "    \n",
    "    doc_topic_word_distr, doc_topic = infer_topic(label_classes, doc_vector, topic_word_distr)\n",
    "    score += int(doc_topic == label_classes[train_labels[doc_index]])\n",
    "    \n",
    "    if doc_topic != label_classes[train_labels[doc_index]]:\n",
    "        misclassified_train.append(doc_index)\n",
    "    \n",
    "train_accuracy = score / (doc_index + 1)\n",
    "print(f\"==> train-accuracy is {train_accuracy*100:.2f}%, {len(misclassified_train)} misclassified\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Topic Model with test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93d59b007e64ec8867ab5d7e7b08857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=396.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> test-accuracy is 83.59%, avg-accuarcy = 91.67%, 65 misclassified\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "print(\"Evaluating Topic Model...\")\n",
    "\n",
    "misclassified_test = []\n",
    "for doc_index in tqdm(range(len(test_labels))):\n",
    "    doc_vector = test_doc_vectors[doc_index]\n",
    "    \n",
    "    doc_topic_word_distr, doc_topic = infer_topic(label_classes, doc_vector, topic_word_distr)\n",
    "    score += int(doc_topic == label_classes[test_labels[doc_index]])\n",
    "    \n",
    "    if doc_topic != label_classes[test_labels[doc_index]]:\n",
    "        misclassified_test.append(doc_index)\n",
    "    \n",
    "\n",
    "test_accuracy = score / (doc_index + 1)\n",
    "print(f\"==> test-accuracy is {test_accuracy*100:.2f}%, avg-accuarcy = {.5*(train_accuracy + test_accuracy)*100:.2f}%, {len(misclassified_test)} misclassified\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating Misclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23338be7dc80499e95c4c8a144cea940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=65.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              autos  religion  graphics     space\n",
      "88         0.000000  0.000000  0.040036  0.000000\n",
      "december   0.008082  0.000749  0.012092  0.000327\n",
      "built      0.003646  0.000754  0.001778  0.010949\n",
      "difficult  0.002238  0.003982  0.005447  0.000406\n",
      "away       0.004236  0.002955  0.000506  0.002587\n",
      "pretty     0.003046  0.002584  0.001332  0.001207\n",
      "early      0.002406  0.002300  0.000946  0.002012\n",
      "so         0.002449  0.002053  0.001952  0.001025\n",
      "certainly  0.001410  0.002650  0.001444  0.001820\n",
      "most       0.001550  0.001717  0.001383  0.002623\n",
      "which      0.001412  0.002400  0.001979  0.001381\n",
      "you        0.002028  0.001589  0.001969  0.001328\n",
      "was        0.002192  0.001619  0.001444  0.001635\n",
      "have       0.002154  0.001567  0.001716  0.001438\n",
      "and        0.001799  0.001543  0.002066  0.001433\n",
      "it         0.001969  0.001366  0.001838  0.001647\n",
      "as         0.001688  0.001965  0.001366  0.001790\n",
      "do         0.001475  0.001952  0.001862  0.001506\n",
      "be         0.001561  0.001844  0.001500  0.001824\n",
      "mine       0.001793  0.001617  0.001482  0.001824\n",
      "to         0.001784  0.001600  0.001813  0.001508\n",
      "in         0.001882  0.001642  0.001596  0.001580\n",
      "the problem with commercial titan is that mm has made little or no attempt to market it.  they re basically happy with their government business and don t want to have to learn how to sell commercially.  a secondary problem is that it is a bit big.  they d need to go after multi-satellite launches, a la ariane, and that complicates the marketing task quite significantly.  they also had some problems with launch facilities at just the wrong time to get them started properly.  if memory serves, the pad used for the mars observer launch had just come out of heavy refurbishment work that had prevented launches from it for a year or so.  there have been a few ct launches.  mars observer was one of them.  so was that stranded intelsat, and at least one of its brothers that reached orbit properly.\n",
      "predicted_topic = graphics, actual_topic = autos \n",
      "\n",
      "             autos  religion  graphics     space\n",
      "shuttle   0.000000  0.000000  0.000014  0.008680\n",
      "launches  0.000000  0.000000  0.000000  0.008688\n",
      "128       0.000000  0.000000  0.008688  0.000000\n",
      "astro     0.000000  0.000000  0.000067  0.008608\n",
      "launch    0.000442  0.000000  0.000000  0.007887\n",
      "...            ...       ...       ...       ...\n",
      "to        0.000341  0.000306  0.000347  0.000289\n",
      "is        0.000292  0.000359  0.000322  0.000310\n",
      "in        0.000360  0.000314  0.000305  0.000302\n",
      "that      0.000339  0.000347  0.000297  0.000298\n",
      "of        0.000329  0.000336  0.000314  0.000297\n",
      "\n",
      "[115 rows x 4 columns]\n",
      "...   you can tell, folks, when the man has run out of reason:  attack the man s beliefs  in legal terminology, argument  ad hominem:  attack the man, not what he did that has yet to  be proven illegal >     wrongo.  remember the fire movie a couple of years ago?   backdraft ?  the scene in the factory with propane gas  coming out of pipes and gasoline all over the floor,  with a 750 degree flame front overhead?    note that it did not flash all at once?   fires ignite and burn unpredictably.  gases  like tear gas  mix and distribute unevenly.   and flash unevenly.   you are not a fire analyst.  you cannnot tell.    nb:  neither am i.  and i cannot tell   nor is the fbi spokesman   nor is reno   maybe we all should shut up and get a    forensics analysis first.    yes,. there was a flash:  in one room, just pumped full of it.,\n",
      "predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "formats     0.000000  0.000000  0.004310  0.000000\n",
      "format      0.000000  0.000000  0.004299  0.000010\n",
      "planet      0.000000  0.000000  0.000000  0.004306\n",
      "binary      0.000000  0.000000  0.004143  0.000102\n",
      "developers  0.000000  0.000000  0.004233  0.000000\n",
      "...              ...       ...       ...       ...\n",
      "to          0.000169  0.000152  0.000172  0.000143\n",
      "is          0.000145  0.000178  0.000160  0.000153\n",
      "in          0.000178  0.000156  0.000151  0.000150\n",
      "that        0.000168  0.000172  0.000147  0.000148\n",
      "of          0.000163  0.000167  0.000156  0.000147\n",
      "\n",
      "[232 rows x 4 columns]\n",
      "i am posting this for a friend without internet access. please inquire to the phone number and address listed. ---------------------------------------------------------------------   space: teaching s newest frontier  sponsored by the planetary studies foundation  the planetary studies foundation is sponsoring a one week class for teachers called  space: teaching s newest frontier.  the class will be held at the sheraton suites in elk grove, illinois from june 14 through june 18. participants who complete the program can earn two semester hours of graduate credit from aurora college. please note that while the class is intended for teachers, it is not restricted to teachers.  the class, which is being cosponsored by the united states space foundation, will teach how to use space exploration as a teaching tool to get students excited about learning and interested in science.  classroom topics to be covered by the class include:      > living in space      > the space shuttle      > the space station      > nasa spinoffs that benefit society      > principles of astrodynamics/aeronautics      > the solar system  there will also be simulated zero-g training in an underwater space station simulation, model rocket launches, observing sessions at the harper college observatory, and field trips to the adler planetarium and the museum of science and industry.  featured speakers include jerry brown of the colorado based united states space foundation and debbie brown of the nasa lewis research center in cleveland, ohio. additional instructors will be provided by the planetary studies foundation.  the social highlight of the class will be a dinner banquet featuring space shuttle payload specialist byron lichtenberg, currently president of payload systems, inc. lichtenberg was a member of the crew of sts-9 which flew in november 1983. the banquet is scheduled for thursday, june 17.  the registration fee includes transportation for field trips, materials, continental breakfasts, lunches, and the special dinner banquet. guest tickets for the dinner banquet are also available.  there is an additional charge to receive the two hours of graduate credit. for any additional information about the class, contact the science learning center at  708  359-7913.  or write to: planetary studies foundation 1520 w. algonquin rd. palatine, il 60067  ------------------------------------------------------------------------\n",
      "predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "jupiter    0.000000  0.000000  0.000000  0.043439\n",
      "directory  0.000000  0.000000  0.037009  0.003218\n",
      "pub        0.000000  0.000000  0.035799  0.003688\n",
      "library    0.001742  0.001195  0.034868  0.000262\n",
      "ftp        0.000000  0.000000  0.033355  0.004591\n",
      "images     0.000000  0.000000  0.030294  0.005668\n",
      "correct    0.002628  0.003864  0.011206  0.000141\n",
      "site       0.003165  0.000702  0.011858  0.001967\n",
      "holds      0.007742  0.002065  0.000250  0.004436\n",
      "address    0.000103  0.003983  0.006662  0.002914\n",
      "info       0.001812  0.001130  0.006871  0.002154\n",
      "edu        0.002736  0.000537  0.004476  0.002328\n",
      "rather     0.002055  0.002585  0.000685  0.003319\n",
      "should     0.001577  0.002328  0.002941  0.000967\n",
      "ca         0.003275  0.001330  0.001743  0.001421\n",
      "they       0.002905  0.001715  0.001134  0.001688\n",
      "for        0.001878  0.001215  0.002565  0.001450\n",
      "than       0.002150  0.001616  0.001119  0.001985\n",
      "which      0.001351  0.002296  0.001893  0.001321\n",
      "are        0.001919  0.002040  0.001336  0.001385\n",
      "be         0.001493  0.001764  0.001435  0.001745\n",
      "the        0.001771  0.001595  0.001621  0.001427\n",
      "in         0.001800  0.001571  0.001527  0.001511\n",
      "hmmm. i seem to recall that the attraction of solid state record- players and radios in the 1960s wasn t better performance but lower per-unit cost than vacuum-tube systems.   mind you, my father was a vacuum-tube fan in the 60s  switched to solid-state in the mid-seventies and then abruptly died; no doubt there s a lesson in that  and his account could have been biased.\n",
      "predicted_topic = space, actual_topic = graphics \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "stupidity  0.000000  0.017010  0.000000  0.000000\n",
      "active     0.000000  0.000000  0.000000  0.017010\n",
      "promises   0.000000  0.017010  0.000000  0.000000\n",
      "planetary  0.000000  0.000865  0.000061  0.016048\n",
      "returns    0.000000  0.015640  0.000255  0.000433\n",
      "deserve    0.010558  0.002661  0.000000  0.000000\n",
      "citizen    0.013055  0.000000  0.000000  0.000000\n",
      "uv         0.000000  0.000000  0.000000  0.013055\n",
      "depressed  0.013055  0.000000  0.000000  0.000000\n",
      "selling    0.008546  0.000213  0.002581  0.000095\n",
      "numbers    0.001876  0.000553  0.008674  0.000088\n",
      "radiation  0.005900  0.000000  0.000000  0.005153\n",
      "wins       0.004091  0.000000  0.000000  0.006914\n",
      "money      0.003511  0.000506  0.000000  0.004268\n",
      "earth      0.000000  0.002553  0.000787  0.004201\n",
      "seriously  0.004619  0.000296  0.000385  0.002139\n",
      "turns      0.001810  0.000958  0.000051  0.004315\n",
      "folks      0.001683  0.002885  0.000000  0.001389\n",
      "pure       0.000000  0.002501  0.001307  0.001836\n",
      "opinion    0.002551  0.001250  0.000041  0.001603\n",
      "ok         0.003199  0.000924  0.000593  0.000601\n",
      "being      0.000475  0.002033  0.000493  0.001164\n",
      "true       0.000888  0.002118  0.000678  0.000446\n",
      "people     0.001050  0.001679  0.000286  0.000822\n",
      "really     0.001407  0.001241  0.000506  0.000436\n",
      "who        0.000861  0.001493  0.000314  0.000900\n",
      "bit        0.000491  0.000904  0.001571  0.000551\n",
      "guess      0.001277  0.000847  0.001087  0.000281\n",
      "long       0.000966  0.001043  0.000311  0.000905\n",
      "get        0.001115  0.000367  0.000877  0.000766\n",
      "we         0.000546  0.001250  0.000536  0.000782\n",
      "my         0.001263  0.000722  0.000604  0.000519\n",
      "those      0.000758  0.001202  0.000451  0.000670\n",
      "they       0.001193  0.000704  0.000466  0.000693\n",
      "make       0.001088  0.000501  0.000556  0.000843\n",
      "out        0.001021  0.000696  0.000788  0.000432\n",
      "another    0.000669  0.001012  0.000787  0.000447\n",
      "think      0.001083  0.000683  0.000569  0.000571\n",
      "every      0.001039  0.000648  0.000577  0.000593\n",
      "stuff      0.000840  0.000436  0.000782  0.000761\n",
      "are        0.000788  0.000838  0.000549  0.000569\n",
      "time       0.000557  0.000781  0.000789  0.000581\n",
      "if         0.000826  0.000563  0.000731  0.000586\n",
      "and        0.000707  0.000606  0.000812  0.000563\n",
      "it         0.000774  0.000537  0.000722  0.000647\n",
      "this       0.000591  0.000637  0.000820  0.000628\n",
      "as         0.000663  0.000772  0.000537  0.000703\n",
      "do         0.000579  0.000767  0.000732  0.000592\n",
      "by         0.000639  0.000783  0.000619  0.000611\n",
      "be         0.000613  0.000724  0.000589  0.000717\n",
      "the        0.000728  0.000655  0.000666  0.000586\n",
      "to         0.000701  0.000629  0.000712  0.000593\n",
      "is         0.000601  0.000737  0.000661  0.000636\n",
      "in         0.000739  0.000645  0.000627  0.000621\n",
      "that       0.000696  0.000713  0.000611  0.000612\n",
      "only       0.000620  0.000687  0.000716  0.000608\n",
      "yes, however, with the top off and the rear window down this car is more  like a convertible than a coupe.  think of it as a convertible with an  integrated roll-bar like addition.\n",
      "predicted_topic = religion, actual_topic = space \n",
      "\n",
      "                autos  religion  graphics     space\n",
      "resulting    0.000000  0.000000  0.017126  0.000000\n",
      "frame        0.000779  0.000509  0.014014  0.000000\n",
      "train        0.015186  0.000000  0.000000  0.000000\n",
      "moral        0.000987  0.013670  0.000000  0.000418\n",
      "stationary   0.000000  0.000000  0.002001  0.011848\n",
      "bullet       0.012604  0.000000  0.000000  0.000000\n",
      "velocity     0.004110  0.000000  0.000000  0.006979\n",
      "relative     0.000000  0.007263  0.000144  0.003356\n",
      "table        0.000000  0.000000  0.005734  0.004522\n",
      "methods      0.001239  0.001032  0.007359  0.000091\n",
      "stiff        0.006671  0.002612  0.000000  0.000355\n",
      "moving       0.004380  0.000000  0.004505  0.000242\n",
      "zero         0.000000  0.001785  0.000973  0.005750\n",
      "reference    0.000057  0.001782  0.004927  0.000853\n",
      "deleted      0.000582  0.002543  0.000055  0.004062\n",
      "measured     0.000000  0.001183  0.002671  0.001890\n",
      "measure      0.001165  0.001248  0.000099  0.002959\n",
      "speed        0.002096  0.000000  0.001936  0.001330\n",
      "filled       0.001050  0.001156  0.002297  0.000154\n",
      "sitting      0.001230  0.000342  0.000593  0.002273\n",
      "off          0.001850  0.001678  0.000230  0.000647\n",
      "makes        0.001994  0.001324  0.000377  0.000504\n",
      "result       0.000231  0.001056  0.002017  0.000895\n",
      "value        0.001873  0.000999  0.000854  0.000261\n",
      "person       0.000960  0.001550  0.000172  0.001289\n",
      "problem      0.001291  0.000260  0.001461  0.000719\n",
      "people       0.001014  0.001621  0.000276  0.000794\n",
      "matter       0.001095  0.001246  0.001173  0.000185\n",
      "see          0.001201  0.001450  0.000341  0.000590\n",
      "next         0.001191  0.000893  0.000254  0.001045\n",
      "know         0.001036  0.000583  0.001199  0.000384\n",
      "exactly      0.001394  0.000584  0.000700  0.000512\n",
      "someone      0.000930  0.000682  0.000354  0.001138\n",
      "no           0.000920  0.001158  0.000387  0.000621\n",
      "interesting  0.000331  0.000813  0.001062  0.000842\n",
      "where        0.000596  0.000497  0.001166  0.000683\n",
      "way          0.000933  0.000858  0.000612  0.000427\n",
      "set          0.000723  0.000961  0.000615  0.000467\n",
      "every        0.001003  0.000625  0.000557  0.000572\n",
      "on           0.000726  0.000469  0.000920  0.000618\n",
      "same         0.000643  0.000686  0.000895  0.000475\n",
      "with         0.000683  0.000734  0.000817  0.000448\n",
      "at           0.000679  0.000478  0.000865  0.000653\n",
      "what         0.000719  0.000691  0.000786  0.000459\n",
      "here         0.000794  0.000568  0.000775  0.000512\n",
      "time         0.000537  0.000754  0.000762  0.000561\n",
      "but          0.000552  0.000649  0.000813  0.000590\n",
      "it           0.000747  0.000518  0.000697  0.000625\n",
      "all          0.000727  0.000706  0.000576  0.000561\n",
      "will         0.000537  0.000652  0.000651  0.000721\n",
      "be           0.000592  0.000699  0.000569  0.000692\n",
      "from         0.000574  0.000644  0.000616  0.000710\n",
      "the          0.000702  0.000632  0.000643  0.000566\n",
      "to           0.000677  0.000607  0.000688  0.000572\n",
      "is           0.000580  0.000711  0.000638  0.000614\n",
      "in           0.000714  0.000623  0.000605  0.000599\n",
      "that         0.000672  0.000688  0.000590  0.000591\n",
      "of           0.000652  0.000667  0.000623  0.000589\n",
      "warren brown, the washington post s auto writer was the first journalist to get his hands on the new yorker.  if you d like his impressions of it his review appeared in friday s paper, in the  weekend  section. he is not your traditional auto writer... enjoy.\n",
      "predicted_topic = graphics, actual_topic = religion \n",
      "\n",
      "             autos  religion  graphics     space\n",
      "planet    0.000000  0.000000  0.000000  0.006167\n",
      "lord      0.000000  0.006004  0.000000  0.000115\n",
      "morality  0.000133  0.005972  0.000000  0.000000\n",
      "vain      0.000000  0.006062  0.000000  0.000000\n",
      "shalt     0.000000  0.006062  0.000000  0.000000\n",
      "...            ...       ...       ...       ...\n",
      "is        0.000208  0.000255  0.000228  0.000220\n",
      "in        0.000256  0.000223  0.000217  0.000215\n",
      "that      0.000241  0.000246  0.000211  0.000211\n",
      "of        0.000233  0.000239  0.000223  0.000211\n",
      "one       0.000241  0.000231  0.000214  0.000220\n",
      "\n",
      "[162 rows x 4 columns]\n",
      "i have received my copies of cosmonautics 1990 and cosmonautics 1991, as well as soviet space 1990 and space station [mir] handbook from aerospace ambassadors with no problem.      i m getting ready to fax them some material in huntsville, and i ll include a printout of your inquiry.  ____________________________________________________________\n",
      "predicted_topic = space, actual_topic = religion \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "bookstore   0.000000  0.047629  0.000000  0.000000\n",
      "quicktime   0.000000  0.000000  0.047629  0.000000\n",
      "stock       0.044471  0.000000  0.000591  0.001984\n",
      "macintosh   0.000000  0.000000  0.003902  0.041111\n",
      "technical   0.001740  0.000000  0.009992  0.009801\n",
      "released    0.002259  0.006429  0.000342  0.005766\n",
      "volume      0.002493  0.000767  0.003069  0.007743\n",
      "inside      0.008128  0.001734  0.001733  0.002311\n",
      "reasonable  0.000519  0.002293  0.006632  0.004265\n",
      "apple       0.000762  0.006699  0.003264  0.002284\n",
      "new         0.006355  0.001122  0.002276  0.002347\n",
      "series      0.002763  0.000634  0.002974  0.005387\n",
      "any         0.002549  0.001729  0.004501  0.001226\n",
      "should      0.001814  0.002678  0.003382  0.001112\n",
      "just        0.003627  0.001546  0.001892  0.001691\n",
      "with        0.001981  0.002129  0.002371  0.001299\n",
      "have        0.002370  0.001724  0.001887  0.001582\n",
      "it          0.002166  0.001503  0.002022  0.001812\n",
      "the         0.002037  0.001834  0.001864  0.001641\n",
      "of          0.001890  0.001933  0.001807  0.001709\n",
      "gm, at least, is heading in that direction.  one of the post-sale questions they asked me was if i d like the choice of a cigarette liter or an accessory plug, and another whether i d like the choice of an ashtray or a cup holder.  the  93 geo storms have the cigarette lighter vs accessory plug option  which did not exist in the  92 i bought  -- i m not sure about the ash tray vs cup holder.  it s a step in the right direction.  the ashtray does make a convenient change-holder so it s not completely useless.\n",
      "predicted_topic = religion, actual_topic = graphics \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "greater    0.000000  0.012293  0.000000  0.098350\n",
      "matters    0.049153  0.018396  0.000000  0.003464\n",
      "knowledge  0.011669  0.008896  0.006230  0.001512\n",
      "ll         0.010341  0.003297  0.006928  0.003724\n",
      "such       0.004379  0.010148  0.003054  0.006155\n",
      "your       0.008220  0.005252  0.004068  0.003633\n",
      "to         0.004906  0.004401  0.004985  0.004148\n",
      "in         0.005175  0.004516  0.004389  0.004344\n",
      "i think the passage you re looking for is the following.  matthew 5:17     think not that i have come to abolish the law and the  prophets; i have come not to abolish them but to fulfil them.  matthew 5:18   for truly, i say to you, till heaven and earth pass away,  not an iota, not a dot, will pass from the law until all is accomplished.  matthew 5:19   whoever then relaxes one of the least of these commandments  and teaches men so, shall be called least in the kingdom of heaven; but he  who does them and teaches them shall be called great in the kingdom of  heaven.  matthew 5:20   for i tell you, unless your righteousness exceeds that of  the scribes and pharisees, you will never enter the kingdom of heaven.   there are several problems with this.  the most serious is that the law was regarded by jews at the time  and now  as binding on jews, but not on gentiles.  there are rules that were binding on all human beings  the so-called noachic laws , but they are quite minimal.  the issue that the church had to face after jesus  death was what to do about gentiles who wanted to follow christ.  the decision not to impose the law on them didn t say that the law was abolished.  it simply acknowledged that fact that it didn t apply to gentiles.  this is a simple answer, which i think just about everyone can agree to.  a discussion of the issue in more or less these terms is recorded in acts 15.   however there s more involved.  in order to get a full picture of the role of the law, we have to come to grips with paul s apparent rejection of the law, and how that relates to jesus  commendation of the law.  at least as i read paul, he says that the law serves a purpose that has been in a certain sense superceded.  again, this issue isn t one of the abolition of the law.  in the middle of his discussion, paul notes that he might be understood this way, and assures us that that s not what he intends to say.  rather, he sees the law as primarily being present to convict people of their sinfulness.  but ultimately it s an impossible standard, and one that has been superceded by christ.  paul s comments are not the world s clearest here, and not everyone agrees with my reading.  but the interesting thing to notice is that even this radical position does not entail an abolition of the law.  it still remains as an uncompromising standard, from which not an iota or dot may be removed. for its purpose of convicting of sin, it s important that it not be relaxed.  however for christians, it s not the end -- ultimately we live in faith, not law.  while the theoretical categories they use are rather different, in the end i think jesus and paul come to a rather similar conclusion.  the quoted passage from mat 5 should be taken in the context of the rest of the sermon on the mount, where jesus shows us how he interprets the law.  the  not an iota or dot  would suggest a rather literal reading, but in fact that s not jesus  approach.  jesus  interpretations emphasize the intent of the law, and stay away from the ceremonial details.  indeed he is well known for taking a rather free attitude towards the sabbath and kosher laws.  some scholars claim that mat 5:17-20 needs to be taken in the context of 1st cent. jewish discussions.  jesus accuses his opponents of caring about giving a tenth of even the most minor herbs, but neglecting the things that really matter: justice, mercy and faith, and caring about how cups and plates are cleaned, but not about the fact that inside the people who use them are full of extortion and rapacity.   mat 23:23-25  this, and the discussion later in mat 5, suggest that jesus has a very specific view of the law in mind, and that when he talks about maintaining the law in its full strength, he is thinking of these aspects of it. paul s conclusion is similar.  while he talks about the law being superceded, all of the specific examples he gives involve the  ceremonial law , such as circumcision and the sabbath.  he is quite concerned about maintaining moral standards.  the net result of this is that when paul talks about the law being superceded, and jesus talks about the law being maintained, i believe they are talking about different aspects of the law.  paul is embroiled in arguments about circumcision.  as is natural in letters responding to specific situations, he s looking at the aspect of the law that is currently causing trouble: the law as specifically jewish ceremonies.  he certainly does not intend to abolish divine standards of conduct.  on the other hand, when jesus commends the law, he seems to be talking the law in its broadest implications for morals and human relationships, and deemphasizing those aspects that were later to give paul so much trouble.\n",
      "predicted_topic = space, actual_topic = religion \n",
      "\n",
      "                 autos  religion  graphics     space\n",
      "exhaust       0.000000  0.000000  0.000000  0.024467\n",
      "energy        0.000000  0.000000  0.003672  0.019204\n",
      "prospects     0.000000  0.000000  0.000000  0.020307\n",
      "max           0.000000  0.000000  0.020307  0.000000\n",
      "con           0.003291  0.016753  0.000000  0.000000\n",
      "follow        0.001560  0.016401  0.000000  0.001876\n",
      "auto          0.012816  0.000000  0.001349  0.002722\n",
      "technology    0.001467  0.000000  0.002694  0.011893\n",
      "air           0.010490  0.002236  0.000031  0.001865\n",
      "solid         0.006960  0.000481  0.000078  0.005947\n",
      "gas           0.008513  0.003083  0.000000  0.001489\n",
      "email         0.002381  0.000000  0.007967  0.002046\n",
      "thread        0.000000  0.005770  0.001669  0.003140\n",
      "applications  0.001802  0.000000  0.005376  0.002975\n",
      "system        0.000621  0.000785  0.002178  0.003355\n",
      "anyone        0.002074  0.000386  0.003099  0.001189\n",
      "working       0.000549  0.000970  0.001862  0.002370\n",
      "kind          0.001316  0.001056  0.002251  0.000646\n",
      "mail          0.000826  0.001008  0.002353  0.001062\n",
      "may           0.001131  0.002128  0.001076  0.000716\n",
      "up            0.001955  0.001199  0.000984  0.000733\n",
      "we            0.000849  0.001945  0.000834  0.001217\n",
      "me            0.001091  0.001190  0.001639  0.000678\n",
      "interested    0.001200  0.000663  0.001587  0.001122\n",
      "for           0.001200  0.000777  0.001639  0.000926\n",
      "on            0.001169  0.000755  0.001481  0.000995\n",
      "or            0.000968  0.001013  0.001456  0.000867\n",
      "are           0.001226  0.001303  0.000853  0.000885\n",
      "have          0.001317  0.000958  0.001049  0.000879\n",
      "discussion    0.001008  0.000939  0.000932  0.001296\n",
      "this          0.000919  0.000991  0.001275  0.000976\n",
      "from          0.000925  0.001038  0.000992  0.001143\n",
      "the           0.001132  0.001019  0.001036  0.000912\n",
      "is            0.000934  0.001146  0.001028  0.000989\n",
      "in            0.001150  0.001004  0.000975  0.000965\n",
      "of            0.001050  0.001074  0.001004  0.000950\n",
      "if you want a summer without rain, you re in the wrong place. you must not have been here a whole year yet. keep the rain-x handy my friend.                thatch\n",
      "predicted_topic = space, actual_topic = autos \n",
      "\n",
      "            autos  religion  graphics     space\n",
      "car      0.010060  0.000035  0.000000  0.000000\n",
      "cars     0.010035  0.000047  0.000007  0.000000\n",
      "landing  0.000000  0.000000  0.000000  0.010076\n",
      "po       0.000000  0.000000  0.009726  0.000206\n",
      "pedal    0.009919  0.000000  0.000000  0.000000\n",
      "...           ...       ...       ...       ...\n",
      "all      0.000426  0.000414  0.000338  0.000329\n",
      "the      0.000412  0.000370  0.000377  0.000332\n",
      "to       0.000396  0.000356  0.000403  0.000335\n",
      "is       0.000340  0.000417  0.000374  0.000360\n",
      "of       0.000382  0.000391  0.000365  0.000345\n",
      "\n",
      "[99 rows x 4 columns]\n",
      "i m sure it is, and i am not amused.  every time i read that part of the tiff spec, it infuriates me- and i m none too happy about the complexity of the spec anyway- because i think their  arbitrary but carefully chosen number  is neither.  additionally, i find their choice of 4 bytes to begin a file with meaningless of themselves- why not just use the letters  tiff ?   and no, i don t think they should have bothered to support both word orders either- and i ve found that many tiff readers actually don t.\n",
      "predicted_topic = space, actual_topic = autos \n",
      "\n",
      "          autos  religion  graphics     space\n",
      "car    0.010163  0.000036  0.000000  0.000000\n",
      "cards  0.000000  0.000000  0.010195  0.000000\n",
      "cars   0.010137  0.000048  0.000007  0.000000\n",
      "card   0.000000  0.000000  0.010102  0.000081\n",
      "door   0.009294  0.000247  0.000000  0.000196\n",
      "...         ...       ...       ...       ...\n",
      "to     0.000400  0.000359  0.000407  0.000339\n",
      "is     0.000343  0.000421  0.000378  0.000363\n",
      "in     0.000422  0.000369  0.000358  0.000355\n",
      "that   0.000398  0.000407  0.000349  0.000349\n",
      "of     0.000386  0.000395  0.000369  0.000349\n",
      "\n",
      "[98 rows x 4 columns]\n",
      "just to remark that i have heard that david koresh has risen from  the dead.  i dont know if it is true or not, but this is what i have been told.  what do you guys think?\n",
      "predicted_topic = graphics, actual_topic = autos \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "killing     0.001196  0.015463  0.000000  0.000249\n",
      "watson      0.000000  0.000000  0.016619  0.000000\n",
      "passed      0.000000  0.000000  0.000000  0.016619\n",
      "rape        0.014334  0.001914  0.000000  0.000000\n",
      "violation   0.001123  0.014436  0.000000  0.000458\n",
      "ibm         0.000000  0.000000  0.011492  0.003026\n",
      "continues   0.000000  0.003003  0.000000  0.011194\n",
      "cruel       0.000000  0.013794  0.000000  0.000000\n",
      "orange      0.013794  0.000000  0.000000  0.000000\n",
      "lm          0.000000  0.000000  0.000000  0.013794\n",
      "forcing     0.013794  0.000000  0.000000  0.000000\n",
      "solely      0.009818  0.000000  0.000000  0.002771\n",
      "larry       0.007323  0.000000  0.000000  0.004314\n",
      "living      0.000000  0.007864  0.000361  0.003072\n",
      "friend      0.008247  0.002303  0.000022  0.000619\n",
      "her         0.003665  0.004875  0.000000  0.000495\n",
      "cold        0.002729  0.001206  0.000000  0.002375\n",
      "com         0.000880  0.004034  0.000628  0.000767\n",
      "down        0.002610  0.001591  0.000011  0.001638\n",
      "ever        0.002126  0.001503  0.000040  0.001670\n",
      "body        0.002716  0.000880  0.000246  0.001362\n",
      "difference  0.002189  0.001085  0.000103  0.001807\n",
      "remain      0.000762  0.002376  0.000279  0.001429\n",
      "being       0.000502  0.002148  0.000521  0.001230\n",
      "true        0.000938  0.002238  0.000716  0.000472\n",
      "life        0.000685  0.002224  0.000555  0.000835\n",
      "right       0.002167  0.000578  0.000574  0.000951\n",
      "away        0.001758  0.001226  0.000210  0.001074\n",
      "nothing     0.000821  0.001831  0.000363  0.000985\n",
      "see         0.001314  0.001587  0.000374  0.000645\n",
      "months      0.001119  0.000316  0.000881  0.001241\n",
      "take        0.001268  0.001065  0.000476  0.000584\n",
      "because     0.000991  0.001216  0.000426  0.000687\n",
      "between     0.000723  0.001269  0.000877  0.000437\n",
      "my          0.001335  0.000763  0.000638  0.000548\n",
      "for         0.000815  0.000527  0.001113  0.000629\n",
      "another     0.000707  0.001069  0.000832  0.000473\n",
      "an          0.001028  0.000644  0.000684  0.000599\n",
      "what        0.000787  0.000756  0.000860  0.000502\n",
      "has         0.000950  0.000615  0.000744  0.000596\n",
      "there       0.000708  0.000616  0.000938  0.000622\n",
      "not         0.000710  0.000913  0.000567  0.000686\n",
      "but         0.000604  0.000710  0.000890  0.000645\n",
      "it          0.000817  0.000567  0.000763  0.000684\n",
      "this        0.000625  0.000673  0.000866  0.000663\n",
      "as          0.000700  0.000816  0.000567  0.000743\n",
      "will        0.000587  0.000714  0.000713  0.000789\n",
      "from        0.000629  0.000705  0.000674  0.000777\n",
      "the         0.000769  0.000692  0.000703  0.000619\n",
      "to          0.000740  0.000664  0.000752  0.000626\n",
      "is          0.000635  0.000779  0.000698  0.000672\n",
      "that        0.000736  0.000753  0.000645  0.000646\n",
      "of          0.000713  0.000729  0.000682  0.000645\n",
      "i can t fiqure this out.  i have properly compiled pov on a unix machine running sunos 4.1.3  the problem is that when i run the sample .pov files and use the exact same parameters when compiling different .tga outputs.  some of the .tga s are okay, and other s are unrecognizable by any software.\n",
      "predicted_topic = graphics, actual_topic = religion \n",
      "\n",
      "                 autos  religion  graphics     space\n",
      "views         0.000000  0.043371  0.000000  0.000000\n",
      "energy        0.000000  0.000000  0.005748  0.030059\n",
      "ward          0.031746  0.001764  0.000000  0.001821\n",
      "universities  0.000000  0.000000  0.000000  0.031785\n",
      "association   0.000000  0.023712  0.000000  0.007648\n",
      "disclaimer    0.007767  0.000000  0.022034  0.000000\n",
      "fiction       0.000000  0.009024  0.000000  0.020074\n",
      "represent     0.000000  0.014075  0.006320  0.001515\n",
      "research      0.000000  0.002911  0.004392  0.009222\n",
      "department    0.004287  0.000000  0.003461  0.006033\n",
      "opinion       0.006212  0.003043  0.000100  0.003904\n",
      "regular       0.005961  0.000723  0.001494  0.003662\n",
      "science       0.001779  0.001533  0.001240  0.003607\n",
      "does          0.002166  0.001612  0.002328  0.001041\n",
      "organization  0.001408  0.002610  0.001474  0.001537\n",
      "or            0.001515  0.001585  0.002279  0.001358\n",
      "not           0.001636  0.002103  0.001306  0.001581\n",
      "and           0.001720  0.001476  0.001976  0.001370\n",
      "this          0.001439  0.001551  0.001996  0.001528\n",
      "mine          0.001715  0.001546  0.001418  0.001744\n",
      "the           0.001771  0.001595  0.001621  0.001427\n",
      "is            0.001462  0.001794  0.001609  0.001548\n",
      "of            0.001644  0.001681  0.001571  0.001486\n",
      "/*  this program doesn t detect edges with compass operators and a laplacian operator. it should output 2 raw grey-scale images with edges. the output doesn t look like edges at all.  in novicee terms, how do i correct the errors? any improvements are welcome.  i ll even accept your corrected code.    if i convolve the input.image with a digital gaussian [7 by 7] to remove noise, will i get an improvement with the laplacian.   --------------------------2 types of edge detection-------------------------*/ #include <stdio.h>  #include <math.h>   #define imagewidth 300 #define imageheight 300  unsigned char input_image [imageheight][imagewidth];  unsigned char angles_wanted [imageheight][imagewidth]; unsigned char magnitude_image [imageheight][imagewidth];  int laplace_op1 [3][3] =   0,-1, 0, -1,4,-1,  0,-1, 0 ;  int compass_op1 [3][3] =   1, 1, 1,  0,0, 0, -1,-1,-1 ; int compass_op2 [3][3] =   1, 1, 0,  1,0,-1,  0,-1,-1 ; int compass_op3 [3][3] =   1, 0,-1,  1,0,-1,  1, 0,-1 ; int compass_op4 [3][3] =   0,-1,-1,  1,0,-1,  1, 1, 0 ; int compass_op5 [3][3] =  -1,-1,-1,  0,0, 0,  1, 1, 1 ; int compass_op6 [3][3] =  -1,-1, 0, -1,0, 1,  0, 1, 1 ; int compass_op7 [3][3] =  -1, 0, 1, -1,0, 1, -1, 0, 1 ; int compass_op8 [3][3] =   0, 1, 1, -1,0, 1, -1,-1, 0 ;  void compass  row,col  int row,col;     int value;   int op_rows, op_cols;   int compass1,compass2,compass3,compass4;   int compass5,compass6,compass7,compass8;      compass1 = compass2 = compass3 = compass4 = 0;   compass5 = compass6 = compass7 = compass8 = 0;      for  op_rows = -1; op_rows < 2; op_rows++      for  op_cols = -1; op_cols < 2; op_cols++           if    row + op_rows  >= 0  &&   col + op_cols  >= 0                   compass1 +=   int  input_image [row + op_rows][col + op_cols]  *                          compass_op1 [op_rows + 1][op_cols + 1];      compass2 +=   int  input_image [row + op_rows][col + op_cols]  *                          compass_op2 [op_rows + 1][op_cols + 1];      compass3 +=   int  input_image [row + op_rows][col + op_cols]  *                          compass_op3 [op_rows + 1][op_cols + 1];      compass4 +=   int  input_image [row + op_rows][col + op_cols]  *                          compass_op4 [op_rows + 1][op_cols + 1];      compass5 +=   int  input_image [row + op_rows][col + op_cols]  *                          compass_op5 [op_rows + 1][op_cols + 1];      compass6 +=   int  input_image [row + op_rows][col + op_cols]  *                          compass_op6 [op_rows + 1][op_cols + 1];      compass7 +=   int  input_image [row + op_rows][col + op_cols]  *                          compass_op7 [op_rows + 1][op_cols + 1];      compass8 +=   int  input_image [row + op_rows][col + op_cols]  *                          compass_op8 [op_rows + 1][op_cols + 1];                      if  compass1 < compass2      value = compass2;   else      value = compass1;         if  value < compass3      value = compass3;   if  value < compass4      value = compass4;   if  value < compass5      value = compass5;   if  value < compass6      value = compass6;   if  value < compass7      value = compass7;   if  value < compass8      value = compass8;    magnitude_image [row][col] =  char  value;    void laplace1  row,col  int row,col;     int op_rows, op_cols;    magnitude_image [row][col] = 0;   for  op_rows = -1; op_rows < 2; op_rows++      for  op_cols = -1; op_cols < 2; op_cols++        if    row + op_rows  >= 0  &&   col + op_cols  >= 0    magnitude_image [row][col] =      char    int magnitude_image [row][col] +       int  input_image [row + op_rows][col + op_cols] *       laplace_op1 [op_rows + 1][op_cols + 1]  ;    main         file *original_image_fp;   file *laplace1_mag_fp,*laplace2_mag_fp,*laplace3_mag_fp;   file *compass_mag_fp;    int row, col, algo_count;    original_image_fp = fopen   input.image , rb  ;    laplace1_mag_fp = fopen   laplace1_magnitude , wb  ;   compass_mag_fp = fopen   compass_magnitude , wb  ;    fread   unsigned char *  input_image,sizeof unsigned char ,imageheight * imagewidth,original_image_fp ;   for  algo_count = 0; algo_count < 2;algo_count ++              for  row = 0; row < imageheight; row++    for  col = 0; col < imagewidth; col++      if   algo_count       laplace1  row,col ;    else       compass  row,col ;              if   algo_count   fwrite magnitude_image,sizeof char ,imageheight * imagewidth,laplace1_mag_fp ;       else   fwrite magnitude_image,sizeof char ,imageheight * imagewidth,compass_mag_fp ;\n",
      "predicted_topic = religion, actual_topic = space \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "unknown    0.000000  0.000000  0.009369  0.000186\n",
      "pressures  0.000000  0.000000  0.000000  0.009248\n",
      "millions   0.000000  0.000000  0.000000  0.009248\n",
      "bow        0.008551  0.000000  0.000000  0.000000\n",
      "license    0.007758  0.000559  0.000071  0.000120\n",
      "...             ...       ...       ...       ...\n",
      "to         0.000381  0.000342  0.000387  0.000322\n",
      "is         0.000326  0.000401  0.000359  0.000346\n",
      "in         0.000402  0.000351  0.000341  0.000337\n",
      "that       0.000379  0.000388  0.000332  0.000333\n",
      "only       0.000337  0.000373  0.000389  0.000331\n",
      "\n",
      "[103 rows x 4 columns]\n",
      "this is turning into  what s a moonbase good for , and i ought not to post when i ve a hundred some odd posts to go, but i would think that the real reason to have a moon base is economic.  since someone with space industry will presumeably have a much larger gnp than they would _without_ space industry, eventually, they will simply be able to afford more stuff.\n",
      "predicted_topic = graphics, actual_topic = autos \n",
      "\n",
      "           autos  religion  graphics     space\n",
      "eve     0.000000  0.140288  0.000000  0.000000\n",
      "bitnet  0.000000  0.000000  0.009185  0.124060\n",
      "home    0.037545  0.010592  0.007549  0.001598\n",
      "heavy   0.017498  0.011668  0.000215  0.012427\n",
      "edu     0.008989  0.001763  0.014708  0.007650\n",
      "go      0.009467  0.006083  0.003552  0.005454\n",
      "or      0.004979  0.005209  0.007489  0.004461\n",
      "mark prado       old pioneer song from the 1850 s or so goes as follows:       in a cavern, in a canyon,    excavating for a mine,    dwelt a miner, forty-niner,    and his daughter, clementine     chorus:    oh my darling, oh my darling,    oh my darling clementine.    you are lost and gone forever,    oh my darling clementine.      i ve also had it explained  but not confirmed from a reliable data source  that clementine is an acronym.  something like combined lunar elemental mapper experiment on extended non terrestrial intercept near earth.  personally, i think that acronym was made up to fit the name  if it really is an acronym .  ------------------------------------------------------------------  wales larrison                           space technology investor\n",
      "predicted_topic = religion, actual_topic = graphics \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             autos  religion  graphics     space\n",
      "lovely    0.000000  0.000000  0.036700  0.000000\n",
      "dwell     0.000000  0.030461  0.000000  0.000000\n",
      "worthy    0.000000  0.023847  0.000000  0.005375\n",
      "praise    0.014507  0.010484  0.000000  0.000000\n",
      "phil      0.000000  0.010980  0.000000  0.011737\n",
      "pure      0.000000  0.005836  0.003049  0.004284\n",
      "whatever  0.001580  0.005382  0.003339  0.000638\n",
      "true      0.002072  0.004942  0.001582  0.001041\n",
      "right     0.004786  0.001276  0.001267  0.002100\n",
      "any       0.002124  0.001441  0.003751  0.001022\n",
      "things    0.001409  0.002351  0.000953  0.003215\n",
      "let       0.002983  0.001948  0.001535  0.000998\n",
      "mind      0.001341  0.003050  0.001327  0.001613\n",
      "finally   0.001067  0.002056  0.002559  0.001386\n",
      "your      0.002740  0.001751  0.001356  0.001211\n",
      "good      0.002341  0.001969  0.001872  0.000872\n",
      "anything  0.001285  0.001800  0.001255  0.002460\n",
      "on        0.001754  0.001133  0.002222  0.001493\n",
      "these     0.002198  0.001746  0.001519  0.001123\n",
      "there     0.001563  0.001360  0.002071  0.001373\n",
      "if        0.001928  0.001313  0.001705  0.001368\n",
      "and       0.001649  0.001415  0.001894  0.001313\n",
      "is        0.001401  0.001719  0.001542  0.001483\n",
      "of        0.001575  0.001611  0.001506  0.001424\n",
      "sorry for wasting your time with a probably simple question, but i m not an computer graphic expert. i want to read tiff-files with a pascal-program. the problem is, that the files i want to read are in compressed form    code 1, e.g. huffman  . all books & articles i found describe only the plain  uncompressed  format. i don t know where to get the original tiff specification, furthermore i haven t any access to a realy complete library. can anybody direct me to a good book or  even better  to an  specification available via ftp ?  thanks in advance - thomas wolf\n",
      "predicted_topic = graphics, actual_topic = religion \n",
      "\n",
      "            autos  religion  graphics     space\n",
      "arrange  0.000000  0.000000  0.034059  0.011585\n",
      "table    0.000000  0.000000  0.023756  0.018736\n",
      "order    0.000613  0.017344  0.004217  0.005233\n",
      "left     0.010883  0.002911  0.002445  0.002761\n",
      "flat     0.003553  0.004184  0.009584  0.001113\n",
      "right    0.008204  0.002187  0.002172  0.003599\n",
      "place    0.004452  0.005887  0.001381  0.002664\n",
      "your     0.004697  0.003001  0.002324  0.002076\n",
      "hands    0.003472  0.003094  0.003056  0.001725\n",
      "on       0.003007  0.001942  0.003809  0.002560\n",
      "and      0.002826  0.002425  0.003246  0.002251\n",
      "from     0.002379  0.002669  0.002551  0.002940\n",
      "the      0.002910  0.002620  0.002663  0.002345\n",
      "to       0.002803  0.002515  0.002849  0.002370\n",
      "hi,  i m interested in writing a program to generate a sird picture, you know the stereogram where you cross your eyes and the picture becomes 3d.  does anyone have one or know where i can get one?  please e-mail to steveq@sndcrft.dialix.oz.au with any replies.  many thanks for your help.\n",
      "predicted_topic = graphics, actual_topic = autos \n",
      "\n",
      "                   autos  religion  graphics     space\n",
      "million         0.000000  0.000000  0.000000  0.038457\n",
      "packages        0.000000  0.000000  0.029222  0.004127\n",
      "software        0.000000  0.000000  0.025627  0.005416\n",
      "recommendation  0.028118  0.000000  0.000000  0.000000\n",
      "pointers        0.009979  0.000000  0.014268  0.000000\n",
      "greatly         0.001150  0.004320  0.017466  0.000186\n",
      "ge              0.000000  0.000000  0.010130  0.010839\n",
      "commercial      0.000000  0.001521  0.005071  0.013093\n",
      "designers       0.010255  0.000000  0.007940  0.000789\n",
      "appreciated     0.003678  0.000000  0.012727  0.002398\n",
      "thanks          0.004245  0.000379  0.010269  0.001299\n",
      "hello           0.002334  0.000000  0.008908  0.004168\n",
      "looking         0.002421  0.000562  0.009675  0.002134\n",
      "professional    0.000000  0.001943  0.005925  0.006236\n",
      "fashion         0.003140  0.002611  0.000191  0.004323\n",
      "please          0.001264  0.001739  0.003757  0.001132\n",
      "any             0.001961  0.001330  0.003462  0.000943\n",
      "am              0.001747  0.001118  0.003443  0.001238\n",
      "mail            0.001143  0.001395  0.003258  0.001471\n",
      "may             0.001566  0.002946  0.001489  0.000992\n",
      "me              0.001510  0.001648  0.002269  0.000939\n",
      "for             0.001662  0.001075  0.002269  0.001282\n",
      "are             0.001698  0.001805  0.001182  0.001225\n",
      "you             0.001716  0.001344  0.001666  0.001124\n",
      "if              0.001779  0.001212  0.001574  0.001262\n",
      "and             0.001522  0.001306  0.001748  0.001212\n",
      "i can t find ctds  connect the dots smoother  in france. if it is a commercial program i ll happily pay whatever it may cost  do not take it litterally . please help  i have *lots* of pov sources, texture images and animations though, if you are looking for something, just tell.\n",
      "predicted_topic = space, actual_topic = graphics \n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [autos, religion, graphics, space]\n",
      "Index: []\n",
      "#rick anderson replied to my letter with... # #ra> in article <c5elp2.l0c@acsu.buffalo.edu>, #ra>   ...   # just briefly, on something that you mentioned in passing. you refer to # differing interpretations of  create,  and say that many christians may # not agree. so what? that is really irrelevant. we do not base our faith # on how many people think one way or another, do we? the bottom line is # truth, regardless of popularity of opinions.  it may be  irrelevant  to you and *your* personal beliefs  or should i say  bias ? , but it is relevant to me and many others.  you re right,  the bottom line is truth,  independant from you or anyone else.  since you proclaim  truths  as a self-proclaimed appointee, may i ask you by what authority you do this?  because  it says so in the bible?   --does the bible  say so,  or is it you, or someone else, who interprets whether a scripture or doctrine conforms to your particular liking or  disapproval ?  excuse moi, but your line of  truths  haven t moved me one bit to persuade me that my beliefs are erroneous.  of all the  preachers  of  truth  on this net, you have struck me as a self-righteous member of the wrecking crew, with no positive message to me or any other latter-day saint... btw, this entire discussion reminds me a lot of the things said by jesus to the pharisees:  ye hypocrite s  . . . ye preach about me with your lips, but your hearts are far removed from me...   # also, i find it rather strange that in trying to persuade that created # and eternally existent are equivalent, you say  granted the mormon # belief...  you can t grant your conclusion and then expect the point to # have been addressed. in order to reply to the issue, you have to address # and answer the point that was raised, and not just jump to the # conclusion that you grant.  sophistry.  look who s talking:  jumping to conclusions?   you wouldn t do that yourself, right?  all you address is your own convictions, regardless whether we come up with any biblical scriptures which supports our points of view, because you reject such interpretations without any consideration whatsoever.  # # the bible states that lucifer was created.  the bible states that jesus # is the creator of all. the contradiction that we have is that the lds # belief is that jesus and lucifer were the same.  a beautiful example of disinformation and a deliberate misrepresentation of lds doctrine.  the former kgb would have loved to employ you. jesus and lucifer are not  the same,  silly, and you know it.   ...   # the mormon belief is that all are children of god. literally. there is # nothing symbolic about it. this however, contradicts what the bible # says. the bible teaches that not everyone is a child of god:  correction: it may contradict would you think the bible says.  the bible indeed does teach that not all are children of god in the sense that they  belong to  or follow god in his footsteps.  satan and his followers have rebelled against god, and are not  children  =followers/redeemed  of god,  but it doesn t mean that they were not once created by god, but chose to separate themselves from those who chose to follow god and his plan of salvation.  # #        the field is the world; the good seed are the children of the #        kingdom; but the tares are the children of the wicked  one ; #         matthew 13:38   kingdom are those who have remained valiant in their testimony of jesus  and have shown  works of repentance, etc. , and the children of the wicked one are those who rebelled against god and the lamb.  the issue of satan s spirit-origin  and of those who followed him  has not been addressed in this and other verses you copied from your bible.  you purposefully obscured the subject by swamping your  right  with non- related scriptures.   ...lots of nice scriptures deleted  not robert w. copyrighted  though...   #ra> > we are told that,  and this is life eternal, that they might know #ra> > thee the only true god, and jesus christ, whom thou hast sent.  #ra> >  john 17:3 . life eternal is to know the only true god. yet the #ra> > doctrines of the lds that i have mentioned portray a vastly #ra> > different jesus, a jesus that cannot be reconciled with the jesus of #ra> > the bible. they are so far removed from each other that to proclaim  correction:  my  jesus is indeed different than your jesus, and can be reconciled with the jesus in the bible.  --not your interpretation of him, i concur, but i honestly couldn t care less.  #ra> > one as being true denies the other from being true. according to the #ra> > bible, eternal life is dependent on knowing the only true god, and #ra> > not the construct of imagination.  in this single posting of yours, i ve seen more  constructs of imagination  than in all of the pro-lds mails combined i have read so far in this news group.  first get your lds-facts straight before you dare preaching to us about  the only true god,  whom you interpret according to your own likes and dislikes, but whose image i cannot reconcile with what i know about him myself.  i guess your grandiose self-image does not allow for other faiths, believing in the divinity of jesus christ, but in a different way or fashion than your own.  not that it really matters, the mission and progress of the lds church will go on, boldly and nobly, and no mob or opponent can stop the work from progressing, until it has visited every continent, swept every clime, and sounded in every ear.  #  this is really a red herring. it doesn t address any issue raised, but #  rather, it seeks to obfuscate. the fact that some groups try to read #  something into the bible, doesn t change what the bible teaches.  sigh.   what the bible teaches ?  or:  what the bible teaches according to robert weiss and co.?   i respect the former, i reject the latter without the remotest feeling that i have rejected jesus.  on the contrary.  and by the way, i do respect your interpretations of the bible, i even grant you being a christian  following your own image of him , as much as i am a christian  following my own image of him in my heart .   ...   #  most of the other replies have instead hop-scotched to the issue of #  bruce mcconkie and whether his views were  official doctrine.  i don t #  think that it matters if mcconkie s views were canon. that is not the #  issue.  were mcconkie s writings indicative of mormon belief on this #  subject is the real issue. the indication from rick is that they may #  certainly be.  the issue is, of course, that you love to use anything to either mis- represent or ridicule the lds church.  the issue of  official doctrine  is obviously very important.  mcconkie s views have been controversial  e.g.  the seven deadly heresies  has made me a heretic   ;-  at best, or erroneous at worst   blacks not to receive the priesthood in this dispensation  .  i respect him as someone who has made his valuable contribution to the church, but i personally do not rely on his personal interpretations  his book  mormon doctrine  is oftentimes referred to as  mcconkie s bible  in mormon circles  on mormon doctrine.  i rather look to official  doctrinal  sources, and... to hugh nibley s books   the last comment is an lds-insider reference.   summarizing: mcconkie was a wise man who contributed undoubtedly far more to the kingdom of god than i have, but whose views are by no means dogma or accepted doctrine, some of it clearly belongs to personal interpretation and speculation.  but having said this, i find mcconkie  even in his most biased and speculative moments  far more thought-provoking than the trash coming from your proverbial pen.  i m somewhat appalled that i have allowed myself to sink as low as you in this posting...  ============================= robert weiss psyrobtw@ubvms.cc.buffalo.edu\n",
      "predicted_topic = autos, actual_topic = religion \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "texture     0.000000  0.000000  0.013796  0.000000\n",
      "industrial  0.000000  0.000000  0.001289  0.011127\n",
      "liking      0.000000  0.012233  0.000000  0.000000\n",
      "space       0.000221  0.000087  0.000845  0.010790\n",
      "_that_      0.000000  0.000000  0.000000  0.010154\n",
      "...              ...       ...       ...       ...\n",
      "the         0.000566  0.000509  0.000518  0.000456\n",
      "to          0.000545  0.000489  0.000554  0.000461\n",
      "that        0.000542  0.000555  0.000475  0.000476\n",
      "only        0.000482  0.000534  0.000557  0.000473\n",
      "of          0.000525  0.000537  0.000502  0.000475\n",
      "\n",
      "[72 rows x 4 columns]\n",
      "you can avoid these problems entirely by installing an oil drain valve in place of the bolt.  i have one on both of my cars.  there have been no leaks in 210,000 miles  combined miles on both cars .\n",
      "predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "             autos  religion  graphics     space\n",
      "pictures  0.000000  0.001025  0.057909  0.001321\n",
      "loads     0.000000  0.000000  0.055050  0.000000\n",
      "fold      0.000000  0.000000  0.045691  0.000000\n",
      "dotted    0.000000  0.000000  0.045691  0.000000\n",
      "deck      0.000000  0.000000  0.045691  0.000000\n",
      "wings     0.000000  0.030352  0.000000  0.012375\n",
      "line      0.003121  0.002469  0.006547  0.001421\n",
      "no        0.003336  0.004199  0.001403  0.002250\n",
      "they      0.004176  0.002465  0.001630  0.002427\n",
      "look      0.003700  0.001457  0.002730  0.002556\n",
      "on        0.002631  0.001699  0.003333  0.002240\n",
      "with      0.002476  0.002662  0.002963  0.001624\n",
      "at        0.002461  0.001733  0.003137  0.002366\n",
      "all       0.002636  0.002561  0.002089  0.002033\n",
      "the       0.002546  0.002292  0.002330  0.002052\n",
      "of        0.002363  0.002416  0.002258  0.002137\n",
      "i m interested in simulating reverse  or negative  color video mathematically.  what is the transform?  is it a simple reversal of the hue value in the hsv color space?  is it a manipulation in the yuv color space?  how is it related to solarization?  if you want to see something truly wild, turn on the reverse video effect on a camcorder so equipped, and point it at the monitor.  this creates a chaotic dynamical system whose phase space is continuous along rotation, zoom, focus, etc.  very very surprising and  lovely.  i d like to write a simulation of this effect without analog grunge.  thanks for any info you may have.  please e-mail any info to me.  i ll post a summary.  thanks,  --\n",
      "predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "cr         0.108744  0.000000  0.000000  0.001216\n",
      "believers  0.000000  0.109113  0.000000  0.000000\n",
      "religious  0.007244  0.097016  0.000000  0.000000\n",
      "true       0.005525  0.013179  0.004218  0.002777\n",
      "number     0.003169  0.007110  0.012143  0.002877\n",
      "my         0.007861  0.004491  0.003759  0.003230\n",
      "and        0.004396  0.003772  0.005050  0.003502\n",
      "the        0.004527  0.004075  0.004142  0.003648\n",
      "of         0.004201  0.004296  0.004015  0.003798\n",
      ">this is turning into  what s a moonbase good for , and i ought not    >to post when i ve a hundred some odd posts to go, but i would    >think that the real reason to have a moon base is economic.    >    >since someone with space industry will presumeably have a much    >larger gnp than they would _without_ space industry, eventually,    >they will simply be able to afford more stuff.     if i read you right, you re saying in essence that, with a larger    economy, nations will have more discretionary funds to *waste* on a    lunar facility. that was certainly partially the case with apollo,    but real lunar colonies will probably require a continuing    military, scientific, or commercial reason for being rather than    just a  we have the money, why not?  approach.  ah, but the whole point is that money spent on a lunar base is not wasted on the moon. it s not like they d be using $1000  1000r?  bills to fuel their moon-dozers. the money to fund a lunar base would be spent in the country to which the base belonged. it s a way of funding high-tech research, just like darpa was a good excuse to fund various fields of research, under the pretense that it was crucial to the defense of the country, or like esprit is a good excuse for the ec to fund research, under the pretense that it s good for pan-european cooperation.  now maybe you think that government-funded research is a waste of money  in fact, i m pretty sure you do , but it does count as investment spending, which does boost the economy  and just look at the size of that multiplier :-> .\n",
      "predicted_topic = religion, actual_topic = autos \n",
      "\n",
      "                autos  religion  graphics     space\n",
      "physics      0.000000  0.000000  0.000363  0.016116\n",
      "abstract     0.000000  0.000000  0.015876  0.000000\n",
      "precisely    0.000000  0.013722  0.000365  0.000834\n",
      "strive       0.000000  0.014680  0.000000  0.000000\n",
      "objective    0.000000  0.010226  0.000000  0.002647\n",
      "lsd          0.000000  0.012184  0.000000  0.000000\n",
      "fiction      0.000000  0.003459  0.000000  0.007695\n",
      "string       0.003053  0.000000  0.000000  0.007025\n",
      "einstein     0.005755  0.000000  0.000000  0.003644\n",
      "gas          0.005108  0.001850  0.000000  0.000893\n",
      "medicine     0.000000  0.004678  0.000753  0.001962\n",
      "traditional  0.003866  0.002346  0.000051  0.000603\n",
      "results      0.000905  0.004126  0.000647  0.000516\n",
      "told         0.003755  0.001432  0.000430  0.000413\n",
      "exist        0.001479  0.003196  0.000000  0.001304\n",
      "respond      0.001076  0.002918  0.001858  0.000000\n",
      "ideal        0.000860  0.003038  0.001807  0.000056\n",
      "prove        0.001932  0.002929  0.000638  0.000132\n",
      "reality      0.000000  0.002366  0.001235  0.001762\n",
      "useful       0.001349  0.000492  0.002720  0.000361\n",
      "towards      0.000357  0.001791  0.000396  0.001975\n",
      "us           0.001553  0.001522  0.000266  0.000592\n",
      "alternative  0.000672  0.001926  0.000511  0.000631\n",
      "light        0.001156  0.000937  0.000183  0.001409\n",
      "people       0.000980  0.001567  0.000267  0.000767\n",
      "consider     0.000851  0.001467  0.000564  0.000415\n",
      "were         0.001127  0.001260  0.000370  0.000528\n",
      "things       0.000564  0.000940  0.000381  0.001286\n",
      "too          0.001265  0.000883  0.000542  0.000413\n",
      "should       0.000605  0.000893  0.001127  0.000371\n",
      "no           0.000890  0.001120  0.000374  0.000600\n",
      "sufficient   0.000308  0.000884  0.000936  0.000809\n",
      "like         0.001028  0.000326  0.000808  0.000771\n",
      "get          0.001040  0.000342  0.000818  0.000715\n",
      "we           0.000510  0.001167  0.000500  0.000730\n",
      "they         0.001114  0.000657  0.000435  0.000647\n",
      "about        0.001007  0.000840  0.000576  0.000408\n",
      "talk         0.000490  0.000757  0.000505  0.001076\n",
      "doesn        0.000629  0.000839  0.000928  0.000386\n",
      "some         0.000530  0.000475  0.000955  0.000751\n",
      "can          0.000748  0.000436  0.000928  0.000588\n",
      "far          0.000525  0.000821  0.000475  0.000842\n",
      "others       0.000738  0.000876  0.000612  0.000431\n",
      "an           0.000908  0.000569  0.000604  0.000529\n",
      "or           0.000581  0.000608  0.000874  0.000520\n",
      "wrong        0.000791  0.000662  0.000688  0.000441\n",
      "actually     0.000791  0.000470  0.000606  0.000690\n",
      "there        0.000625  0.000544  0.000828  0.000549\n",
      "not          0.000627  0.000806  0.000501  0.000606\n",
      "if           0.000771  0.000525  0.000682  0.000547\n",
      "have         0.000790  0.000575  0.000629  0.000527\n",
      "but          0.000534  0.000627  0.000786  0.000570\n",
      "and          0.000659  0.000566  0.000758  0.000525\n",
      "it           0.000722  0.000501  0.000674  0.000604\n",
      "as           0.000619  0.000720  0.000501  0.000656\n",
      "be           0.000572  0.000676  0.000550  0.000669\n",
      "from         0.000555  0.000623  0.000595  0.000686\n",
      "to           0.000654  0.000587  0.000665  0.000553\n",
      "that         0.000650  0.000666  0.000570  0.000571\n",
      "only         0.000579  0.000641  0.000668  0.000567\n",
      "some rendering programs require that all surface normals point in the same direction.   ie: on a closed cube, all normals point outwards .  you can use the points on the faces to determine the direction of the normal, by making sure that all points are either in clockwise or counter-clockwise order.  how do you go about orienting all normals in the same direction, given a  set of points, edges and faces?   say that you had a cube with all faces that  have their normals facing outwards, except for one face.  what s the best way to realize that face is  flipped , and should have it s points re-ordered?   i thought i had a good way of telling this, but then realized that the algorithm i had would only tell you if you had points in clockwise order for a 2d polygon.  i d like something for 3d data.  any hints, tips, references would be appreciated.  steve\n",
      "predicted_topic = space, actual_topic = religion \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "identical  0.056034  0.000000  0.000000  0.000000\n",
      "scanners   0.000000  0.000000  0.051812  0.000000\n",
      "drek       0.000000  0.043003  0.000000  0.000000\n",
      "neutrino   0.000000  0.000000  0.000000  0.043003\n",
      "star       0.000000  0.004955  0.002456  0.034799\n",
      "next       0.004065  0.003045  0.000865  0.003564\n",
      "re         0.005099  0.002661  0.001324  0.002444\n",
      "they       0.003931  0.002320  0.001534  0.002284\n",
      "got        0.003330  0.001874  0.001651  0.002728\n",
      "can        0.002640  0.001539  0.003275  0.002077\n",
      "them       0.002095  0.002970  0.001533  0.002763\n",
      "how        0.002289  0.002564  0.001490  0.002969\n",
      "tell       0.002133  0.002962  0.001852  0.002067\n",
      "you        0.002625  0.002056  0.002549  0.001718\n",
      "the        0.002397  0.002157  0.002193  0.001931\n",
      "of         0.002224  0.002274  0.002125  0.002011\n",
      "one        0.002300  0.002199  0.002038  0.002097\n",
      "nut or not, he was clearly a liar.  he said he would surrender after   local radio stations broadcast his message, but he didn t.  then he   said he would surrender after passover, but he didn t.    none of which excuses the gross incompetence and disregard for the   safety of the children displayed by the feds.   as someone else   pointed out, if it had been chelsea clinton in there you would    probably have seen more restraint.\n",
      "predicted_topic = autos, actual_topic = space \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "songs       0.000000  0.073400  0.000000  0.000000\n",
      "lemur       0.000000  0.000000  0.000000  0.060922\n",
      "elvis       0.000000  0.000000  0.000000  0.060922\n",
      "listen      0.020808  0.013106  0.000000  0.003122\n",
      "definitely  0.004895  0.012635  0.000000  0.010721\n",
      "spell       0.000000  0.007477  0.011926  0.006834\n",
      "his         0.004263  0.013000  0.001166  0.005294\n",
      "couldn      0.004600  0.002312  0.002457  0.008369\n",
      "any         0.004249  0.002882  0.007501  0.002044\n",
      "just        0.006044  0.002577  0.003153  0.002819\n",
      "to          0.003270  0.002934  0.003323  0.002765\n",
      "of          0.003150  0.003222  0.003011  0.002849\n",
      ": >hi netters, : > : >i m building a cad package and need a 3d graphics library that can handle : >some rudimentry tasks, such as hidden line removal, shading, animation, etc. : > : >can you please offer some recommendations? : > : >i ll also need contact info  name, address, email...  if you can find it. : > : >thanks : > : > please post your responses, in case others have same need  : > : >bob carpenter : >  the following is extracted from sumex-aim.stanford.edu.  it should also be on the mirrors.  i think there is source for some applications that may have some bearing on your project.  poke around the source directory.  i ve never used this package, nor do i know anyone who did, but the price is right :-   hope this helps.       cheinan  abstracts of files as of thu apr  1 03:11:39 pst 1993 directory: info-mac/source  #### binhex     3d-grafsys-121.hqx   ****  date: fri, 5 mar 93 14:13:07 +0100 from: christian steffen ove franz <cfranz@iiic.ethz.ch> to: questions@mac.archive.umich.edu subject: 3d grafsys 1.21 in incoming directory a 3d grafsys short description follows:  programmers 3d grafsys vers 1.21 now available.   version 1.21 is mainly a bugfix for think c users. this version now runs with think c, i promise  the docs now contain a chapter for c programmers on how to use the grafsys. if you have problems, feel free  to contact me. the other change is that i removed the fastperftrig calls from the fpu version to make it run faster.  those of you who don t know what all this is about, read on.  ********  programmers 3d grafsys -- what it is: -------------------------------------  didn t you always have this great game in mind where you needed some way of  drawing three-dimensional scenes?   didn t you always want to write this program that visualized the structure  of three-dimensional molecules?  and didn t the task of writing your 3d conversions routines keep you from  actually doing it?  well if the answer to any of the above questions is  yes, but what has it to  do with this package???  , read on.  grafsys is a think pascal/c library that provides you with simple routines  for building, saving, loading  as resources , and manipulating   independent rotating around arbitrary achses, translating and scaling   three dimensional objects. objects, not just simple single-line drawings.  grafsys supports full 3d clipping, animation and some  primitive  hidden- line/hidden-surface drawing with simple commands from within your program.  grafsys also supports full eye control with both perspective and parallel projections  if you can t understand a word, don t worry, this is just showing off for those who know about it. the docs that come with it will try to explain what it all means later on .   grafsys provides a powerful interface to supply your own drawing routines with data so you can use grafsys to do the 3d transformations and your own routines to do the actual drawing.  note that grafsys also provides drawing routines so you don t have to worry about that if you don t want to   grafsys 1.11 comes in two versions. one for the 881 and 020 or above  processors. the other version uses fixed-point arithmetic and runs on any mac. both versions are *100% source compatibel*.   grafsys comes with an extensive manual that teaches you the fundamentals of 3d graphics and how to use the package.  if demand is big enough i will convert the grafsys to an object-class library.  however, i feelt that the way it is implemented now makes it easier to use for a lot more people than the select  oop-guild .  grafsys is free for any non-commercial usage. read the documentation enclosed.\n",
      "predicted_topic = religion, actual_topic = space \n",
      "\n",
      "                autos  religion  graphics     space\n",
      "archer       0.000000  0.095257  0.000000  0.000000\n",
      "interactive  0.000000  0.000000  0.080466  0.009182\n",
      "sex          0.000000  0.088080  0.000000  0.000000\n",
      "lars         0.000000  0.000000  0.073106  0.000000\n",
      "short        0.009926  0.004614  0.007306  0.001293\n",
      "about        0.006043  0.005042  0.003455  0.002450\n",
      "for          0.004320  0.002796  0.005900  0.003334\n",
      "how          0.003891  0.004358  0.002532  0.005047\n",
      "with         0.003962  0.004259  0.004741  0.002599\n",
      "or           0.003485  0.003646  0.005243  0.003123\n",
      "the most current orbital elements from the norad two-line element sets are carried on the celestial bbs,  513  427-0674, and are updated daily  when possible .  documentation and tracking software are also available on this system.  as a service to the satellite user community, the most current elements for the current shuttle mission are provided below.  the celestial bbs may be accessed 24 hours/day at 300, 1200, 2400, 4800, or 9600 bps using 8 data bits, 1 stop bit, no parity.  element sets  also updated daily , shuttle elements, and some documentation and software are also available via anonymous ftp from archive.afit.af.mil  129.92.1.66  in the directory pub/space.  sts 56      1 22621u 93 23  a 93105.06179397  .00044513  00000-0  12649-3 0   230 2 22621  57.0022 147.2850 0004246 288.7332  38.0941 15.92991629  1084 1993 023b   1 22623u 93 23  b 93103.37312705  .00041032  00000-0  11888-3 0    86 2 22623  57.0000 155.1150 0004422 293.4650  66.5967 15.92653917   803\n",
      "predicted_topic = religion, actual_topic = graphics \n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [autos, religion, graphics, space]\n",
      "Index: []\n",
      "it was a test of the first reusable tool.   pointy so they can find them or so they will stick into their pants better, and be closer to their brains?\n",
      "predicted_topic = autos, actual_topic = graphics \n",
      "\n",
      "          autos  religion  graphics     space\n",
      "fund   0.000000  0.000000  0.000000  0.008011\n",
      "dying  0.000000  0.000000  0.000000  0.007682\n",
      "ought  0.000000  0.000000  0.000000  0.007682\n",
      "shit   0.007103  0.000000  0.000000  0.000000\n",
      "fed    0.000000  0.000000  0.000000  0.007103\n",
      "...         ...       ...       ...       ...\n",
      "is     0.000271  0.000333  0.000298  0.000287\n",
      "in     0.000334  0.000291  0.000283  0.000280\n",
      "that   0.000314  0.000322  0.000276  0.000276\n",
      "only   0.000280  0.000310  0.000323  0.000275\n",
      "of     0.000305  0.000312  0.000291  0.000276\n",
      "\n",
      "[124 rows x 4 columns]\n",
      "i m looking for any leads to the source of a good windows meta file converter or interpreter. i need this for use outside the windows environment. pd sources preferred, but not a requirement. please reply to the address below.\n",
      "predicted_topic = space, actual_topic = religion \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "fi         0.000000  0.000000  0.013417  0.000000\n",
      "subscribe  0.000768  0.011589  0.000200  0.000000\n",
      "space      0.000224  0.000088  0.000857  0.010942\n",
      "hut        0.000000  0.011372  0.000000  0.000578\n",
      "listserv   0.009924  0.000000  0.001162  0.000000\n",
      "...             ...       ...       ...       ...\n",
      "to         0.000553  0.000496  0.000562  0.000467\n",
      "is         0.000474  0.000581  0.000521  0.000501\n",
      "in         0.000583  0.000509  0.000495  0.000489\n",
      "of         0.000532  0.000545  0.000509  0.000481\n",
      "one        0.000551  0.000526  0.000488  0.000502\n",
      "\n",
      "[71 rows x 4 columns]\n",
      "->i addressed most of the key issues in this very long  284 lines  post ->by dean kaflowitz in two posts yesterday.  the first was made into the ->title post of a new thread,  is dean kaflowitz terminally irony-impaired?  ->and the second, more serious one appeared along the thread -> a chaney post, and a challenge, reissued and revised\n",
      "predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "                autos  religion  graphics     space\n",
      "purchase     0.022449  0.000160  0.000072  0.000210\n",
      "tree         0.000000  0.022838  0.000000  0.000000\n",
      "tire         0.022153  0.000000  0.000000  0.000000\n",
      "onto         0.000000  0.020484  0.000000  0.000000\n",
      "trucks       0.020484  0.000000  0.000000  0.000000\n",
      "mechanic     0.020484  0.000000  0.000000  0.000000\n",
      "vans         0.017001  0.000000  0.000000  0.000000\n",
      "hooks        0.000000  0.000000  0.017001  0.000000\n",
      "netters      0.003956  0.000469  0.008767  0.000000\n",
      "price        0.008415  0.000047  0.002437  0.001100\n",
      "product      0.001967  0.000307  0.007009  0.000971\n",
      "thanks       0.002567  0.000229  0.006209  0.000786\n",
      "hello        0.001411  0.000000  0.005386  0.002520\n",
      "storage      0.003646  0.000000  0.001222  0.003553\n",
      "information  0.001323  0.000136  0.003853  0.002002\n",
      "address      0.000055  0.002130  0.003563  0.001559\n",
      "device       0.001983  0.000000  0.002213  0.003002\n",
      "step         0.001572  0.002007  0.002702  0.000097\n",
      "ve           0.001399  0.000894  0.002903  0.000478\n",
      "seen         0.000854  0.002130  0.000698  0.000895\n",
      "find         0.000685  0.001106  0.002052  0.000707\n",
      "know         0.001398  0.000786  0.001618  0.000518\n",
      "used         0.000697  0.000606  0.001443  0.001359\n",
      "like         0.001435  0.000455  0.001128  0.001076\n",
      "up           0.001637  0.001004  0.000824  0.000613\n",
      "where        0.000804  0.000670  0.001572  0.000922\n",
      "about        0.001405  0.001173  0.000804  0.000570\n",
      "good         0.001307  0.001099  0.001045  0.000487\n",
      "out          0.001330  0.000906  0.001026  0.000563\n",
      "for          0.001005  0.000650  0.001372  0.000775\n",
      "can          0.001044  0.000608  0.001295  0.000821\n",
      "on           0.000979  0.000632  0.001240  0.000833\n",
      "also         0.001150  0.000870  0.000858  0.000688\n",
      "would        0.000999  0.000643  0.000919  0.000973\n",
      "if           0.001076  0.000733  0.000952  0.000763\n",
      "and          0.000920  0.000790  0.001057  0.000733\n",
      "it           0.001007  0.000699  0.000940  0.000843\n",
      "this         0.000770  0.000829  0.001067  0.000817\n",
      "the          0.000948  0.000853  0.000867  0.000763\n",
      "to           0.000913  0.000819  0.000927  0.000772\n",
      "is           0.000782  0.000960  0.000861  0.000828\n",
      "that         0.000907  0.000929  0.000796  0.000797\n",
      "of           0.000879  0.000899  0.000840  0.000795\n",
      "so its an automatic? don t know if us spec=cdn spec. for maximas.   if it is the first set of brake pads on front, then this is fine. my car eats a set every 15k miles or so. the fact that he is replacing the muffler too is also ok.   the mileage is fairly low - but typical fwd stuff is cv joints. check the maintenance records with the manufacturers requirements for valve adjustments, timing belt changes and so on.  the 60k mile service is often expensive, so make sure he has done everything.   well, this is one of the commonly cited methods for identifying a car with highway miles.  might check the gas pedal wear too. ask him how many sets of tires he has been through. a highway car might have squeezed by on 2 sets, a hard driven car 6-10 sets.    well, the maxima should be pretty reliable - but if its out of warranty you should get it checked out by someone knowledgeable first. stuff for japanese cars can be expensive.   1995 model year, i believe.\n",
      "predicted_topic = religion, actual_topic = autos \n",
      "\n",
      "                autos  religion  graphics     space\n",
      "theory       0.000000  0.025142  0.000000  0.003673\n",
      "yep          0.000000  0.000000  0.024369  0.000000\n",
      "42           0.004175  0.000000  0.018159  0.000729\n",
      "suggestions  0.005607  0.000000  0.017117  0.000236\n",
      "peter        0.000000  0.008016  0.011060  0.000239\n",
      "sort         0.002323  0.007065  0.000246  0.002168\n",
      "around       0.005954  0.001561  0.000952  0.001432\n",
      "thinking     0.004736  0.002105  0.000524  0.001557\n",
      "anyone       0.002488  0.000463  0.003719  0.001427\n",
      "once         0.001574  0.003157  0.000378  0.002759\n",
      "number       0.000951  0.002133  0.003643  0.000863\n",
      "heard        0.001682  0.002171  0.000472  0.002378\n",
      "any          0.001700  0.001153  0.003000  0.000818\n",
      "rather       0.001576  0.001982  0.000525  0.002545\n",
      "came         0.001058  0.002931  0.001499  0.000986\n",
      "sound        0.002540  0.001212  0.001033  0.001182\n",
      "where        0.001152  0.000961  0.002254  0.001321\n",
      "does         0.001661  0.001236  0.001785  0.000798\n",
      "for          0.001440  0.000932  0.001967  0.001111\n",
      "think        0.002022  0.001276  0.001063  0.001067\n",
      "on           0.001403  0.000906  0.001778  0.001194\n",
      "than         0.001648  0.001239  0.000858  0.001522\n",
      "two          0.001652  0.001433  0.000925  0.001180\n",
      "here         0.001535  0.001099  0.001497  0.000990\n",
      "have         0.001580  0.001149  0.001258  0.001054\n",
      "other        0.001351  0.001018  0.001239  0.001354\n",
      "from         0.001110  0.001246  0.001190  0.001372\n",
      "the          0.001358  0.001222  0.001243  0.001094\n",
      "that         0.001300  0.001331  0.001140  0.001142\n",
      "of           0.001260  0.001289  0.001204  0.001140\n",
      "i have a 1986 acura integra 5 speed with 95,000 miles on it. it is positively the worst car i have ever owned. i had an 83 prelude that had 160k miles on it when i sold it, and it was still going strong .  this is with religious attention to maintenance such as oil changes etc. both cars were driven in exactly the same manner..    1. it has gone through two clutches  which are underrated.    2. 3 sets of tires  really eats tires in the front even with careful align    3. all struts started leaking about 25-30k miles   4. windshield wiper motor burned up  service note on this one    5. seek stop working on radio about 20k miles   6. two timing belts.   7. constant error signals from computer.    8. and finally. a rod bearing went out on the no. 1 piston seriously damaging      the crankshaft, contaminating the engine etc. when the overhaul was done      last week it required new crankshaft, one new cam shaft  has two  because      the camshaft shattered when they tried to mill it. the camshaft took 4      weeks to get because it is on national back order.        everything on the engine is unique to the 1986 year. they went to a new      design in 87. parts are very expensive.\n",
      "predicted_topic = religion, actual_topic = graphics \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              autos  religion  graphics     space\n",
      "lord       0.000000  0.012799  0.000000  0.000245\n",
      "equations  0.000000  0.000000  0.012280  0.000469\n",
      "solve      0.000000  0.000000  0.012534  0.000000\n",
      "iti        0.000000  0.000000  0.000542  0.011581\n",
      "rid        0.011094  0.000980  0.000000  0.000000\n",
      "...             ...       ...       ...       ...\n",
      "the        0.000536  0.000483  0.000491  0.000432\n",
      "to         0.000516  0.000463  0.000525  0.000437\n",
      "is         0.000442  0.000543  0.000487  0.000468\n",
      "in         0.000545  0.000475  0.000462  0.000457\n",
      "of         0.000497  0.000509  0.000475  0.000450\n",
      "\n",
      "[76 rows x 4 columns]\n",
      "hi there ...   well, i have a 386/40 with svga 1mb.  oak chip 077  and i don t   have vesa tsr program for this card. i need it .     please... if anybody can help me, mail me at:    lulagos@araucaria.cec.uchile.cl\n",
      "predicted_topic = religion, actual_topic = graphics \n",
      "\n",
      "                autos  religion  graphics     space\n",
      "chip         0.022955  0.000000  0.020523  0.000000\n",
      "phone        0.014728  0.000187  0.019779  0.001139\n",
      "information  0.004064  0.000417  0.011834  0.006149\n",
      "address      0.000169  0.006544  0.010944  0.004788\n",
      "number       0.002037  0.004571  0.007806  0.001850\n",
      "like         0.004408  0.001397  0.003464  0.003305\n",
      "get          0.004459  0.001466  0.003506  0.003063\n",
      "about        0.004316  0.003602  0.002468  0.001750\n",
      "some         0.002273  0.002037  0.004094  0.003220\n",
      "you          0.003187  0.002497  0.003095  0.002087\n",
      "have         0.003386  0.002463  0.002696  0.002260\n",
      "this         0.002364  0.002547  0.003278  0.002510\n",
      "do           0.002317  0.003068  0.002926  0.002367\n",
      "to           0.002803  0.002515  0.002849  0.002370\n",
      "any comments on the absorbtion of the office of exploration into the office of space sciences and the reassignment of griffin to the  chief engineer  position?  is this just a meaningless administrative shuffle, or does this bode ill for sei?  in my opinion, this seems like a bad thing, at least on the surface. griffin seemed to be someone who was actually interested in getting things done, and who was willing to look an innovative approaches to getting things done faster, better, and cheaper.  it s unclear to me whether he will be able to do this at his new position.  does anyone know what his new duties will be? -- _______________________________________________________________________________\n",
      "predicted_topic = autos, actual_topic = graphics \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "economical  0.097866  0.000000  0.000000  0.000000\n",
      "exist       0.009863  0.021309  0.000000  0.008692\n",
      "even        0.004119  0.008835  0.002498  0.005649\n",
      "though      0.007577  0.003637  0.004954  0.003073\n",
      "they        0.007425  0.004382  0.002897  0.004314\n",
      "at          0.004376  0.003082  0.005577  0.004205\n",
      "not         0.004180  0.005374  0.003337  0.004040\n",
      "time        0.003463  0.004859  0.004909  0.003618\n",
      "this        0.003678  0.003963  0.005100  0.003905\n",
      "ppppp    ooooo  v     v  persistance of vision raytracer. p    p  o     o v     v p    p  o     o v     v ppppp   o     o v     v p       o     o  v   v p       o     o   v v p        ooooo     v  available on archie and wuarchive in graphics type directories.  ps it s freeware.  --\n",
      "predicted_topic = autos, actual_topic = space \n",
      "\n",
      "            autos  religion  graphics     space\n",
      "ultrix   0.000000  0.000000  0.125828  0.000000\n",
      "running  0.012173  0.004120  0.095079  0.000000\n",
      "steve    0.017959  0.000000  0.016066  0.010708\n",
      "see      0.009950  0.012017  0.002829  0.004887\n",
      "re       0.012383  0.006461  0.003216  0.005936\n",
      "not      0.005374  0.006910  0.004291  0.005195\n",
      "you      0.006375  0.004994  0.006189  0.004173\n",
      "hi ...   i am searching for packages that could handle multi-page gif files...      are there any on some ftp servers?  i ll appreciate one which works on pc  either on dos or windows 3.0/3.1 . but any package works on unix will be ok..\n",
      "predicted_topic = graphics, actual_topic = religion \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "brought     0.026557  0.010075  0.000000  0.000363\n",
      "details     0.001102  0.001712  0.008369  0.004582\n",
      "appreciate  0.002555  0.000762  0.004621  0.004030\n",
      "really      0.004379  0.003861  0.001574  0.001358\n",
      "back        0.005190  0.002423  0.001456  0.002087\n",
      "didn        0.002544  0.004723  0.001566  0.001805\n",
      "someone     0.002998  0.002196  0.001140  0.003667\n",
      "like        0.003428  0.001087  0.002695  0.002570\n",
      "up          0.003910  0.002398  0.001967  0.001465\n",
      "when        0.002948  0.002867  0.001091  0.002629\n",
      "they        0.003712  0.002191  0.001448  0.002157\n",
      "asked       0.001879  0.003415  0.002490  0.001488\n",
      "out         0.003177  0.002165  0.002450  0.001345\n",
      "for         0.002400  0.001553  0.003278  0.001852\n",
      "something   0.001613  0.001944  0.002626  0.002322\n",
      "would       0.002387  0.001536  0.002196  0.002325\n",
      "if          0.002570  0.001750  0.002273  0.001824\n",
      "this        0.001839  0.001981  0.002550  0.001952\n",
      "----- news saved at 23 apr 93 22:22:40 gmt       well, i m working on it, but getting a little impatient. so far,  i ve made it through egyptian, chinese, and greek cultures, and up through the rennaisance. but so far, these insights just don t  seem to be gelling. perhaps it s in an appendix somewhere.\n",
      "predicted_topic = autos, actual_topic = religion \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "3d          0.000000  0.000000  0.001445  0.000000\n",
      "spacecraft  0.000000  0.000000  0.000000  0.001445\n",
      "lunar       0.000000  0.000000  0.000000  0.001445\n",
      "formats     0.000000  0.000000  0.001445  0.000000\n",
      "orbital     0.000000  0.000000  0.000000  0.001445\n",
      "...              ...       ...       ...       ...\n",
      "in          0.000060  0.000052  0.000051  0.000050\n",
      "that        0.000056  0.000058  0.000049  0.000049\n",
      "only        0.000050  0.000056  0.000058  0.000049\n",
      "of          0.000055  0.000056  0.000052  0.000049\n",
      "one         0.000057  0.000054  0.000050  0.000052\n",
      "\n",
      "[692 rows x 4 columns]\n",
      ">i recently have become aware that my health insurance includes   >coverage for abortion.  i strongly oppose abortion for reasons of   >conscience.  it disturbs me deeply to know that my premiums may   >be being used to pay for that which i sincerely believe is   >murder.  i would like to request that i be exempted from abortion   >coverage with my health premiums reduced accordingly.  i share dennis s outrage over a similar manner.  i have recently become aware that my health insurance includes coverage for illness and injuries suffered by christians.  it disturbs me deeply to know that my premiums may be used to pay for that which i sincerely believe is divine punishment for their sinful conduct.  in addition these folks are able to avail themselves of such alternative therapies as lourdes, fatima, morris cerullo, benny hinn, etc.  in any case as  jesus saves  i feel that there is no reason for them to be covering their bets at my expense.  i would like to request that i be exempted from christian coverage with my health premiums reduced accordingly.\n",
      "predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "                autos  religion  graphics     space\n",
      "turbo        0.015296  0.000000  0.000071  0.000000\n",
      "solar        0.000000  0.000000  0.000414  0.014730\n",
      "altitude     0.000000  0.000000  0.000000  0.015108\n",
      "electronics  0.014655  0.000000  0.000000  0.000000\n",
      "amounts      0.000000  0.000000  0.000949  0.013278\n",
      "...               ...       ...       ...       ...\n",
      "to           0.000604  0.000542  0.000614  0.000510\n",
      "is           0.000517  0.000635  0.000569  0.000548\n",
      "in           0.000637  0.000556  0.000540  0.000535\n",
      "that         0.000600  0.000614  0.000526  0.000527\n",
      "of           0.000582  0.000595  0.000556  0.000526\n",
      "\n",
      "[65 rows x 4 columns]\n",
      "a lot of people won t agree with me.  that s their right and i respect that. however, to the point, jews are also covered by the saving grace of jesus christ.  there are jews who have become christians.\n",
      "predicted_topic = autos, actual_topic = space \n",
      "\n",
      "          autos  religion  graphics     space\n",
      "sure   0.005784  0.003177  0.004662  0.006226\n",
      "wrong  0.005933  0.004968  0.005161  0.003305\n",
      "also   0.006183  0.004677  0.004609  0.003699\n",
      "you    0.005578  0.004369  0.005416  0.003651\n",
      "would  0.005370  0.003456  0.004941  0.005232\n",
      "but    0.004002  0.004702  0.005896  0.004276\n",
      "might  0.004942  0.004991  0.003605  0.005260\n",
      "be     0.004292  0.005070  0.004126  0.005016\n",
      "the quality of autobahns is something of a myth. the road surface isn t much different to a typical tx freeway. they are better in terms of lighting, safety, signs, roadmarkings etc. i d have no problem driving 130 on most us freeways, as it is, i save it for the backroads, which really are more likely to be dangerous.   it would have to be quite severe. i don t recall any us freeway, without road damage warnings, that i would regard as unsafe at 130 in any decent, well damped car. note that my definition of decent, well damped, would exclude most typical american sedans.   i don t know where you live, but i would be much more worried about cops, other traffic etc. than the road surface at 130. it just isn t that fast or that dangerous. if you have a probe gt, no problem. the 4cyl models i have driven would be likely to be unpredictable at higher speeds.\n",
      "predicted_topic = space, actual_topic = religion \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "suggestion  0.008226  0.000000  0.086979  0.008359\n",
      "age         0.005755  0.017623  0.000000  0.054550\n",
      "douglas     0.013105  0.000000  0.032987  0.009918\n",
      "new         0.018158  0.003206  0.006503  0.006706\n",
      "try         0.006180  0.004277  0.009260  0.004406\n",
      "by          0.005108  0.006264  0.004955  0.004892\n",
      "the         0.005820  0.005239  0.005326  0.004690\n",
      "sorry about that last post, my server neglected to send the message:\n",
      "predicted_topic = graphics, actual_topic = religion \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "car        0.016881  0.000059  0.000000  0.000000\n",
      "weapons    0.000000  0.016907  0.000000  0.000000\n",
      "alarm      0.016644  0.000000  0.000000  0.000000\n",
      "fire       0.000000  0.011483  0.000000  0.002322\n",
      "kid        0.009921  0.002745  0.000000  0.000000\n",
      "scum       0.012391  0.000000  0.000000  0.000000\n",
      "defend     0.012391  0.000000  0.000000  0.000000\n",
      "kill       0.001458  0.009635  0.000000  0.000743\n",
      "worse      0.000797  0.000000  0.005105  0.002062\n",
      "carrying   0.000548  0.000000  0.004383  0.002894\n",
      "honest     0.004687  0.002402  0.000000  0.000688\n",
      "gun        0.004707  0.001189  0.000000  0.001511\n",
      "argue      0.003871  0.002929  0.000602  0.000000\n",
      "seriously  0.004384  0.000281  0.000366  0.002030\n",
      "shooting   0.002446  0.002410  0.000109  0.000646\n",
      "glad       0.001886  0.001310  0.000000  0.002069\n",
      "care       0.001054  0.002979  0.000386  0.000651\n",
      "setting    0.000171  0.002461  0.001346  0.000835\n",
      "property   0.001250  0.002099  0.000054  0.001385\n",
      "off        0.001819  0.001649  0.000227  0.000636\n",
      "right      0.001947  0.000519  0.000515  0.000854\n",
      "people     0.000997  0.001593  0.000272  0.000780\n",
      "reason     0.000380  0.001486  0.000534  0.001107\n",
      "did        0.001349  0.001210  0.000458  0.000429\n",
      "really     0.001336  0.001178  0.000480  0.000414\n",
      "going      0.000872  0.001075  0.000248  0.001126\n",
      "things     0.000573  0.000956  0.000387  0.001308\n",
      "issue      0.000592  0.001464  0.000613  0.000556\n",
      "ask        0.001071  0.001188  0.000593  0.000356\n",
      "thought    0.000849  0.000928  0.000303  0.000942\n",
      "why        0.000594  0.000935  0.000392  0.001027\n",
      "they       0.001133  0.000669  0.000442  0.000658\n",
      "about      0.001024  0.000855  0.000586  0.000415\n",
      "world      0.000484  0.000937  0.000484  0.000969\n",
      "give       0.000400  0.000919  0.000952  0.000601\n",
      "your       0.001115  0.000712  0.000552  0.000493\n",
      "out        0.000969  0.000661  0.000748  0.000410\n",
      "for        0.000732  0.000474  0.001000  0.000565\n",
      "anything   0.000523  0.000732  0.000510  0.001001\n",
      "got        0.000960  0.000540  0.000476  0.000786\n",
      "think      0.001028  0.000649  0.000541  0.000542\n",
      "can        0.000761  0.000443  0.000944  0.000598\n",
      "their      0.000780  0.000862  0.000399  0.000695\n",
      "than       0.000838  0.000630  0.000436  0.000774\n",
      "there      0.000636  0.000553  0.000842  0.000558\n",
      "not        0.000638  0.000820  0.000509  0.000616\n",
      "you        0.000756  0.000592  0.000734  0.000495\n",
      "would      0.000728  0.000469  0.000670  0.000709\n",
      "if         0.000784  0.000534  0.000694  0.000556\n",
      "have       0.000803  0.000584  0.000640  0.000536\n",
      "but        0.000543  0.000638  0.000799  0.000580\n",
      "do         0.000550  0.000728  0.000694  0.000562\n",
      "before     0.000637  0.000585  0.000562  0.000734\n",
      "be         0.000582  0.000688  0.000559  0.000680\n",
      "more       0.000618  0.000649  0.000547  0.000692\n",
      "the        0.000691  0.000622  0.000632  0.000556\n",
      "to         0.000665  0.000597  0.000676  0.000562\n",
      "in         0.000702  0.000612  0.000595  0.000589\n",
      "of         0.000641  0.000655  0.000612  0.000579\n",
      "i have a 1982 regal and i am interested in buying a fiberglass hood, trunk, and bumpers for it.  does anybody know of a company who makes fiberglass parts for regals ??     thanks in advance,\n",
      "predicted_topic = religion, actual_topic = autos \n",
      "\n",
      "                autos  religion  graphics     space\n",
      "appreciated  0.003825  0.000000  0.013236  0.002494\n",
      "email        0.003429  0.000000  0.011473  0.002946\n",
      "hate         0.006272  0.003271  0.000000  0.003562\n",
      "newsgroups   0.006683  0.002625  0.000814  0.001559\n",
      "interest     0.005014  0.000593  0.003933  0.001338\n",
      "please       0.001314  0.001808  0.003908  0.001177\n",
      "limited      0.002573  0.000556  0.002344  0.002388\n",
      "know         0.002405  0.001352  0.002782  0.000892\n",
      "me           0.001571  0.001714  0.002360  0.000976\n",
      "how          0.001556  0.001743  0.001013  0.002019\n",
      "with         0.001585  0.001704  0.001896  0.001040\n",
      "here         0.001842  0.001318  0.001797  0.001188\n",
      "you          0.001785  0.001398  0.001733  0.001168\n",
      "if           0.001851  0.001260  0.001637  0.001313\n",
      "and          0.001583  0.001358  0.001818  0.001261\n",
      "post         0.001458  0.001298  0.001866  0.001395\n",
      "discussion   0.001452  0.001352  0.001342  0.001866\n",
      "it           0.001733  0.001202  0.001617  0.001450\n",
      "this         0.001324  0.001427  0.001836  0.001406\n",
      "do           0.001298  0.001718  0.001639  0.001325\n",
      "want         0.001652  0.001429  0.001673  0.001225\n",
      "don          0.001642  0.001577  0.001224  0.001508\n",
      "to           0.001570  0.001408  0.001595  0.001327\n",
      "is           0.001345  0.001650  0.001480  0.001424\n",
      "of           0.001512  0.001546  0.001445  0.001367\n",
      "i have the need for displaying 2 1/2 d surfaces under x, using only xlib, xt and xm.  does anyone know of a package, available on internet, which will be able to do the work?     i am looking for a stand-alone package providing similar functions to  xprism3  available with khoros, but without the numerous libraries required for it.  i want to be able to recompile it and run it on various platforms, from sgis to i486s  unix .     any help will be appreciated.\n",
      "predicted_topic = graphics, actual_topic = religion \n",
      "\n",
      "           autos  religion  graphics     space\n",
      "prize   0.000000  0.000000  0.000000  0.006800\n",
      "apollo  0.000000  0.000000  0.000031  0.006765\n",
      "sgi     0.000000  0.000000  0.006786  0.000000\n",
      "pc      0.000000  0.000000  0.006718  0.000065\n",
      "binary  0.000000  0.000000  0.006538  0.000161\n",
      "...          ...       ...       ...       ...\n",
      "is      0.000229  0.000281  0.000252  0.000242\n",
      "in      0.000282  0.000246  0.000239  0.000236\n",
      "that    0.000265  0.000272  0.000233  0.000233\n",
      "of      0.000257  0.000263  0.000246  0.000233\n",
      "one     0.000266  0.000254  0.000236  0.000243\n",
      "\n",
      "[147 rows x 4 columns]\n",
      "are there any tiff to anything programs out there for the ibm? our scanner works into tiff, and i can view it on cshow 8.1, but  all of my other programs read errors.  are there any basic tiff to  jpeg, gif, pcx, bmp, etc...?  thanks for the time...email or post acceptable. joshuaf\n",
      "predicted_topic = space, actual_topic = graphics \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "greatly     0.002991  0.011231  0.045413  0.000483\n",
      "rich        0.000000  0.022811  0.002264  0.023153\n",
      "his         0.005116  0.015600  0.001400  0.006352\n",
      "yes         0.009732  0.007886  0.002750  0.002298\n",
      "appreciate  0.004599  0.001372  0.008318  0.007255\n",
      "give        0.002357  0.005425  0.005614  0.003546\n",
      "me          0.003927  0.004285  0.005900  0.002441\n",
      "name        0.003964  0.005286  0.002278  0.004987\n",
      "would       0.004296  0.002765  0.003953  0.004186\n",
      "it          0.004332  0.003005  0.004043  0.003624\n",
      "i ve been asking myself this same question for the past year, so, if/when you find out, would you please share the magistic answer with me..   the way i see it right now, work twice as hard so you can have both.  cheers :\n",
      "predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "         autos  religion  graphics     space\n",
      "luck  0.052921  0.000000  0.035071  0.080112\n",
      "good  0.028091  0.023622  0.022459  0.010466\n",
      "found it  thanks. i got several offers for help. i appreciate it and will be contacting those people via e-mail.  thanks again...\n",
      "predicted_topic = space, actual_topic = autos \n",
      "\n",
      "          autos  religion  graphics     space\n",
      "rs     0.000000  0.000000  0.063505  0.000000\n",
      "sr     0.000000  0.000000  0.000000  0.048737\n",
      "fwiw   0.000000  0.000000  0.000000  0.048737\n",
      "doug   0.000000  0.000000  0.032088  0.013611\n",
      "sic    0.000000  0.013142  0.000000  0.032525\n",
      "page   0.000000  0.000000  0.031432  0.014055\n",
      "71     0.000000  0.002723  0.008490  0.022722\n",
      "he     0.002820  0.010336  0.001344  0.003969\n",
      "until  0.002686  0.008297  0.001782  0.002987\n",
      "who    0.003215  0.005576  0.001172  0.003362\n",
      "also   0.003298  0.002494  0.002458  0.001973\n",
      "was    0.003215  0.002375  0.002118  0.002398\n",
      "it     0.002888  0.002004  0.002695  0.002416\n",
      "the    0.002716  0.002445  0.002485  0.002189\n",
      "one    0.002607  0.002492  0.002310  0.002377\n",
      "at&t also puts out two new products for windows, model numbers elude me now, a 15 bit video board with framegrabber and a 16bit with same. yesterday i was looking at a product at a local software etc store. media vision makes a 15bit  32,768 color  frame capture board that is stand alone and doesnot use the feature connector on your existing video card. it claims upto 30 fps live capture as well as single frame from either composite ntsc or s-video in and out.\n",
      "predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "                 autos  religion  graphics     space\n",
      "intelligence  0.000000  0.000000  0.000000  0.011159\n",
      "originally    0.000000  0.010789  0.000088  0.000201\n",
      "humans        0.000000  0.010161  0.000000  0.000641\n",
      "police        0.009376  0.000952  0.000000  0.000000\n",
      "deeper        0.000000  0.010009  0.000000  0.000000\n",
      "...                ...       ...       ...       ...\n",
      "to            0.000446  0.000400  0.000453  0.000377\n",
      "is            0.000382  0.000469  0.000421  0.000405\n",
      "in            0.000470  0.000411  0.000399  0.000395\n",
      "that          0.000443  0.000454  0.000389  0.000389\n",
      "of            0.000430  0.000439  0.000411  0.000388\n",
      "\n",
      "[88 rows x 4 columns]\n",
      "see:    maureen stone and tony derose,     a geometric characterization of parametric cubic curves ,    acm tog, vol 8, no 3, july 1989, pp. 147-163. _______________________________________________________________________  ...ron capelli                 ibm corp.  dept. c13,  ms. p230    capelli@vnet.ibm.com        po box 950     914  435-1673              poughkeepsie, ny  12602 _______________________________________________________________________\n",
      "predicted_topic = space, actual_topic = autos \n",
      "\n",
      "                 autos  religion  graphics     space\n",
      "sensible      0.000000  0.002365  0.000000  0.026991\n",
      "theory        0.000000  0.025142  0.000000  0.003673\n",
      "objective     0.000000  0.020452  0.000000  0.005295\n",
      "myriad        0.000000  0.021004  0.000000  0.003638\n",
      "distinctly    0.000000  0.024369  0.000000  0.000000\n",
      "explaining    0.000000  0.024369  0.000000  0.000000\n",
      "pundurs       0.000000  0.024369  0.000000  0.000000\n",
      "merely        0.000000  0.005663  0.000647  0.012939\n",
      "observations  0.000000  0.007788  0.000958  0.006599\n",
      "idea          0.000658  0.002415  0.001346  0.009750\n",
      "reality       0.000000  0.004732  0.002470  0.003523\n",
      "accept        0.000503  0.004829  0.000921  0.003989\n",
      "jim           0.002677  0.003300  0.000393  0.001542\n",
      "model         0.003645  0.000637  0.001716  0.001519\n",
      "people        0.001961  0.003134  0.000534  0.001534\n",
      "about         0.002014  0.001681  0.001152  0.000817\n",
      "your          0.002192  0.001400  0.001085  0.000969\n",
      "different     0.001421  0.001778  0.001635  0.000722\n",
      "can           0.001496  0.000872  0.001856  0.001177\n",
      "than          0.001648  0.001239  0.000858  0.001522\n",
      "an            0.001816  0.001138  0.001209  0.001058\n",
      "sorry         0.000852  0.001411  0.001577  0.001362\n",
      "mark          0.000971  0.001588  0.001094  0.001520\n",
      "but           0.001067  0.001254  0.001572  0.001140\n",
      "it            0.001444  0.001002  0.001348  0.001208\n",
      "more          0.001215  0.001276  0.001075  0.001360\n",
      "the           0.001358  0.001222  0.001243  0.001094\n",
      "is            0.001121  0.001375  0.001234  0.001187\n",
      "that          0.001300  0.001331  0.001140  0.001142\n",
      "of            0.001260  0.001289  0.001204  0.001140\n",
      "i agree, which is why i ve asked for help with it.  the reason i m working on this list is because i ve recently had one too many christians tell me  the bible contains no contradictions whatsoever.   they believe that it s true, and that it describes reality perfectly, and even predicts history before it happens.  before i can carry on any sort of meaningful conversation with these people, i ve got to show them, with concrete evidence, that the bible is not nearly as airtight as they thought.  i hope to do that with this list.  specifically: when i bring up the fact that genesis contains two contradictory creation stories, i usually get blank stares or flat denials.  i ve never had a fundamentalist acknowledge that there are indeed two different accounts of creation.\n",
      "predicted_topic = space, actual_topic = religion \n",
      "\n",
      "           autos  religion  graphics     space\n",
      "buying  0.004874  0.000000  0.000000  0.000000\n",
      "sgi     0.000000  0.000000  0.004866  0.000000\n",
      "lab     0.000000  0.000000  0.000045  0.004815\n",
      "intend  0.000000  0.004790  0.000000  0.000000\n",
      "truck   0.004568  0.000000  0.000000  0.000180\n",
      "...          ...       ...       ...       ...\n",
      "is      0.000164  0.000201  0.000181  0.000174\n",
      "in      0.000202  0.000176  0.000171  0.000170\n",
      "that    0.000190  0.000195  0.000167  0.000167\n",
      "of      0.000184  0.000189  0.000176  0.000167\n",
      "one     0.000191  0.000182  0.000169  0.000174\n",
      "\n",
      "[205 rows x 4 columns]\n",
      "my honda accord just hit the magic 100,000 mile mark and now all sorts of things are beginning to go bad. the latest problem i am experiencing is with my brakes.  they still stop the car fine, but once i am stopped completely, my brake pedal will sink another 2 or 3 inches all by itself.  if feels really strange, and i am worried my brakes will quit working one of these days.  i checked my brake fluid, and the reservoir was full, but the fluid itself looked really dirty  like dirty oil .  i called my mechanic and he told me i need a new brake master cylinder, which will cost me a whopping $250-300.  i was just wondering if anyone out there has experienced this sort of thing.  if so, is my mechanic being honest? or do i simply need to have my brakes bled and new fluid put in?  any help you could provide would be appreciated.  please send replies directly to me, as i rarely have a chance to read this list.  i will post the responses if there is any interest.  thanks,\n",
      "predicted_topic = autos, actual_topic = graphics \n",
      "\n",
      "           autos  religion  graphics     space\n",
      "life    0.009071  0.029463  0.007353  0.011070\n",
      "please  0.008215  0.011303  0.024423  0.007359\n",
      "real    0.014986  0.011605  0.004712  0.012965\n",
      "get     0.015607  0.005131  0.012272  0.010721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i m using  rayshade  on the u.w. computers here, and i d like input from other users, and perhaps swap some ideas.  i could post uuencoded .gifs here, or .ray code, if anyone s interested.  i m having trouble coming up with colors that are metallic  i.e. brass, steel  from the rgb values.  if you re on the u.w. machines, check out  ~fineman/rle.files/*.rle  on  stein.u.washington.edu for some of what i ve got.\n",
      "predicted_topic = religion, actual_topic = space \n",
      "\n",
      "            autos  religion  graphics     space\n",
      "lisa     0.000000  0.121843  0.000000  0.000000\n",
      "preston  0.000000  0.000000  0.000000  0.121843\n",
      "reply    0.008873  0.014253  0.019370  0.001332\n",
      "edu      0.010487  0.002057  0.017159  0.008925\n",
      "to       0.006541  0.005868  0.006647  0.005530\n",
      "in       0.006900  0.006021  0.005852  0.005792\n",
      "what is the phone number for alias? a toll-free number is preferred, if available.  thanks\n",
      "predicted_topic = religion, actual_topic = graphics \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "ut          0.000000  0.000000  0.000000  0.220199\n",
      "fellowship  0.000000  0.182765  0.000000  0.000000\n",
      "contact     0.000000  0.003875  0.092435  0.046980\n",
      "box         0.013722  0.011567  0.016845  0.004389\n",
      "no, i don t mean the lr, whatever that is.  as for which gd, i m using _the complete golden dawn system of magic_ as my source, so  unless regardie is lying  i m pulling the name out the the original order s rituals.  the multiple modern groups are part of why i through in the comment about all the  spin-offs .   as a member of the religious society of friends  my membership is in the urbana-champaign  il  friends meeting  i find that amusingly ironic. :    not me--i don t want to belong to *anything* which runs around claiming to be the true whatever.  i find that disgusting. :   enjoy the journey                        --br anarthur                                       queer, peculiar, and wyrd  :-\n",
      "predicted_topic = space, actual_topic = religion \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "racing     0.044040  0.000000  0.000000  0.000000\n",
      "classes    0.000000  0.000000  0.036553  0.000000\n",
      "auto       0.023069  0.000000  0.002429  0.004900\n",
      "depending  0.002103  0.000212  0.006693  0.008300\n",
      "total      0.000275  0.002469  0.005394  0.007009\n",
      "made       0.002230  0.005161  0.000565  0.004392\n",
      "such       0.001752  0.004059  0.001221  0.002462\n",
      "many       0.001437  0.003698  0.001515  0.002362\n",
      "different  0.002131  0.002667  0.002453  0.001083\n",
      "on         0.002105  0.001360  0.002667  0.001792\n",
      "how        0.001946  0.002179  0.001266  0.002524\n",
      "or         0.001743  0.001823  0.002621  0.001561\n",
      "are        0.002207  0.002346  0.001536  0.001592\n",
      "there      0.001875  0.001632  0.002485  0.001647\n",
      "have       0.002370  0.001724  0.001887  0.001582\n",
      "and        0.001978  0.001698  0.002273  0.001576\n",
      "as         0.001856  0.002161  0.001503  0.001969\n",
      "the        0.002037  0.001834  0.001864  0.001641\n",
      "in         0.002070  0.001806  0.001756  0.001737\n",
      "of         0.001890  0.001933  0.001807  0.001709\n",
      "i was chaining around in the anonymous ftp world looking for 3d studio meshes and other interesting graphical stuff for the program, and found a few files with the extension 3d2.  my 3ds v2.01 doesn t know this type of file, so what are they?  and of course, the perennial... where are some meshes, fli files, etc. out there?   i would have thought that someone would have collected a few and put them somewhere, but alas i am without this knowledge.  mucho appreciato\n",
      "predicted_topic = autos, actual_topic = space \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "mileage    0.047501  0.000000  0.000000  0.000000\n",
      "violation  0.002835  0.036433  0.000000  0.001155\n",
      "cells      0.000000  0.034818  0.003449  0.000000\n",
      "clump      0.000000  0.000000  0.000000  0.034812\n",
      "mindless   0.000000  0.034812  0.000000  0.000000\n",
      "thumb      0.026086  0.000000  0.006543  0.000000\n",
      "seriously  0.012318  0.000788  0.001028  0.005703\n",
      "happen     0.011453  0.003290  0.000224  0.003514\n",
      "vary       0.007874  0.004850  0.003365  0.000000\n",
      "smaller    0.007201  0.000682  0.002353  0.003069\n",
      "person     0.002653  0.004281  0.000475  0.003560\n",
      "may        0.001939  0.003648  0.001844  0.001228\n",
      "take       0.003199  0.002687  0.001200  0.001475\n",
      "much       0.002684  0.000990  0.001827  0.003019\n",
      "my         0.003369  0.001925  0.001611  0.001384\n",
      "your       0.003132  0.002001  0.001550  0.001384\n",
      "than       0.002354  0.001770  0.001226  0.002174\n",
      "more       0.001736  0.001823  0.001536  0.001944\n",
      "the        0.001940  0.001746  0.001775  0.001563\n",
      "to         0.001869  0.001676  0.001899  0.001580\n",
      "of         0.001800  0.001841  0.001721  0.001628\n",
      "it s great that all these other cars can out-handle, out-corner, and out- accelerate an integra.  but, you ve got to ask yourself one question: do all these other cars have a moonroof with a sliding sunshade?  no wimpy pop-up sunroofs or power sliding roofs that are opaque.  a moonroof that can be opened to the air, closed to let just light in, or shaded so that nothing comes in.  you ve just got to know what s important :^ .\n",
      "predicted_topic = autos, actual_topic = religion \n",
      "\n",
      "              autos  religion  graphics     space\n",
      "sky        0.000000  0.000000  0.000000  0.010843\n",
      "tree       0.000000  0.010674  0.000000  0.000000\n",
      "humans     0.000000  0.009719  0.000000  0.000613\n",
      "southern   0.000000  0.009693  0.000000  0.000592\n",
      "engineers  0.000000  0.000000  0.000711  0.009480\n",
      "...             ...       ...       ...       ...\n",
      "is         0.000366  0.000448  0.000402  0.000387\n",
      "in         0.000450  0.000393  0.000382  0.000378\n",
      "that       0.000424  0.000434  0.000372  0.000372\n",
      "of         0.000411  0.000420  0.000393  0.000372\n",
      "one        0.000425  0.000406  0.000377  0.000388\n",
      "\n",
      "[92 rows x 4 columns]\n",
      "does anybody know if there are any good 2d-graphics packages  available for ibm rs/6000 & aix ? i m looking for something  like dec s gks or hewlett-packards starbase, both of which  have reasonably good support for different output devices  like plotters, terminals, x etc.   i have tried also xgks from x11 distribution and ibm s implementation  of phigs. both of them work but we require more output devices  than just x-windows.   our salesman at ibm was not very familiar with graphics and  i am not expecting for any good solutions from there.     ari  ---\n",
      "predicted_topic = space, actual_topic = religion \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "correcting  0.000000  0.035232  0.000000  0.000000\n",
      "missed      0.005970  0.025662  0.000000  0.000000\n",
      "vgalib      0.000000  0.000000  0.029242  0.000000\n",
      "appealing   0.000000  0.000000  0.000000  0.029242\n",
      "amazing     0.014851  0.010068  0.000000  0.000000\n",
      "lost        0.004072  0.001948  0.000000  0.017368\n",
      "thanks      0.004415  0.000394  0.010680  0.001351\n",
      "glad        0.004450  0.003091  0.000000  0.004883\n",
      "wasn        0.002795  0.000470  0.002325  0.002804\n",
      "guess       0.002860  0.001898  0.002436  0.000629\n",
      "major       0.002030  0.000656  0.002594  0.002208\n",
      "no          0.002135  0.002688  0.000898  0.001440\n",
      "sound       0.003048  0.001454  0.001240  0.001418\n",
      "though      0.002728  0.001309  0.001784  0.001106\n",
      "those       0.001699  0.002692  0.001011  0.001502\n",
      "doesn       0.001509  0.002014  0.002226  0.000927\n",
      "me          0.001571  0.001714  0.002360  0.000976\n",
      "for         0.001728  0.001118  0.002360  0.001334\n",
      "very        0.001843  0.001160  0.001878  0.001321\n",
      "something   0.001161  0.001400  0.001890  0.001672\n",
      "was         0.001929  0.001425  0.001271  0.001439\n",
      "it          0.001733  0.001202  0.001617  0.001450\n",
      "all         0.001687  0.001639  0.001337  0.001301\n",
      "in          0.001656  0.001445  0.001405  0.001390\n",
      "only        0.001389  0.001538  0.001603  0.001362\n",
      "hello...      does anyone know of any c or c++ function libraries in the public domain  that assist in parsing an autocad .dxf file?        please e-mail.                                   thanks,  --\n",
      "predicted_topic = religion, actual_topic = graphics \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "originally  0.000000  0.012659  0.000103  0.000236\n",
      "truck       0.012485  0.000000  0.000000  0.000493\n",
      "trucks      0.011744  0.000000  0.000000  0.000000\n",
      "exhaust     0.000000  0.000000  0.000000  0.011744\n",
      "degree      0.000000  0.010228  0.000152  0.001095\n",
      "...              ...       ...       ...       ...\n",
      "the         0.000543  0.000489  0.000497  0.000438\n",
      "is          0.000448  0.000550  0.000493  0.000475\n",
      "in          0.000552  0.000482  0.000468  0.000463\n",
      "that        0.000520  0.000532  0.000456  0.000457\n",
      "of          0.000504  0.000515  0.000482  0.000456\n",
      "\n",
      "[75 rows x 4 columns]\n",
      "yeah, and it s also true most long complicated sequences of events, calculations, or big computer programs in general.  i don t argue that you can get similar and maybe useful results from fractals, i just question whether you >should<.  the fractal fiends seem to be saying that any part of a system that we can t model should be replaced with a random number generator.  that has been useful, for instance, in making data more palatable to human perception or for torture testing the rest of the system, but i don t think it has much to do with fractals, and i certainly would rather that the model be improved in a more explicable manner.  i guess i just haven t seen all these earth-shaking fractal models that explain and correlate to the universe as it actually exists.  i really hope i do, but i m not holding my self-similar breath.   uh huh.  i ll believe it when i see it.  i ve been chasing fractal compression for a few years, and i still don t believe in it.  if it s so great, how come we don t see it competing with jpeg?   cause it can t, i ll wager.  actually, i have wagered, i quit trying to make fractal compression work- and i was trying- because i don t think it s a reasonable alternative to other techniques.  it is neat, though. :-   i ll reiterate my disbelief that everything is fractal.  that s why i don t think fractal compression as it is widely explained is practical.  i know barnsley and sloan have some tricks up their sleeves that make their demos work, but i don t see anyone using it in a real product.  it s been six years since iterated systems was formed, right?    there are always going to be questions until there s a product  out there,  sloan replies.  the company plans to ship its first  encoding devices in the summer, he says.  in march, iterated  systems will have the other half of the system: the decoders.    - scientific american, march 1990, page 77\n",
      "predicted_topic = religion, actual_topic = autos \n",
      "\n",
      "           autos  religion  graphics     space\n",
      "equal   0.010270  0.010647  0.060126  0.001737\n",
      "weight  0.034737  0.003003  0.000345  0.043873\n",
      "you     0.007437  0.005826  0.007221  0.004869\n",
      "if      0.007711  0.005251  0.006820  0.005471\n",
      "to      0.006541  0.005868  0.006647  0.005530\n",
      "only    0.005787  0.006407  0.006680  0.005674\n",
      "rboudrie@chpc.org  rob boudrie  writes...     for discussion purposes only  on the other hand, if it can be proven, it s possible the changed  terms could be thrown out.  the question will be whether the  agreement contains a merger clause.  see ucc @ 2-202  parol  evidence .  if we re talking about warranties, then, of course,  ucc @ 2-316 should be looked at.  but we have so little information that none of us can say anything  conclusive.        daniel reitman\n",
      "predicted_topic = graphics, actual_topic = religion \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "thanks      0.006899  0.000616  0.016688  0.002111\n",
      "responses   0.011408  0.001329  0.006148  0.001521\n",
      "am          0.002839  0.001816  0.005595  0.002012\n",
      "may         0.002545  0.004787  0.002420  0.001611\n",
      "mind        0.002012  0.004575  0.001991  0.002420\n",
      "get         0.003902  0.001283  0.003068  0.002680\n",
      "interested  0.002701  0.001492  0.003571  0.002525\n",
      "others      0.002769  0.003285  0.002296  0.001618\n",
      "posting     0.003219  0.002400  0.002109  0.001934\n",
      "also        0.003092  0.002338  0.002305  0.001849\n",
      "there       0.002344  0.002040  0.003106  0.002059\n",
      "you         0.002789  0.002185  0.002708  0.001826\n",
      "would       0.002685  0.001728  0.002471  0.002616\n",
      "and         0.002473  0.002122  0.002841  0.001970\n",
      "be          0.002146  0.002535  0.002063  0.002508\n",
      "the         0.002546  0.002292  0.002330  0.002052\n",
      "sayeth sjwyrick@lbl.gov  steve wyrick : $anybody keeping track of how many of these there are?  so far i have $miata, tredia, previa, sentra, maxima, altima, camry, and justy, not to $mention lexus, acura and infiniti        you re apparently including names that are, or appear to be, derivatives of real words in english or some other language  e.g. acura, infiniti, maxima, altima , in which case you missed ones such as integra, supra, allante , capri and calibra.  in canada, add serenia and precidia.  if you count misspellings, add protege and  in canada  vigor.  how about the forthcoming mondeo, if it is given that name in north america?     others might include celica, corolla, paseo, and tercel.  in canada, add asu na.\n",
      "predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "           autos  religion  graphics     space\n",
      "life    0.012094  0.039284  0.009804  0.014760\n",
      "people  0.019605  0.031339  0.005344  0.015343\n",
      "get     0.020809  0.006841  0.016363  0.014294\n",
      "forwarded from the mars observer project                         mars observer status report                              april 23, 1993                               10:00 am pdt  flight sequence c8 is active, the spacecraft subsystems and instrument payload performing well in array normal spin and outer cruise configuration, with uplink and downlink via the high gain antenna; uplink at 125 bps, downlink at the 2 k engineering data rate.  as a result of the spacecraft entering contingency mode on april 9, all payload instruments were automatically powered off by on-board fault protection software.  gamma ray spectrometer random access memory was successfully reloaded on monday, april 19.  to prepare for magnetometer calibrations which were rescheduled for execution in flight sequence c9 on tuesday and wednesday of next week, a reload of payload data system random access memory will take place this morning beginning at 10:30 am.  over this weekend, the flight team will send real-time commands to perform differential one-way ranging to obtain additional data for analysis by the navigation team.  radio science ultra stable oscillator testing will take place on monday .  the flight sequence c9 uplink will occur on sunday, april 25, with activation at midnight, monday evening april 26.  c9 has been modified to include magnetometer calibrations which could not be performed in c8 due to contingency mode entry on april 9.  these magnetometer instrument calibrations will allow the instrument team to better characterize the spacecraft-generated magnetic field and its effect on their instrument. this information is critical to martian magnetic field measurements which occur during approach and mapping phases. mag cals will require the sequence to command the spacecraft out of array normal spin state and perform slew and roll maneuvers to provide the mag team data points in varying spacecraft attitudes and orientations.\n",
      "predicted_topic = religion, actual_topic = autos \n",
      "\n",
      "                 autos  religion  graphics     space\n",
      "mit           0.000000  0.000000  0.047629  0.000000\n",
      "lcs           0.000000  0.000000  0.044040  0.000000\n",
      "astronomical  0.000000  0.000000  0.007877  0.030512\n",
      "downey        0.000000  0.000000  0.000000  0.036553\n",
      "compute       0.000000  0.000000  0.012852  0.018830\n",
      "written       0.000000  0.007713  0.011453  0.002044\n",
      "export        0.012249  0.000855  0.003258  0.002430\n",
      "edu           0.003146  0.000617  0.005148  0.002677\n",
      "things        0.001691  0.002821  0.001143  0.003858\n",
      "many          0.001437  0.003698  0.001515  0.002362\n",
      "get           0.003121  0.001026  0.002454  0.002144\n",
      "go            0.003313  0.002129  0.001243  0.001909\n",
      "on            0.002105  0.001360  0.002667  0.001792\n",
      "and           0.001978  0.001698  0.002273  0.001576\n",
      "it            0.002166  0.001503  0.002022  0.001812\n",
      "this          0.001655  0.001783  0.002295  0.001757\n",
      "other         0.002027  0.001528  0.001859  0.002031\n",
      "by            0.001788  0.002192  0.001734  0.001712\n",
      "to            0.001962  0.001760  0.001994  0.001659\n",
      "is            0.001681  0.002063  0.001851  0.001780\n",
      "930420  do what thou wilt shall be the whole of the law. the word of sin is restriction.    sorry, the san jose based rosicrucian order is called a.m.o.r.c,  i don t remember for the time being what the a.m. stand for but o.r.c is ordo rosae crucis, in other words latin for order of the rose cross.    response:  yes, very true.  the entire title is  the ancient and mystical order  rosae crucis .  they are located at 1342 naglee avenue, san jose, california, 95191-0001, usa.  they are considered different and largely unrelated by a number of sources.  i ve seen documentation which links them through the figure of h. spencer lewis.  lewis was apparently involved with reuss, who was the o.h.o. of ordo templi orientis for many years.  apparently it is also true that lewis had a charter to form an o.t.o. body and then created a.m.o.r.c.  as a subsidiary?  an interesting question .   kent:  otherwise their headquarters in san jose has a pretty decent metaphysical bookstore, if any of you are interested in such books. and my son loves to run around in their egyptian museum.   response:  indeed, and diagonally across the street is another metaphysical book store called  ram metaphysical , wherein i ve purchased some wonderful works by crowley and others.  ram metaphysical books, 1749 park ave., san jose, ca.   408  294-2651.   invoke me under my stars.  love is the law, love under will.  i am i\n",
      "predicted_topic = graphics, actual_topic = space \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "minds       0.000000  0.016817  0.000000  0.000562\n",
      "select      0.000000  0.000000  0.016365  0.000813\n",
      "launch      0.000908  0.000000  0.000000  0.016196\n",
      "nasa        0.000000  0.000000  0.001343  0.015146\n",
      "gotta       0.010604  0.000000  0.000000  0.002645\n",
      "caution     0.000000  0.013055  0.000000  0.000000\n",
      "nt          0.000000  0.013055  0.000000  0.000000\n",
      "unexpected  0.000000  0.013055  0.000000  0.000000\n",
      "expected    0.000480  0.000326  0.001435  0.009081\n",
      "warning     0.000708  0.000000  0.001917  0.008578\n",
      "watching    0.008557  0.001793  0.000000  0.000798\n",
      "saying      0.000270  0.008219  0.000705  0.001319\n",
      "wondering   0.005826  0.000000  0.004554  0.000093\n",
      "forget      0.004049  0.000808  0.000096  0.001901\n",
      "dumb        0.003870  0.000143  0.000754  0.001814\n",
      "errors      0.000000  0.001736  0.003467  0.001272\n",
      "verify      0.003371  0.000000  0.002183  0.000917\n",
      "maybe       0.000358  0.000862  0.000798  0.001671\n",
      "say         0.000981  0.001554  0.000708  0.000356\n",
      "really      0.001407  0.001241  0.000506  0.000436\n",
      "who         0.000861  0.001493  0.000314  0.000900\n",
      "error       0.000276  0.001088  0.001310  0.000854\n",
      "am          0.000811  0.000519  0.001598  0.000575\n",
      "going       0.000918  0.001133  0.000261  0.001186\n",
      "know        0.001073  0.000604  0.001242  0.000398\n",
      "exactly     0.001444  0.000605  0.000725  0.000530\n",
      "while       0.001268  0.000738  0.000357  0.000925\n",
      "memory      0.000593  0.000455  0.000880  0.001349\n",
      "should      0.000648  0.000956  0.001208  0.000397\n",
      "no          0.000953  0.001200  0.000401  0.000643\n",
      "been        0.001080  0.000985  0.000348  0.000757\n",
      "just        0.001295  0.000552  0.000676  0.000604\n",
      "when        0.000947  0.000921  0.000351  0.000845\n",
      "they        0.001193  0.000704  0.000466  0.000693\n",
      "me          0.000701  0.000765  0.001054  0.000436\n",
      "for         0.000771  0.000499  0.001054  0.000595\n",
      "better      0.000721  0.000797  0.000422  0.000975\n",
      "think       0.001083  0.000683  0.000569  0.000571\n",
      "an          0.000973  0.000609  0.000648  0.000567\n",
      "well        0.000859  0.000625  0.000489  0.000814\n",
      "sorry       0.000456  0.000756  0.000845  0.000730\n",
      "what        0.000745  0.000716  0.000814  0.000475\n",
      "has         0.000899  0.000582  0.000704  0.000564\n",
      "are         0.000788  0.000838  0.000549  0.000569\n",
      "question    0.000694  0.000739  0.000812  0.000488\n",
      "something   0.000518  0.000625  0.000844  0.000746\n",
      "there       0.000670  0.000583  0.000888  0.000588\n",
      "would       0.000767  0.000494  0.000706  0.000747\n",
      "if          0.000826  0.000563  0.000731  0.000586\n",
      "but         0.000572  0.000672  0.000842  0.000611\n",
      "clear       0.000648  0.000785  0.000524  0.000737\n",
      "might       0.000706  0.000713  0.000515  0.000751\n",
      "this        0.000591  0.000637  0.000820  0.000628\n",
      "be          0.000613  0.000724  0.000589  0.000717\n",
      "to          0.000701  0.000629  0.000712  0.000593\n",
      "is          0.000601  0.000737  0.000661  0.000636\n",
      "yes, this is certainly one of the traditional ideas about the mithraic cult  although not the only one.   it had many elements that seem to have been borrowed by catholicism  e.g. the mass, communion, the sharing of a sacred meal, consecration of bread and wine, etc.   for quite an amusing novel that uses this same idea, check out:  the covenant of the flame by david morrell.  it has some quite interesting occult bits, and lots of killing. i won t spoil it by revealing the ending, but i will say that it is relevant to mithraism.\n",
      "predicted_topic = religion, actual_topic = space \n",
      "\n",
      "               autos  religion  graphics     space\n",
      "windows     0.002799  0.000000  0.027339  0.000525\n",
      "tremendous  0.000000  0.000000  0.026940  0.002264\n",
      "superior    0.004396  0.010075  0.001128  0.000261\n",
      "noise       0.010341  0.000757  0.001534  0.002365\n",
      "speeds      0.004541  0.000000  0.001770  0.008677\n",
      "simple      0.002923  0.001191  0.008190  0.000711\n",
      "flow        0.007459  0.003028  0.000142  0.002236\n",
      "vent        0.006846  0.003360  0.000000  0.002364\n",
      "designed    0.004832  0.000000  0.002503  0.004179\n",
      "create      0.002812  0.002914  0.005372  0.000061\n",
      "understand  0.001435  0.004326  0.002742  0.000527\n",
      "makes       0.004131  0.002743  0.000782  0.001043\n",
      "impossible  0.000974  0.000793  0.003713  0.002991\n",
      "right       0.004102  0.001094  0.001086  0.001800\n",
      "current     0.001407  0.000615  0.002383  0.003432\n",
      "even        0.001324  0.002840  0.000803  0.001816\n",
      "they        0.002387  0.001409  0.000931  0.001387\n",
      "above       0.001625  0.001966  0.001528  0.000798\n",
      "far         0.001124  0.001759  0.001017  0.001804\n",
      "with        0.001415  0.001521  0.001693  0.000928\n",
      "at          0.001407  0.000991  0.001793  0.001352\n",
      "are         0.001577  0.001676  0.001097  0.001137\n",
      "if          0.001652  0.001125  0.001462  0.001172\n",
      "and         0.001413  0.001213  0.001623  0.001126\n",
      "don         0.001466  0.001408  0.001093  0.001347\n",
      "more        0.001302  0.001367  0.001152  0.001458\n",
      "the         0.001455  0.001310  0.001331  0.001172\n",
      "that        0.001393  0.001426  0.001222  0.001223\n",
      "ii samuel 24: and again the anger of the lord was kindled against israel, and he moved david against them to say, go, number isreal and judah.\n",
      "predicted_topic = graphics, actual_topic = autos \n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [autos, religion, graphics, space]\n",
      "Index: []\n",
      "mr. meritt, please state explicitly the inductive argument which leads you to conclude mr. tice thinks it  ok  to take biblical quotes out of context in some other t.r.m. articles.  also, please explain why you rely on inductive reasoning  with its implicit uncertainty  in determining mr. tice s opinions when the man is himself clearly available for questioning.  finally, please indicate whether you agree  yes or no  with the following statement:\n",
      "predicted_topic = autos, actual_topic = graphics \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training = False\n",
    "tlabels = train_labels if training else test_labels\n",
    "tdoc_vectors = train_doc_vectors if training else test_doc_vectors\n",
    "misclassified = misclassified_train if training else misclassified_test\n",
    "\n",
    "for doc_index in tqdm(misclassified):\n",
    "    doc_vector = tdoc_vectors[doc_index]\n",
    "    doc_topic_word_distr, doc_topic = infer_topic(label_classes, doc_vector, topic_word_distr)\n",
    "    \n",
    "    xv = doc_topic_word_distr.iloc[np.where(doc_topic_word_distr.sum(1) > 0)]\n",
    "    print(xv.loc[xv.sum(1).sort_values(ascending=False).index])\n",
    "    print(train_docs[doc_index])\n",
    "    print(f\"predicted_topic = {doc_topic}, actual_topic = {label_classes[tlabels[doc_index]]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07692308, 0.03846154, 0.03703704, 0.03225806, 0.02777778,\n",
       "       0.02631579, 0.02564103, 0.025     , 0.02380952, 0.02325581,\n",
       "       0.02      , 0.01960784, 0.01923077, 0.01818182, 0.01785714,\n",
       "       0.01694915, 0.01587302, 0.01408451, 0.01351351, 0.01123596])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xv = train_doc_vectors[:, vocabulary.index(\"enough\")]\n",
    "xv[xv.argsort()[::-1]][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usually....go enough places and you ll see stuff happen you didn t think did. ====> autos\n",
      "\n",
      "where does the shadow come from?  there s nothing close enough to block sunlight from hitting them.  i wouldn t expect there to be anything block our view of them either.  what am i missing? ====> space\n",
      "\n",
      "if raw materials where to cost enough that getting them from space would be cost effective then the entire world economy would colapse long before the space mines could be built.    allen ====> space\n",
      "\n",
      "too many clues, not enough substance.  you ask a lot of good questions, though, but they are questions *you* should be worried about, not me.  i m not the inerrantist here.  let me know when you are ready to get serious. ====> religion\n",
      "\n",
      "recently-manufactured locomotives have wheel-slip detection systems that use frequencies shared with police radar  i forget which band . these will set off your radar detector if you get close enough, though i believe the range is pretty short. ====> autos\n",
      "\n",
      "right. in the thirties both buick and packard had two spares mounted in wells in the front fenders. of course that was back when the front fenders were long enough to provide room. there were a couple of other marques that did this as well, but memory fades. ====> autos\n",
      "\n",
      "cup holders  driving is an importantant enough undertaking  cellular phones and mobile fax machines  see above  vanity mirrors on the driver s side. ashtrays  smokers seem to think it s just fine to use the road  fake convertible roofs and vinyl roofs. any gold trim. ====> autos\n",
      "\n",
      "i bought an intrepid about two months ago and am very happy with it.  lots of room inside and even with the smaller engine it has enough power for me.  the only problem i found was a small selection on the dealer s lots. they are hot sellers around here. ====> autos\n",
      "\n",
      "well, first you work out how much cold gas you need, then make the tanks big enough.  working out how much cold gas is another problem, depending on vehicle configuration, flight duration, thruster isp  which couples into storage pressure, which may be a factor in selecting tank wall thickness etc. ====> space\n",
      "\n",
      "hi, i ve come across a fast triangle fill-draw routine for mode 13h.  by calling this routine enough times, you have a fast polygon drawing routine.  i think i ftp ed from wuarchive.wustl.edu:/pub/msdos_uploads/programming. i have a copy of it so i reupload it there.  the triangle.txt file has this to say : ====> graphics\n",
      "\n",
      "the girl s ok, actually, and she recovered well enough to go home.  i don t know if she has any permanent damage, though.  just in case anybody was concerned...    if people start forcing others to take responsibility for their actions things like this wouldn t happen.  untill we stop blaming outside causes, and start blaming the criminals, we will continue to let things like this happen. ====> autos\n",
      "\n",
      "hmmm....i was listening to the local radio expert  who is, amazingly enough, an honest-to-god expert tm ; it s amazing what he knows... ,  and he said that, based on his conversations with the inventor of  slick50  who is no longer with the comapny, due to some kind of  conflict , he avoids it like the plague.  he does recommend other  teflon-based/type oil additives, though.      james ====> autos\n",
      "\n",
      "i like my power windows. i think they re worth it.  however, cruise control is a pretty dumb option. what s the point? if you re on a long trip, you floor the gas and keep your eyes on the rear-view mirror for cops, right?  power seats are pretty dumb too, unless you re unlucky enough to have to share your car. otherwise, you d just adjust it once and just leave it like that. ====> autos\n",
      "\n",
      "depends. if you assume the existance of a working ssto like dc, on billion $$ would be enough to put about a quarter million pounds of stuff on the moon. if some of that mass went to send equipment to make lox for the transfer vehicle, you could send a lot more. either way, its a lot more than needed.  this prize isn t big enough to warrent developing a ssto, but it is enough to do it if the vehicle exists.    allen ====> space\n",
      "\n",
      "how about brass or silver?  i ve seen real chessboards that use that material.   right here is as good a place as any.  can t wait to see it.  i use the pov raytracer - is it compatible enough for your chessboard?  -------------------------------------------------------------------------------       i don t know if you ve got the whole picture or not, but it doesn t        seem like he s running on all thrusters   -- leonard mccoy        a guess?  you, spock?  that s extraordinary   -- james t. kirk ====> graphics\n",
      "\n",
      "no. reverse lights are to warn others that you are backing up. they aren t bright enough to  typically  see by without the brake and tail lights.    well, red and orange were already taken. maybe white defines the direction that the car is moving in.   if you really want to be able to see behind you, get some fog lamps for the back of the car. these work very well - and are a good way to get rid of tailgaters if you get that rush of testosterone. ====> autos\n",
      "\n",
      "[constitution sacrificed to the bandwidth gods]  im glad i finally have heard exactly what the oto is all about.  i finally know that i can stop looking, content i the knowlege that im not interested. it s tough enough listening to all the religions who refer to themselves as  the one truth .  how can i possibly accept it from a magical order?   we have all the answers and will give them to those who join us  and pay dues ?  scary.  besides, answers are easy.  questions   now that s another story...  rintaw ====> religion\n",
      "\n",
      ">very cost effective if you use the right accounting method :-      sherzer methodology        hell, yes. i m not going to let a bunch of seven suits tell me what the right way to estimate cost effectiveness is, at least not until they can make their mind up long enough to leave their scheme stable for a fiscal year or two.   seriously though. if you were to ask the british government whether their colonisation efforts in the americas were cost effective, what answer do you think you d get? what if you asked in 1765, 1815, 1865, 1915 and 1945 respectively? ;- ====> space\n",
      "\n",
      "in spite of my great respect for the people you speak of, i think their cost estimates are a bit over-optimistic. if nothing else, a working ssto is at least as complex as a large airliner and has a smaller experience base. it therefore seems that ssto development should cost at least as much as a typical airliner development. that puts it in the $3g to $5g range.   true it and the contest would result in a much larger market. but i don t think it would be enough to attract the investors given the risks involved.  if you could gurantee the ssto costs and gurantee that it captures 100% of the available launch market, then i think you could do it.    allen ====> space\n",
      "\n",
      "all of this talk about a commercial space race  i.e. $1g to the first 1-year  moon base  is intriguing. similar prizes have influenced aerospace  development before. the $25k orteig prize helped lindbergh sell his spirit of  saint louis venture to his financial backers.  if memory serves, the $25k prize would not have been enough to totally  reimburse some of the more expensive transatlantic projects  such as  fokker s, nungesser and other multi-engine projects . however lindbergh  ultimately kept his total costs below that amount.  but i strongly suspect that his saint louis backers had the foresight to  realize that much more was at stake than $25,000.  could it work with the moon? who are the far-sighted financial backers of  today? ====> space\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index in xv.argsort()[::-1][:20]:\n",
    "    print(train_docs[index], '====>', label_classes[train_labels[index]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xv.argsort()[::-1][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

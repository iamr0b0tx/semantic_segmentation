{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + (np.e**-x))\n",
    "\n",
    "def infer_topic(doc_vector, topic_word_distr):\n",
    "    doc_topic_word_distr = topic_word_distr.copy()\n",
    "    doc_word_freq_norm = (doc_vector > 0).astype(int)\n",
    "#     doc_word_freq_norm = doc_vector / doc_vector.sum() if doc_vector.sum() else 0\n",
    "\n",
    "    for label_class in label_classes:\n",
    "        doc_topic_word_distr[label_class] *= doc_word_freq_norm\n",
    "    \n",
    "    \n",
    "    doc_topic = np.max(doc_topic_word_distr).idxmax()\n",
    "    return doc_topic_word_distr, doc_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of samples needed\n",
    "datasize = 1000\n",
    "\n",
    "# retrieve dataset\n",
    "docs = fetch_20newsgroups(subset='train', shuffle=False, remove=('headers', 'footers', 'quotes'))\n",
    "docs, old_labels, classes = docs.data[:datasize], docs.target[:datasize], docs.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the actual labels as np array\n",
    "old_labels = np.array(old_labels)\n",
    "labels = np.zeros(old_labels.shape, dtype=int)\n",
    "\n",
    "# the new classes\n",
    "label_classes = list(set([x.split('.')[0] for x in classes]))\n",
    "\n",
    "# restructuring classes  from 19 to less\n",
    "for label, cl in enumerate(classes):\n",
    "    labels[old_labels == label] = label_classes.index(cl.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 1000 docs and 7 classes: ['rec', 'sci', 'misc', 'comp', 'alt', 'talk', 'soc']\n"
     ]
    }
   ],
   "source": [
    "print(f\"there are {len(docs)} docs and {len(label_classes)} classes: {label_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'morgan and guzman will have era s 1 run higher than last year, and  the cubs will be idiots and not pitch harkey as much as hibbard.  castillo won t be good  i think he s a stud pitcher'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean out the new line characters from text in docs\n",
    "def clean_doc(doc):\n",
    "    ''' remove unwanter characters line new line '''\n",
    "\n",
    "    unwanted_chrs = [')', '(', '{', '}', '\\t', '\\n', '\\r', \"'\", '\"', \"!\"]\n",
    "    doc = doc.lower()\n",
    "    for unwanted_chr in unwanted_chrs:\n",
    "        doc = doc.replace(unwanted_chr, ' ')\n",
    "\n",
    "    return doc.strip()\n",
    "\n",
    "clean_docs = [clean_doc(doc) for doc in docs]\n",
    "clean_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### count words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_count is 19476\n"
     ]
    }
   ],
   "source": [
    "# initialize the count vectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "# count_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# fit it to dataset\n",
    "count_vectorizer.fit(clean_docs)\n",
    "\n",
    "words = count_vectorizer.get_feature_names()\n",
    "\n",
    "print(\"word_count is\", len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Datatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670 train_docs, 330 test docs\n"
     ]
    }
   ],
   "source": [
    "# create doc count vectors\n",
    "doc_vectors = count_vectorizer.transform(clean_docs).toarray()\n",
    "\n",
    "\n",
    "\n",
    "train_doc_vectors, test_doc_vectors, train_labels, test_labels = train_test_split(doc_vectors, labels, test_size=.33, random_state=42)\n",
    "print(f\"{len(train_labels)} train_docs, {len(test_labels)} test docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document_word_frequency shape is (670, 19477)\n"
     ]
    }
   ],
   "source": [
    "document_word_frequency = pd.DataFrame(train_doc_vectors, columns=count_vectorizer.get_feature_names())\n",
    "document_word_binary_frequency = (document_word_frequency > 0).astype('int')\n",
    "\n",
    "document_word_frequency[\"__labels__\"] = train_labels\n",
    "document_word_binary_frequency[\"__labels__\"] = train_labels\n",
    "\n",
    "print(\"document_word_frequency shape is\", document_word_frequency.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 1000 docs and 7 classes\n"
     ]
    }
   ],
   "source": [
    "print(f\"there are {len(clean_docs)} docs and {len(label_classes)} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>00000000</th>\n",
       "      <th>00000000b</th>\n",
       "      <th>00000001</th>\n",
       "      <th>00000001b</th>\n",
       "      <th>00000010</th>\n",
       "      <th>00000010b</th>\n",
       "      <th>00000011</th>\n",
       "      <th>...</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoomed</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zubov</th>\n",
       "      <th>zum</th>\n",
       "      <th>zupancic</th>\n",
       "      <th>zx</th>\n",
       "      <th>zx900a</th>\n",
       "      <th>zzz</th>\n",
       "      <th>__labels__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19477 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0000  00000000  00000000b  00000001  00000001b  00000010  \\\n",
       "0   0    0     0         0          0         0          0         0   \n",
       "1   0    0     0         0          0         0          0         0   \n",
       "2   0    0     0         0          0         0          0         0   \n",
       "3   0    0     0         0          0         0          0         0   \n",
       "4   0    0     0         0          0         0          0         0   \n",
       "\n",
       "   00000010b  00000011  ...  zoom  zoomed  zooming  zubov  zum  zupancic  zx  \\\n",
       "0          0         0  ...     0       0        0      0    0         0   0   \n",
       "1          0         0  ...     0       0        0      0    0         0   0   \n",
       "2          0         0  ...     0       0        0      0    0         0   0   \n",
       "3          0         0  ...     0       0        0      0    0         0   0   \n",
       "4          0         0  ...     0       0        0      0    0         0   0   \n",
       "\n",
       "   zx900a  zzz  __labels__  \n",
       "0       0    0           1  \n",
       "1       0    0           3  \n",
       "2       0    0           5  \n",
       "3       0    0           1  \n",
       "4       0    0           0  \n",
       "\n",
       "[5 rows x 19477 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_word_frequency.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>00000000</th>\n",
       "      <th>00000000b</th>\n",
       "      <th>00000001</th>\n",
       "      <th>00000001b</th>\n",
       "      <th>00000010</th>\n",
       "      <th>00000010b</th>\n",
       "      <th>00000011</th>\n",
       "      <th>...</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoomed</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zubov</th>\n",
       "      <th>zum</th>\n",
       "      <th>zupancic</th>\n",
       "      <th>zx</th>\n",
       "      <th>zx900a</th>\n",
       "      <th>zzz</th>\n",
       "      <th>__labels__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19477 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0000  00000000  00000000b  00000001  00000001b  00000010  \\\n",
       "0   0    0     0         0          0         0          0         0   \n",
       "1   0    0     0         0          0         0          0         0   \n",
       "2   0    0     0         0          0         0          0         0   \n",
       "3   0    0     0         0          0         0          0         0   \n",
       "4   0    0     0         0          0         0          0         0   \n",
       "\n",
       "   00000010b  00000011  ...  zoom  zoomed  zooming  zubov  zum  zupancic  zx  \\\n",
       "0          0         0  ...     0       0        0      0    0         0   0   \n",
       "1          0         0  ...     0       0        0      0    0         0   0   \n",
       "2          0         0  ...     0       0        0      0    0         0   0   \n",
       "3          0         0  ...     0       0        0      0    0         0   0   \n",
       "4          0         0  ...     0       0        0      0    0         0   0   \n",
       "\n",
       "   zx900a  zzz  __labels__  \n",
       "0       0    0           1  \n",
       "1       0    0           3  \n",
       "2       0    0           5  \n",
       "3       0    0           1  \n",
       "4       0    0           0  \n",
       "\n",
       "[5 rows x 19477 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_word_binary_frequency.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Binary Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#reduce freq in doc to bin value of 1 or 0\n",
    "# word_doc_binary_freqency = document_word_binary_frequency.drop([\"__labels__\"], axis='columns')\n",
    "word_doc_binary_freqency = document_word_frequency.drop([\"__labels__\"], axis='columns')\n",
    "\n",
    "#the sum vertically of bin freq\n",
    "word_doc_frequency = word_doc_binary_freqency.sum(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic and word corelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_word_distr has shape (19476, 7)\n"
     ]
    }
   ],
   "source": [
    "topic_word_distr = pd.DataFrame(data=0.0, columns=label_classes, index=words)\n",
    "\n",
    "for topic, label in enumerate(label_classes):\n",
    "    word_topic_frequency = word_doc_binary_freqency[document_word_frequency['__labels__'] == topic].sum(0)\n",
    "    trust_factor = sigmoid(word_doc_frequency)\n",
    "    \n",
    "    topic_word_distr[label] = ((word_topic_frequency * trust_factor) / word_doc_frequency).fillna(0)\n",
    "    \n",
    "print(f\"topic_word_distr has shape {topic_word_distr.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rec</th>\n",
       "      <th>sci</th>\n",
       "      <th>misc</th>\n",
       "      <th>comp</th>\n",
       "      <th>alt</th>\n",
       "      <th>talk</th>\n",
       "      <th>soc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.166666</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499997</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00000000</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.880797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00000000b</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.880797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                rec       sci      misc      comp  alt      talk       soc\n",
       "00         0.083333  0.083333  0.166666  0.083333  0.0  0.499997  0.083333\n",
       "000        0.266667  0.133333  0.066667  0.066667  0.0  0.466667  0.000000\n",
       "0000       0.000000  0.000000  0.000000  0.000000  0.0  0.000000  0.000000\n",
       "00000000   0.000000  0.880797  0.000000  0.000000  0.0  0.000000  0.000000\n",
       "00000000b  0.000000  0.880797  0.000000  0.000000  0.0  0.000000  0.000000"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word_distr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rec', 'sci', 'misc', 'comp', 'alt', 'talk', 'soc']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3t            1.000000\n",
       "1d9           1.000000\n",
       "b8f           1.000000\n",
       "wm            1.000000\n",
       "9v            1.000000\n",
       "                ...   \n",
       "game          0.014706\n",
       "him           0.013605\n",
       "government    0.011494\n",
       "si            0.010417\n",
       "db            0.005415\n",
       "Name: comp, Length: 4148, dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_class = 'comp'\n",
    "topic_word_distr[label_class][topic_word_distr[label_class] > 0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rec     0.145125\n",
       "sci     0.175471\n",
       "misc    0.016297\n",
       "comp    0.131498\n",
       "alt     0.025709\n",
       "talk    0.431582\n",
       "soc     0.074319\n",
       "Name: the, dtype: float64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word_distr.loc[\"the\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word word corelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5de21913765040d1a7bd60b1f0785d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5550.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "word_word_distr has shape (5550, 5550)\n"
     ]
    }
   ],
   "source": [
    "word_word_distr = pd.DataFrame(data=0.0, columns=words, index=words)\n",
    "\n",
    "for word in tqdm(words):\n",
    "    word_word_frequency = word_doc_binary_freqency[word_doc_binary_freqency[word] > 0].sum(0)\n",
    "    trust_factor = sigmoid(word_doc_frequency)\n",
    "\n",
    "    word_word_co = ((word_word_frequency * trust_factor) / word_doc_frequency).fillna(0)\n",
    "    word_word_distr[word][word_word_co > word_word_distr[word]] = word_word_co[word_word_co > word_word_distr[word]]\n",
    "\n",
    "word_word_distr = word_word_distr.T\n",
    "print(\"word_word_distr has shape\", word_word_distr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0188</th>\n",
       "      <th>02026</th>\n",
       "      <th>04110</th>\n",
       "      <th>0837</th>\n",
       "      <th>0988</th>\n",
       "      <th>0q</th>\n",
       "      <th>0qax</th>\n",
       "      <th>0qq</th>\n",
       "      <th>...</th>\n",
       "      <th>z5</th>\n",
       "      <th>z6e1</th>\n",
       "      <th>z6e1t</th>\n",
       "      <th>z6ei</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zeh</th>\n",
       "      <th>zip</th>\n",
       "      <th>zirconium</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoomed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.880797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0188</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.731059</td>\n",
       "      <td>0.731059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.731059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.440399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02026</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.731059</td>\n",
       "      <td>0.731059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.731059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.440399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04110</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5550 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        00       000      0188     02026  04110      0837  0988   0q  0qax  \\\n",
       "00     0.0  0.000000  0.000000  0.000000    0.0  0.000000   0.0  0.0   0.0   \n",
       "000    0.0  0.880797  0.000000  0.000000    0.0  0.000000   0.0  0.0   0.0   \n",
       "0188   0.0  0.000000  0.731059  0.731059    0.0  0.731059   0.0  0.0   0.0   \n",
       "02026  0.0  0.000000  0.731059  0.731059    0.0  0.731059   0.0  0.0   0.0   \n",
       "04110  0.0  0.000000  0.000000  0.000000    0.0  0.000000   0.0  0.0   0.0   \n",
       "\n",
       "       0qq  ...   z5  z6e1  z6e1t  z6ei  zealand  zeh       zip  zirconium  \\\n",
       "00     0.0  ...  0.0   0.0    0.0   0.0      0.0  0.0  0.000000        0.0   \n",
       "000    0.0  ...  0.0   0.0    0.0   0.0      0.0  0.0  0.000000        0.0   \n",
       "0188   0.0  ...  0.0   0.0    0.0   0.0      0.0  0.0  0.440399        0.0   \n",
       "02026  0.0  ...  0.0   0.0    0.0   0.0      0.0  0.0  0.440399        0.0   \n",
       "04110  0.0  ...  0.0   0.0    0.0   0.0      0.0  0.0  0.000000        0.0   \n",
       "\n",
       "       zone  zoomed  \n",
       "00      0.0     0.0  \n",
       "000     0.0     0.0  \n",
       "0188    0.0     0.0  \n",
       "02026   0.0     0.0  \n",
       "04110   0.0     0.0  \n",
       "\n",
       "[5 rows x 5550 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_word_distr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "of              0.952574\n",
       "computer        0.952574\n",
       "machine         0.952574\n",
       "for             0.952574\n",
       "am              0.952574\n",
       "an              0.952574\n",
       "and             0.952574\n",
       "to              0.952574\n",
       "one             0.952574\n",
       "be              0.952574\n",
       "in              0.952574\n",
       "the             0.952574\n",
       "out             0.952574\n",
       "have            0.635049\n",
       "if              0.635049\n",
       "is              0.635049\n",
       "functions       0.635049\n",
       "it              0.635049\n",
       "just            0.635049\n",
       "has             0.635049\n",
       "fast            0.635049\n",
       "from            0.635049\n",
       "first           0.635049\n",
       "much            0.635049\n",
       "by              0.635049\n",
       "but             0.635049\n",
       "at              0.635049\n",
       "as              0.635049\n",
       "any             0.635049\n",
       "also            0.635049\n",
       "all             0.635049\n",
       "might           0.635049\n",
       "you             0.635049\n",
       "not             0.635049\n",
       "substitution    0.635049\n",
       "with            0.635049\n",
       "which           0.635049\n",
       "well            0.635049\n",
       "was             0.635049\n",
       "up              0.635049\n",
       "time            0.635049\n",
       "this            0.635049\n",
       "they            0.635049\n",
       "these           0.635049\n",
       "there           0.635049\n",
       "such            0.635049\n",
       "store           0.635049\n",
       "would           0.635049\n",
       "so              0.635049\n",
       "series          0.635049\n",
       "seen            0.635049\n",
       "saw             0.635049\n",
       "price           0.635049\n",
       "own             0.635049\n",
       "over            0.635049\n",
       "other           0.635049\n",
       "ordered         0.635049\n",
       "or              0.635049\n",
       "on              0.635049\n",
       "610             0.635049\n",
       "Name: computer, dtype: float64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"computer\"\n",
    "word_word_distr[word][word_word_distr[word] > .5].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c45a764488d43a89072cb5e2884cf4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5550.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "re_topic_word_distr has shape (5550, 7)\n"
     ]
    }
   ],
   "source": [
    "re_topic_word_distr = pd.DataFrame(data=0.0, columns=label_classes, index=words)\n",
    "\n",
    "for word in tqdm(words):\n",
    "    word_word_co = word_word_distr[word]\n",
    "    \n",
    "    for label_class in label_classes:\n",
    "        infered_ratio = (word_word_co * topic_word_distr[label_class]).max()\n",
    "        \n",
    "        if infered_ratio > re_topic_word_distr[label_class][word]:\n",
    "            re_topic_word_distr[label_class][word] = infered_ratio\n",
    "            \n",
    "print(\"re_topic_word_distr has shape\", re_topic_word_distr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>talk</th>\n",
       "      <th>sci</th>\n",
       "      <th>alt</th>\n",
       "      <th>rec</th>\n",
       "      <th>soc</th>\n",
       "      <th>misc</th>\n",
       "      <th>comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>0.432477</td>\n",
       "      <td>0.559350</td>\n",
       "      <td>0.279675</td>\n",
       "      <td>0.279675</td>\n",
       "      <td>0.279675</td>\n",
       "      <td>0.193951</td>\n",
       "      <td>0.524941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0188</th>\n",
       "      <td>0.464258</td>\n",
       "      <td>0.696387</td>\n",
       "      <td>0.321957</td>\n",
       "      <td>0.464258</td>\n",
       "      <td>0.321957</td>\n",
       "      <td>0.321957</td>\n",
       "      <td>0.538432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02026</th>\n",
       "      <td>0.464258</td>\n",
       "      <td>0.696387</td>\n",
       "      <td>0.321957</td>\n",
       "      <td>0.464258</td>\n",
       "      <td>0.321957</td>\n",
       "      <td>0.321957</td>\n",
       "      <td>0.538432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04110</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           talk       sci       alt       rec       soc      misc      comp\n",
       "00     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "000    0.432477  0.559350  0.279675  0.279675  0.279675  0.193951  0.524941\n",
       "0188   0.464258  0.696387  0.321957  0.464258  0.321957  0.321957  0.538432\n",
       "02026  0.464258  0.696387  0.321957  0.464258  0.321957  0.321957  0.538432\n",
       "04110  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_topic_word_distr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sci     0.696387\n",
       "comp    0.487369\n",
       "talk    0.364625\n",
       "misc    0.358955\n",
       "rec     0.321957\n",
       "alt     0.321957\n",
       "soc     0.232129\n",
       "Name: companies, dtype: float64"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"companies\"\n",
    "re_topic_word_distr.loc[word].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(f\"{word} against TOPICS\")\n",
    "plt.bar(re_topic_word_distr.loc[word].index, re_topic_word_distr.loc[word])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Topic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb2cd4b43bc64d2ebf627df98a232921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=670.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> train-accuracy is 91.19% and re is 91.19%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score1 = score2 = 0\n",
    "print(\"Evaluating Topic Model...\")\n",
    "for doc_index in tqdm(range(len(train_labels))):\n",
    "    doc_vector = train_doc_vectors[doc_index]\n",
    "    \n",
    "    doc_topic_word_distr, doc_topic = infer_topic(doc_vector, topic_word_distr)\n",
    "    score1 += int(doc_topic == label_classes[train_labels[doc_index]])\n",
    "    \n",
    "#     doc_topic_word_distr, doc_topic = infer_topic(doc_vector, re_topic_word_distr)\n",
    "    score2 += int(doc_topic == label_classes[train_labels[doc_index]])\n",
    "    \n",
    "    if score1:\n",
    "        continue\n",
    "    \n",
    "#     print(clean_docs[len(train_labels)+doc_index])\n",
    "#     print(\"{:8s} {:16s} {:6s}\".format(\"topic\", \"word\", \"relation\"))\n",
    "#     print(\"=\"*40)\n",
    "#     for label, word in doc_topic_word_distr.idxmax().items():\n",
    "#         print(\"{:8s} {:16s} {:.4f}\".format(label, word, doc_topic_word_distr[label][word]))\n",
    "\n",
    "#     print(f\"\\nthe topic predicted is ==> '{np.max(doc_topic_word_distr).idxmax()}'\")\n",
    "#     print(f\"the actual topic is ==> '{label_classes[labels[doc_index]]}'\")\n",
    "\n",
    "accuracy1 = score1 / (doc_index + 1)\n",
    "accuracy2 = score2 / (doc_index + 1)\n",
    "print(f\"==> train-accuracy is {accuracy1*100:.2f}% and re is {accuracy2*100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Topic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78f233b979e49c9ac3fc399ce10c318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=330.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> test-accuracy is 60.30% and re is 60.30%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score1 = score2 = 0\n",
    "print(\"Evaluating Topic Model...\")\n",
    "for doc_index in tqdm(range(len(test_labels))):\n",
    "    doc_vector = test_doc_vectors[doc_index]\n",
    "    \n",
    "    doc_topic_word_distr, doc_topic = infer_topic(doc_vector, topic_word_distr)\n",
    "    score1 += int(doc_topic == label_classes[test_labels[doc_index]])\n",
    "    \n",
    "#     doc_topic_word_distr, doc_topic = infer_topic(doc_vector, re_topic_word_distr)\n",
    "    score2 += int(doc_topic == label_classes[test_labels[doc_index]])\n",
    "    \n",
    "    if score1:\n",
    "        continue\n",
    "    \n",
    "#     print(clean_docs[len(train_labels)+doc_index])\n",
    "#     print(\"{:8s} {:16s} {:6s}\".format(\"topic\", \"word\", \"relation\"))\n",
    "#     print(\"=\"*40)\n",
    "#     for label, word in doc_topic_word_distr.idxmax().items():\n",
    "#         print(\"{:8s} {:16s} {:.4f}\".format(label, word, doc_topic_word_distr[label][word]))\n",
    "\n",
    "#     print(f\"\\nthe topic predicted is ==> '{np.max(doc_topic_word_distr).idxmax()}'\")\n",
    "#     print(f\"the actual topic is ==> '{label_classes[labels[doc_index]]}'\")\n",
    "\n",
    "accuracy1 = score1 / (doc_index + 1)\n",
    "accuracy2 = score2 / (doc_index + 1)\n",
    "print(f\"==> test-accuracy is {accuracy1*100:.2f}% and re is {accuracy2*100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sci', 'soc', 'misc', 'rec', 'alt', 'comp', 'talk']"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\christian\\documents\\christian\\work\\python\\cyberspace\\semantic_segmentation\\venv\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670 training data\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = np.nan_to_num(train_doc_vectors / train_doc_vectors.sum(0))\n",
    "y = train_labels\n",
    "\n",
    "clf = LogisticRegression(random_state=0, fit_intercept=False).fit(X, y)\n",
    "# clf = LogisticRegression(random_state=0, fit_intercept=False, multi_class=\"multinomial\", solver=\"lbfgs\").fit(X, y)\n",
    "\n",
    "print(len(X), \"training data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['nutek', 'crt', 'soundblaster', ..., 'conservatives',\n",
       "       'informative', 'canceled'], dtype='<U79')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(count_vectorizer.get_feature_names())[clf.coef_[3].argsort()][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rec', 'sci', 'misc', 'comp', 'alt', 'talk', 'soc']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9776119402985075"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\christian\\documents\\christian\\work\\python\\cyberspace\\semantic_segmentation\\venv\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6818181818181818"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX = np.nan_to_num(test_doc_vectors / test_doc_vectors.sum(0))#[test_labels == 2]\n",
    "yy = test_labels#[test_labels == 2]\n",
    "\n",
    "clf.score(XX, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330, 330)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels), len(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\christian\\documents\\christian\\work\\python\\cyberspace\\semantic_segmentation\\venv\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "224df9fa0cc5450da72d7e5091cacf21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19476.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = np.nan_to_num(train_doc_vectors / train_doc_vectors.sum(0))\n",
    "y = train_labels\n",
    "\n",
    "models = []\n",
    "for index in tqdm(range(len(count_vectorizer.get_feature_names()))):\n",
    "    clf = LogisticRegression(random_state=0).fit(X[:, index:index+1], y)\n",
    "    models.append(clf)\n",
    "    \n",
    "#     print(\"training score\", clf.score(X[:, index:index+1], y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\christian\\documents\\christian\\work\\python\\cyberspace\\semantic_segmentation\\venv\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "135ff0c05911459db0e5731f62fda925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19476.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5151515151515151"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX = np.nan_to_num(test_doc_vectors / test_doc_vectors.sum(0))\n",
    "yy = test_labels\n",
    "\n",
    "p = np.zeros((len(XX[:, 0]), 7))\n",
    "\n",
    "for index in tqdm(range(len(count_vectorizer.get_feature_names()))):\n",
    "    clf = models[index]\n",
    "    prob = clf.predict_proba(XX[:, index:index+1])\n",
    "    p[prob > p] = prob[prob > p]\n",
    "\n",
    "(p.argmax(1) == yy).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24242424242424243"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

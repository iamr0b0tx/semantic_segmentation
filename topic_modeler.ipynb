{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5],\n",
       "       [6, 7],\n",
       "       [8, 9]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = np.arange(10).reshape((5, 2)), range(5)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 5)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=2/5, random_state=42, shuffle=False)\n",
    "X_train1\n",
    "# assert (X_train, X_test, y_train, y_test) == train_test_split(X, y, test_size=2/5, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=2/5, random_state=42, shuffle=False)\n",
    "X_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = {}\n",
    "z.get(0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9795918367346939"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "48 / 49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + (np.e**-x))\n",
    "\n",
    "def infer_topic(doc_vector, topic_word_distr):\n",
    "    doc_topic_word_distr = topic_word_distr.copy()\n",
    "    doc_word_freq_norm = (doc_vector > 0).astype(int)\n",
    "#     doc_word_freq_norm = doc_vector / doc_vector.sum() if doc_vector.sum() else 0\n",
    "\n",
    "    for label_class in label_classes:\n",
    "        doc_topic_word_distr[label_class] *= doc_word_freq_norm\n",
    "    \n",
    "    \n",
    "    doc_topic = np.max(doc_topic_word_distr).idxmax()\n",
    "    return doc_topic_word_distr, doc_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of samples needed\n",
    "datasize = 100\n",
    "\n",
    "# retrieve dataset\n",
    "docs = fetch_20newsgroups(subset='train', shuffle=False, remove=('headers', 'footers', 'quotes'))\n",
    "docs, old_labels, classes = docs.data[:datasize], docs.target[:datasize], docs.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the actual labels as np array\n",
    "old_labels = np.array(old_labels)\n",
    "labels = np.zeros(old_labels.shape, dtype=int)\n",
    "\n",
    "# the new classes\n",
    "label_classes = list(set([x.split('.')[0] for x in classes]))\n",
    "\n",
    "# restructuring classes  from 19 to less\n",
    "for label, cl in enumerate(classes):\n",
    "    labels[old_labels == label] = label_classes.index(cl.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 100 docs and 7 classes: ['talk', 'sci', 'alt', 'rec', 'soc', 'misc', 'comp']\n"
     ]
    }
   ],
   "source": [
    "print(f\"there are {len(docs)} docs and {len(label_classes)} classes: {label_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'morgan and guzman will have era s 1 run higher than last year, and  the cubs will be idiots and not pitch harkey as much as hibbard.  castillo won t be good  i think he s a stud pitcher'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean out the new line characters from text in docs\n",
    "def clean_doc(doc):\n",
    "    ''' remove unwanter characters line new line '''\n",
    "\n",
    "    unwanted_chrs = [')', '(', '{', '}', '\\t', '\\n', '\\r', \"'\", '\"', \"!\"]\n",
    "    doc = doc.lower()\n",
    "    for unwanted_chr in unwanted_chrs:\n",
    "        doc = doc.replace(unwanted_chr, ' ')\n",
    "\n",
    "    return doc.strip()\n",
    "\n",
    "clean_docs = [clean_doc(doc) for doc in docs]\n",
    "clean_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### count words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_count is 5550\n"
     ]
    }
   ],
   "source": [
    "# initialize the count vectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "# count_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# fit it to dataset\n",
    "count_vectorizer.fit(clean_docs)\n",
    "\n",
    "words = count_vectorizer.get_feature_names()\n",
    "\n",
    "print(\"word_count is\", len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Datatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 train_docs, 33 test docs\n"
     ]
    }
   ],
   "source": [
    "# create doc count vectors\n",
    "doc_vectors = count_vectorizer.transform(clean_docs).toarray()\n",
    "\n",
    "\n",
    "\n",
    "train_doc_vectors, test_doc_vectors, train_labels, test_labels = train_test_split(doc_vectors, labels, test_size=.33, random_state=42)\n",
    "print(f\"{len(train_labels)} train_docs, {len(test_labels)} test docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document_word_frequency shape is (67, 5551)\n"
     ]
    }
   ],
   "source": [
    "document_word_frequency = pd.DataFrame(train_doc_vectors, columns=count_vectorizer.get_feature_names())\n",
    "document_word_binary_frequency = (document_word_frequency > 0).astype('int')\n",
    "\n",
    "document_word_frequency[\"__labels__\"] = train_labels\n",
    "document_word_binary_frequency[\"__labels__\"] = train_labels\n",
    "\n",
    "print(\"document_word_frequency shape is\", document_word_frequency.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 100 docs and 7 classes\n"
     ]
    }
   ],
   "source": [
    "print(f\"there are {len(clean_docs)} docs and {len(label_classes)} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0188</th>\n",
       "      <th>02026</th>\n",
       "      <th>04110</th>\n",
       "      <th>0837</th>\n",
       "      <th>0988</th>\n",
       "      <th>0q</th>\n",
       "      <th>0qax</th>\n",
       "      <th>0qq</th>\n",
       "      <th>...</th>\n",
       "      <th>z6e1</th>\n",
       "      <th>z6e1t</th>\n",
       "      <th>z6ei</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zeh</th>\n",
       "      <th>zip</th>\n",
       "      <th>zirconium</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoomed</th>\n",
       "      <th>__labels__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5551 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0188  02026  04110  0837  0988  0q  0qax  0qq  ...  z6e1  z6e1t  \\\n",
       "0   0    0     0      0      0     0     0   0     0    0  ...     0      0   \n",
       "1   0    0     0      0      0     0     0   0     0    0  ...     0      0   \n",
       "2   0    0     0      0      0     0     0   0     0    0  ...     0      0   \n",
       "3   0    0     0      0      0     0     0   0     0    0  ...     0      0   \n",
       "4   0    0     0      0      0     0     0   0     0    0  ...     0      0   \n",
       "\n",
       "   z6ei  zealand  zeh  zip  zirconium  zone  zoomed  __labels__  \n",
       "0     0        0    0    0          0     0       0           6  \n",
       "1     0        0    0    0          0     0       0           0  \n",
       "2     0        0    0    0          0     0       0           6  \n",
       "3     0        0    1    0          0     0       0           6  \n",
       "4     0        0    0    0          0     0       0           1  \n",
       "\n",
       "[5 rows x 5551 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_word_frequency.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0188</th>\n",
       "      <th>02026</th>\n",
       "      <th>04110</th>\n",
       "      <th>0837</th>\n",
       "      <th>0988</th>\n",
       "      <th>0q</th>\n",
       "      <th>0qax</th>\n",
       "      <th>0qq</th>\n",
       "      <th>...</th>\n",
       "      <th>z6e1</th>\n",
       "      <th>z6e1t</th>\n",
       "      <th>z6ei</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zeh</th>\n",
       "      <th>zip</th>\n",
       "      <th>zirconium</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoomed</th>\n",
       "      <th>__labels__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5551 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0188  02026  04110  0837  0988  0q  0qax  0qq  ...  z6e1  z6e1t  \\\n",
       "0   0    0     0      0      0     0     0   0     0    0  ...     0      0   \n",
       "1   0    0     0      0      0     0     0   0     0    0  ...     0      0   \n",
       "2   0    0     0      0      0     0     0   0     0    0  ...     0      0   \n",
       "3   0    0     0      0      0     0     0   0     0    0  ...     0      0   \n",
       "4   0    0     0      0      0     0     0   0     0    0  ...     0      0   \n",
       "\n",
       "   z6ei  zealand  zeh  zip  zirconium  zone  zoomed  __labels__  \n",
       "0     0        0    0    0          0     0       0           6  \n",
       "1     0        0    0    0          0     0       0           0  \n",
       "2     0        0    0    0          0     0       0           6  \n",
       "3     0        0    1    0          0     0       0           6  \n",
       "4     0        0    0    0          0     0       0           1  \n",
       "\n",
       "[5 rows x 5551 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_word_binary_frequency.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Binary Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#reduce freq in doc to bin value of 1 or 0\n",
    "word_doc_binary_freqency = document_word_binary_frequency.drop([\"__labels__\"], axis='columns')\n",
    "\n",
    "#the sum vertically of bin freq\n",
    "word_doc_frequency = word_doc_binary_freqency.sum(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic and word corelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_word_distr has shape (5550, 7)\n"
     ]
    }
   ],
   "source": [
    "topic_word_distr = pd.DataFrame(data=0.0, columns=label_classes, index=words)\n",
    "\n",
    "for topic, label in enumerate(label_classes):\n",
    "    word_topic_frequency = word_doc_binary_freqency[document_word_frequency['__labels__'] == topic].sum(0)\n",
    "    trust_factor = sigmoid(word_doc_frequency)\n",
    "    \n",
    "    topic_word_distr[label] = ((word_topic_frequency * trust_factor) / word_doc_frequency).fillna(0)\n",
    "    \n",
    "print(f\"topic_word_distr has shape {topic_word_distr.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>talk</th>\n",
       "      <th>sci</th>\n",
       "      <th>alt</th>\n",
       "      <th>rec</th>\n",
       "      <th>soc</th>\n",
       "      <th>misc</th>\n",
       "      <th>comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>0.440399</td>\n",
       "      <td>0.440399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0188</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.731059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02026</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.731059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04110</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           talk       sci  alt  rec  soc  misc  comp\n",
       "00     0.000000  0.000000  0.0  0.0  0.0   0.0   0.0\n",
       "000    0.440399  0.440399  0.0  0.0  0.0   0.0   0.0\n",
       "0188   0.000000  0.731059  0.0  0.0  0.0   0.0   0.0\n",
       "02026  0.000000  0.731059  0.0  0.0  0.0   0.0   0.0\n",
       "04110  0.000000  0.000000  0.0  0.0  0.0   0.0   0.0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word_distr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['talk', 'sci', 'alt', 'rec', 'soc', 'misc', 'comp']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "windows    0.997527\n",
       "problem    0.997527\n",
       "bit        0.982014\n",
       "advance    0.982014\n",
       "change     0.982014\n",
       "             ...   \n",
       "around     0.111097\n",
       "here       0.099995\n",
       "most       0.083333\n",
       "we         0.083333\n",
       "just       0.083333\n",
       "Name: comp, Length: 1365, dtype: float64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_class = 'comp'\n",
    "topic_word_distr[label_class][topic_word_distr[label_class] > 0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "talk    0.090909\n",
       "sci     0.272727\n",
       "alt     0.054545\n",
       "rec     0.145455\n",
       "soc     0.036364\n",
       "misc    0.054545\n",
       "comp    0.345455\n",
       "Name: the, dtype: float64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word_distr.loc[\"the\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word word corelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5de21913765040d1a7bd60b1f0785d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5550.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "word_word_distr has shape (5550, 5550)\n"
     ]
    }
   ],
   "source": [
    "word_word_distr = pd.DataFrame(data=0.0, columns=words, index=words)\n",
    "\n",
    "for word in tqdm(words):\n",
    "    word_word_frequency = word_doc_binary_freqency[word_doc_binary_freqency[word] > 0].sum(0)\n",
    "    trust_factor = sigmoid(word_doc_frequency)\n",
    "\n",
    "    word_word_co = ((word_word_frequency * trust_factor) / word_doc_frequency).fillna(0)\n",
    "    word_word_distr[word][word_word_co > word_word_distr[word]] = word_word_co[word_word_co > word_word_distr[word]]\n",
    "\n",
    "word_word_distr = word_word_distr.T\n",
    "print(\"word_word_distr has shape\", word_word_distr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0188</th>\n",
       "      <th>02026</th>\n",
       "      <th>04110</th>\n",
       "      <th>0837</th>\n",
       "      <th>0988</th>\n",
       "      <th>0q</th>\n",
       "      <th>0qax</th>\n",
       "      <th>0qq</th>\n",
       "      <th>...</th>\n",
       "      <th>z5</th>\n",
       "      <th>z6e1</th>\n",
       "      <th>z6e1t</th>\n",
       "      <th>z6ei</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zeh</th>\n",
       "      <th>zip</th>\n",
       "      <th>zirconium</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoomed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.880797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0188</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.731059</td>\n",
       "      <td>0.731059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.731059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.440399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02026</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.731059</td>\n",
       "      <td>0.731059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.731059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.440399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04110</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5550 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        00       000      0188     02026  04110      0837  0988   0q  0qax  \\\n",
       "00     0.0  0.000000  0.000000  0.000000    0.0  0.000000   0.0  0.0   0.0   \n",
       "000    0.0  0.880797  0.000000  0.000000    0.0  0.000000   0.0  0.0   0.0   \n",
       "0188   0.0  0.000000  0.731059  0.731059    0.0  0.731059   0.0  0.0   0.0   \n",
       "02026  0.0  0.000000  0.731059  0.731059    0.0  0.731059   0.0  0.0   0.0   \n",
       "04110  0.0  0.000000  0.000000  0.000000    0.0  0.000000   0.0  0.0   0.0   \n",
       "\n",
       "       0qq  ...   z5  z6e1  z6e1t  z6ei  zealand  zeh       zip  zirconium  \\\n",
       "00     0.0  ...  0.0   0.0    0.0   0.0      0.0  0.0  0.000000        0.0   \n",
       "000    0.0  ...  0.0   0.0    0.0   0.0      0.0  0.0  0.000000        0.0   \n",
       "0188   0.0  ...  0.0   0.0    0.0   0.0      0.0  0.0  0.440399        0.0   \n",
       "02026  0.0  ...  0.0   0.0    0.0   0.0      0.0  0.0  0.440399        0.0   \n",
       "04110  0.0  ...  0.0   0.0    0.0   0.0      0.0  0.0  0.000000        0.0   \n",
       "\n",
       "       zone  zoomed  \n",
       "00      0.0     0.0  \n",
       "000     0.0     0.0  \n",
       "0188    0.0     0.0  \n",
       "02026   0.0     0.0  \n",
       "04110   0.0     0.0  \n",
       "\n",
       "[5 rows x 5550 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_word_distr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "of              0.952574\n",
       "computer        0.952574\n",
       "machine         0.952574\n",
       "for             0.952574\n",
       "am              0.952574\n",
       "an              0.952574\n",
       "and             0.952574\n",
       "to              0.952574\n",
       "one             0.952574\n",
       "be              0.952574\n",
       "in              0.952574\n",
       "the             0.952574\n",
       "out             0.952574\n",
       "have            0.635049\n",
       "if              0.635049\n",
       "is              0.635049\n",
       "functions       0.635049\n",
       "it              0.635049\n",
       "just            0.635049\n",
       "has             0.635049\n",
       "fast            0.635049\n",
       "from            0.635049\n",
       "first           0.635049\n",
       "much            0.635049\n",
       "by              0.635049\n",
       "but             0.635049\n",
       "at              0.635049\n",
       "as              0.635049\n",
       "any             0.635049\n",
       "also            0.635049\n",
       "all             0.635049\n",
       "might           0.635049\n",
       "you             0.635049\n",
       "not             0.635049\n",
       "substitution    0.635049\n",
       "with            0.635049\n",
       "which           0.635049\n",
       "well            0.635049\n",
       "was             0.635049\n",
       "up              0.635049\n",
       "time            0.635049\n",
       "this            0.635049\n",
       "they            0.635049\n",
       "these           0.635049\n",
       "there           0.635049\n",
       "such            0.635049\n",
       "store           0.635049\n",
       "would           0.635049\n",
       "so              0.635049\n",
       "series          0.635049\n",
       "seen            0.635049\n",
       "saw             0.635049\n",
       "price           0.635049\n",
       "own             0.635049\n",
       "over            0.635049\n",
       "other           0.635049\n",
       "ordered         0.635049\n",
       "or              0.635049\n",
       "on              0.635049\n",
       "610             0.635049\n",
       "Name: computer, dtype: float64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"computer\"\n",
    "word_word_distr[word][word_word_distr[word] > .5].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a193fc701d764257b47650cc8fb8ddcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19476.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "re_topic_word_distr has shape (19476, 7)\n"
     ]
    }
   ],
   "source": [
    "re_topic_word_distr = topic_word_distr.copy()\n",
    "\n",
    "for word in tqdm(words):\n",
    "    word_word_co = word_word_distr[word]\n",
    "    \n",
    "    for label_class in label_classes:\n",
    "        infered_ratio = (word_word_co * topic_word_distr[label_class]).max()\n",
    "        \n",
    "        if infered_ratio > re_topic_word_distr[label_class][word]:\n",
    "            re_topic_word_distr[label_class][word] = infered_ratio\n",
    "            \n",
    "print(\"re_topic_word_distr has shape\", re_topic_word_distr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sci</th>\n",
       "      <th>soc</th>\n",
       "      <th>misc</th>\n",
       "      <th>rec</th>\n",
       "      <th>alt</th>\n",
       "      <th>comp</th>\n",
       "      <th>talk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>0.217247</td>\n",
       "      <td>0.190412</td>\n",
       "      <td>0.124958</td>\n",
       "      <td>0.187437</td>\n",
       "      <td>0.055031</td>\n",
       "      <td>0.227176</td>\n",
       "      <td>0.374874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>0.215250</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.049983</td>\n",
       "      <td>0.245361</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00000000</th>\n",
       "      <td>0.731059</td>\n",
       "      <td>0.321957</td>\n",
       "      <td>0.290466</td>\n",
       "      <td>0.364625</td>\n",
       "      <td>0.145233</td>\n",
       "      <td>0.548291</td>\n",
       "      <td>0.521709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00000000b</th>\n",
       "      <td>0.731059</td>\n",
       "      <td>0.321957</td>\n",
       "      <td>0.290466</td>\n",
       "      <td>0.364625</td>\n",
       "      <td>0.145233</td>\n",
       "      <td>0.548291</td>\n",
       "      <td>0.521709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                sci       soc      misc       rec       alt      comp  \\\n",
       "00         0.217247  0.190412  0.124958  0.187437  0.055031  0.227176   \n",
       "000        0.215250  0.088889  0.066667  0.266667  0.049983  0.245361   \n",
       "0000       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "00000000   0.731059  0.321957  0.290466  0.364625  0.145233  0.548291   \n",
       "00000000b  0.731059  0.321957  0.290466  0.364625  0.145233  0.548291   \n",
       "\n",
       "               talk  \n",
       "00         0.374874  \n",
       "000        0.466667  \n",
       "0000       0.000000  \n",
       "00000000   0.521709  \n",
       "00000000b  0.521709  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_topic_word_distr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rec     0.491007\n",
       "sci     0.491007\n",
       "comp    0.342217\n",
       "talk    0.263982\n",
       "soc     0.130424\n",
       "alt     0.108119\n",
       "misc    0.092064\n",
       "Name: companies, dtype: float64"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"companies\"\n",
    "re_topic_word_distr.loc[word].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(f\"{word} against TOPICS\")\n",
    "plt.bar(re_topic_word_distr.loc[word].index, re_topic_word_distr.loc[word])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Topic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc0de7e64b554fcb9cf22c2759e5f85e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=670.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> test-accuracy is 93.13% and re is 93.13%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score1 = score2 = 0\n",
    "print(\"Evaluating Topic Model...\")\n",
    "for doc_index in tqdm(range(len(train_labels))):\n",
    "    doc_vector = train_doc_vectors[doc_index]\n",
    "    \n",
    "    doc_topic_word_distr, doc_topic = infer_topic(doc_vector, topic_word_distr)\n",
    "    score1 += int(doc_topic == label_classes[train_labels[doc_index]])\n",
    "    \n",
    "    doc_topic_word_distr, doc_topic = infer_topic(doc_vector, re_topic_word_distr)\n",
    "    score2 += int(doc_topic == label_classes[train_labels[doc_index]])\n",
    "    \n",
    "    if score1:\n",
    "        continue\n",
    "    \n",
    "#     print(clean_docs[len(train_labels)+doc_index])\n",
    "#     print(\"{:8s} {:16s} {:6s}\".format(\"topic\", \"word\", \"relation\"))\n",
    "#     print(\"=\"*40)\n",
    "#     for label, word in doc_topic_word_distr.idxmax().items():\n",
    "#         print(\"{:8s} {:16s} {:.4f}\".format(label, word, doc_topic_word_distr[label][word]))\n",
    "\n",
    "#     print(f\"\\nthe topic predicted is ==> '{np.max(doc_topic_word_distr).idxmax()}'\")\n",
    "#     print(f\"the actual topic is ==> '{label_classes[labels[doc_index]]}'\")\n",
    "\n",
    "accuracy1 = score1 / (doc_index + 1)\n",
    "accuracy2 = score2 / (doc_index + 1)\n",
    "print(f\"==> train-accuracy is {accuracy1*100:.2f}% and re is {accuracy2*100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Topic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Topic Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ec438a11c134a9b85051aadb5fda51c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=330.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> test-accuracy is 61.21% and re is 61.52%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score1 = score2 = 0\n",
    "print(\"Evaluating Topic Model...\")\n",
    "for doc_index in tqdm(range(len(test_labels))):\n",
    "    doc_vector = test_doc_vectors[doc_index]\n",
    "    \n",
    "    doc_topic_word_distr, doc_topic = infer_topic(doc_vector, topic_word_distr)\n",
    "    score1 += int(doc_topic == label_classes[test_labels[doc_index]])\n",
    "    \n",
    "    doc_topic_word_distr, doc_topic = infer_topic(doc_vector, re_topic_word_distr)\n",
    "    score2 += int(doc_topic == label_classes[test_labels[doc_index]])\n",
    "    \n",
    "    if score1:\n",
    "        continue\n",
    "    \n",
    "#     print(clean_docs[len(train_labels)+doc_index])\n",
    "#     print(\"{:8s} {:16s} {:6s}\".format(\"topic\", \"word\", \"relation\"))\n",
    "#     print(\"=\"*40)\n",
    "#     for label, word in doc_topic_word_distr.idxmax().items():\n",
    "#         print(\"{:8s} {:16s} {:.4f}\".format(label, word, doc_topic_word_distr[label][word]))\n",
    "\n",
    "#     print(f\"\\nthe topic predicted is ==> '{np.max(doc_topic_word_distr).idxmax()}'\")\n",
    "#     print(f\"the actual topic is ==> '{label_classes[labels[doc_index]]}'\")\n",
    "\n",
    "accuracy1 = score1 / (doc_index + 1)\n",
    "accuracy2 = score2 / (doc_index + 1)\n",
    "print(f\"==> test-accuracy is {accuracy1*100:.2f}% and re is {accuracy2*100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sci', 'soc', 'misc', 'rec', 'alt', 'comp', 'talk']"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\christian\\documents\\christian\\work\\python\\cyberspace\\semantic_segmentation\\venv\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670 training data\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = np.nan_to_num(train_doc_vectors / train_doc_vectors.sum(0))\n",
    "y = train_labels\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X, y)\n",
    "\n",
    "print(len(X), \"training data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9477611940298507"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\christian\\documents\\christian\\work\\python\\cyberspace\\semantic_segmentation\\venv\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5303030303030303"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX = np.nan_to_num(test_doc_vectors / test_doc_vectors.sum(0))#[test_labels == 2]\n",
    "yy = test_labels#[test_labels == 2]\n",
    "\n",
    "clf.score(XX, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330, 330)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels), len(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\christian\\documents\\christian\\work\\python\\cyberspace\\semantic_segmentation\\venv\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "224df9fa0cc5450da72d7e5091cacf21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19476.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = np.nan_to_num(train_doc_vectors / train_doc_vectors.sum(0))\n",
    "y = train_labels\n",
    "\n",
    "models = []\n",
    "for index in tqdm(range(len(count_vectorizer.get_feature_names()))):\n",
    "    clf = LogisticRegression(random_state=0).fit(X[:, index:index+1], y)\n",
    "    models.append(clf)\n",
    "    \n",
    "#     print(\"training score\", clf.score(X[:, index:index+1], y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\christian\\documents\\christian\\work\\python\\cyberspace\\semantic_segmentation\\venv\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "135ff0c05911459db0e5731f62fda925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19476.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5151515151515151"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX = np.nan_to_num(test_doc_vectors / test_doc_vectors.sum(0))\n",
    "yy = test_labels\n",
    "\n",
    "p = np.zeros((len(XX[:, 0]), 7))\n",
    "\n",
    "for index in tqdm(range(len(count_vectorizer.get_feature_names()))):\n",
    "    clf = models[index]\n",
    "    prob = clf.predict_proba(XX[:, index:index+1])\n",
    "    p[prob > p] = prob[prob > p]\n",
    "\n",
    "(p.argmax(1) == yy).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24242424242424243"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QfWTxubYcMxR"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zS4cUkmGcMxd"
   },
   "source": [
    "### imports and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "qOriDeG8cMxl",
    "outputId": "a4b003fc-c8fb-4937-e900-b5807b0d6d53"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\christian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\christian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\christian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3liQaMKccMxs"
   },
   "outputs": [],
   "source": [
    "# from std lib\n",
    "import re, string\n",
    "from collections import Counter\n",
    "\n",
    "# from thrid party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.special import softmax\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import entropy as calculate_entropy\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word, use_pos):\n",
    "    if not use_pos:\n",
    "        return 'n'\n",
    "\n",
    "    tag = pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ, \"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"r\":wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "# clean out the new line characters from text in docs\n",
    "def clean_doc(doc, use_pos=False):\n",
    "    ''' remove unwanter characters line new line '''\n",
    "\n",
    "    unwanted_chrs = list(string.punctuation)\n",
    "    # unwanted_chrs = [')', '(', '{', '}', '\\t', '\\n', '\\r', \"'\", '\"', \"!\", \",\", \".\", \"?\", \">\", \"<\", \"[\", \"]\"]\n",
    "\n",
    "    doc = doc.lower()\n",
    "    for unwanted_chr in unwanted_chrs:\n",
    "        doc = doc.replace(unwanted_chr, ' ')\n",
    "\n",
    "    doc = word_tokenize(doc)\n",
    "\n",
    "    word_count = len(doc)\n",
    "    doc = \" \".join([wordnet_lemmatizer.lemmatize(word, get_wordnet_pos(word, use_pos)) for word in doc])\n",
    "\n",
    "    status = (len(doc) != 0 and not doc.isspace())\n",
    "\n",
    "    return status, doc, word_count\n",
    "\n",
    "def calculate_sparsity(matrix):\n",
    "    non_zero = np.count_nonzero(matrix)\n",
    "    total_val = np.product(matrix.shape)\n",
    "    sparsity = (total_val - non_zero) / total_val\n",
    "    return sparsity\n",
    "\n",
    "def calculate_word_inference_weight(word_word_pr_distr):\n",
    "    entropy_values = calculate_entropy(word_word_pr_distr, axis=0)\n",
    "    entropy_values_norm = (entropy_values.max() - entropy_values) / entropy_values.max()\n",
    "    entropy_values_norm = pd.DataFrame(data=entropy_values_norm, index=word_word_pr_distr.columns)[0]\n",
    "    return entropy_values_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gQtq2JhkcMxz"
   },
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "vR1db5rUcMx0",
    "outputId": "8498f3d2-9ac1-4952-8ad6-85b2c076f94a"
   },
   "outputs": [],
   "source": [
    "dataset = \"newsgroup\"\n",
    "\n",
    "# total number of samples needed\n",
    "randomize = False\n",
    "\n",
    "# retrieve dataset\n",
    "categories = ['rec.autos', 'talk.politics.mideast', 'alt.atheism', 'sci.space']\n",
    "\n",
    "all_docs = fetch_20newsgroups(subset='train', shuffle=randomize, remove=('headers', 'footers', 'quotes'), categories=categories)\n",
    "all_docs, old_labels, categories = all_docs.data, all_docs.target, all_docs.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xd-imY-icMx8"
   },
   "outputs": [],
   "source": [
    "# dataset = \"bbc\"\n",
    "\n",
    "# data = pd.read_csv('bbcsport.csv')\n",
    "\n",
    "# all_docs = data[\"text\"].to_list()\n",
    "# old_labels = data[\"topic\"].to_list()\n",
    "# categories = classes = np.unique(data[\"topic\"]).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WYe4XYDfcMyI"
   },
   "source": [
    "### clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "b8ee6c0914474dab8186285123c3c25a",
      "1029c3cb5c264802a7bd45639c1a7c20",
      "94d411d6977f493894ec3c8b5975f693",
      "846b5c7701bc49e4be2a7681d5361dd8",
      "2e8643a34a7143e284ed8e94aaca32d7",
      "b8ce72deb0c34c35a99b91bbc9b5504c",
      "cee50571766e465b81cd2d06ac0a4d31",
      "5c20409065a347d18e1ab6bde4c5a0ba"
     ]
    },
    "colab_type": "code",
    "id": "RgG4w-qpcMyJ",
    "outputId": "142478ec-50d6-4c3a-f6fb-db0ee38fcb1a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76123eb2e3d494e848f5c7e5eae369d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=160.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "datasize = 40\n",
    "min_document_length = 160\n",
    "max_document_length = 256\n",
    "\n",
    "\n",
    "index = -1\n",
    "docs, labels, label_indices = [], [], []\n",
    "\n",
    "sizes = [0]*len(categories)\n",
    "\n",
    "with tqdm(total=len(categories)*datasize) as pbar:\n",
    "    while sum(sizes) < len(categories)*datasize:\n",
    "        index += 1\n",
    "        label_index = old_labels[index]\n",
    "            \n",
    "        if sizes[label_index] == datasize:\n",
    "            continue\n",
    "        \n",
    "        doc = all_docs[index]\n",
    "        status, doc, word_count = clean_doc(doc, True)\n",
    "        \n",
    "        if not status:\n",
    "            continue\n",
    "            \n",
    "        if min_document_length is not None and len(doc) < min_document_length:\n",
    "            continue\n",
    "            \n",
    "        if max_document_length is not None and len(doc) > max_document_length:\n",
    "            continue\n",
    "        \n",
    "        label_indices.append(label_index)\n",
    "        labels.append(categories[label_index])\n",
    "        \n",
    "        docs.append(doc)\n",
    "        sizes[label_index] += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "labels = np.array(labels)\n",
    "label_indices = np.array(label_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "_eBXjBUecMyU",
    "outputId": "12f081a4-fab6-4de7-f36f-62399abaa5b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: rec.autos\n",
      "==================================================\n",
      "not to mention my friend s 54 citroen traction avant with the light switch and dimmer integrate in a single stalk off the steer column those dumb french be apparently copying the japanese before the german\n"
     ]
    }
   ],
   "source": [
    "doc_index = 3\n",
    "print(f\"Topic: {labels[doc_index]}\\n{'='*50}\\n{docs[doc_index][:512]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KS5PW7qHcMyb",
    "outputId": "d83a2010-8955-4c8f-f2d6-be15ecad2198",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, 40, 40, 40]\n"
     ]
    }
   ],
   "source": [
    "print(sizes)\n",
    "assert min(sizes) == max(sizes) == datasize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(docs, labels, test_size =.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "s8R3CeUBcMyg",
    "outputId": "adcba1c9-85ae-428d-ff5f-ba33bd7beef8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 160 total docs, 112 train and 48 test\n"
     ]
    }
   ],
   "source": [
    "print(f\"there are {len(docs)} total docs, {len(y_train)} train and {len(y_test)} test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-OUac83RcMyl"
   },
   "source": [
    "### Initialize Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZCBHEIyEcMyn",
    "outputId": "18cbf825-2576-4937-908b-ce0cc5a29150"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_count is 1483\n"
     ]
    }
   ],
   "source": [
    "vectorizer_type = \"not-tfidf\"\n",
    "\n",
    "# initialize the count vectorizer\n",
    "if vectorizer_type == \"tfidf\":\n",
    "    vectorizer = TfidfVectorizer\n",
    "else:\n",
    "    vectorizer = CountVectorizer()\n",
    "\n",
    "# fit it to dataset\n",
    "vectorizer.fit(x_train)\n",
    "\n",
    "vocabulary = np.array(vectorizer.get_feature_names())\n",
    "print(\"word_count is\", len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UKomwY7acMyz"
   },
   "source": [
    "### Prepare Datatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IIYeZA4EcMy0",
    "outputId": "da04274f-82f4-49a5-8be6-d1c9230aa835"
   },
   "outputs": [],
   "source": [
    "# create doc count vectors\n",
    "train_doc_vectors = vectorizer.transform(x_train).toarray()\n",
    "test_doc_vectors = vectorizer.transform(x_test).toarray()\n",
    "\n",
    "wdf_train = pd.DataFrame(train_doc_vectors, columns=vocabulary)\n",
    "wdf_test = pd.DataFrame(test_doc_vectors, columns=vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>031349</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>16th</th>\n",
       "      <th>1900</th>\n",
       "      <th>1940</th>\n",
       "      <th>1968</th>\n",
       "      <th>1982</th>\n",
       "      <th>1984</th>\n",
       "      <th>...</th>\n",
       "      <th>ya</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yo</th>\n",
       "      <th>yorker</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>zeuge</th>\n",
       "      <th>zuma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1483 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  031349  10  11  16th  1900  1940  1968  1982  1984  ...  ya  yeah  \\\n",
       "0    0       0   0   0     0     0     0     0     0     0  ...   0     0   \n",
       "1    0       0   0   0     0     0     0     0     0     0  ...   0     0   \n",
       "2    0       0   0   0     0     0     0     0     0     0  ...   0     0   \n",
       "3    0       0   0   0     0     0     0     0     0     0  ...   0     0   \n",
       "4    0       0   0   0     0     0     0     0     0     0  ...   0     0   \n",
       "\n",
       "   year  yes  yo  yorker  you  your  zeuge  zuma  \n",
       "0     0    0   0       0    6     0      0     0  \n",
       "1     0    0   0       0    1     3      0     0  \n",
       "2     0    0   0       0    1     1      0     0  \n",
       "3     0    0   0       0    0     0      0     0  \n",
       "4     0    0   0       0    2     0      0     0  \n",
       "\n",
       "[5 rows x 1483 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wdf_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_word_doc_freq matrix sparsity = 0.9790\n"
     ]
    }
   ],
   "source": [
    "print(f\"train_word_doc_freq matrix sparsity = {calculate_sparsity(wdf_train):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Word Co-Occurence Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6685fcc0b24bc8a08279b58aea1562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1483.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "word_word_pr_distr shape = (1483, 1483)\n"
     ]
    }
   ],
   "source": [
    "alpha = 0\n",
    "wdf_train_prime = wdf_train.copy()\n",
    "\n",
    "wdt_train = wdf_train_prime.copy()\n",
    "wdt_train[\"__labels__\"] = y_train\n",
    "\n",
    "word_doc_count = wdf_train_prime.sum(0)\n",
    "word_word_pr_distr = pd.DataFrame(data=0.0, columns=vocabulary, index=vocabulary)\n",
    "\n",
    "for word in tqdm(vocabulary):\n",
    "    pxy = (wdf_train_prime[wdf_train_prime[word] > 0].sum(0) + alpha) / (word_doc_count[word] + alpha)\n",
    "    word_word_pr_distr[word] = pxy * (word_doc_count[word] / word_doc_count)\n",
    "\n",
    "print(f\"word_word_pr_distr shape = {word_word_pr_distr.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>031349</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>16th</th>\n",
       "      <th>1900</th>\n",
       "      <th>1940</th>\n",
       "      <th>1968</th>\n",
       "      <th>1982</th>\n",
       "      <th>1984</th>\n",
       "      <th>...</th>\n",
       "      <th>ya</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yo</th>\n",
       "      <th>yorker</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>zeuge</th>\n",
       "      <th>zuma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>031349</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16th</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1483 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        000  031349   10   11  16th  1900  1940  1968  1982  1984  ...   ya  \\\n",
       "000     1.0     0.0  0.5  0.0   0.0   0.0   0.0   0.0   0.0   0.5  ...  0.0   \n",
       "031349  0.0     1.0  0.0  0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...  0.0   \n",
       "10      1.0     0.0  1.0  0.0   0.0   0.0   0.0   0.0   0.0   1.0  ...  0.0   \n",
       "11      0.0     0.0  0.0  1.0   0.0   0.0   0.0   0.0   0.0   0.0  ...  0.0   \n",
       "16th    0.0     0.0  0.0  0.0   1.0   0.0   0.0   0.0   0.0   0.0  ...  0.0   \n",
       "\n",
       "        yeah  year  yes   yo  yorker  you  your  zeuge  zuma  \n",
       "000      0.0   0.0  0.0  0.0     0.0  0.5   0.5    0.0   0.0  \n",
       "031349   0.0   0.0  0.0  0.0     0.0  1.0   1.0    0.0   0.0  \n",
       "10       0.0   0.0  0.0  0.0     0.0  1.0   1.0    0.0   0.0  \n",
       "11       0.0   0.0  0.0  0.0     0.0  0.0   0.0    0.0   0.0  \n",
       "16th     0.0   0.0  0.0  0.0     0.0  0.0   0.0    0.0   0.0  \n",
       "\n",
       "[5 rows x 1483 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_word_pr_distr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_word_pr_distr matrix sparsity = 0.9603\n"
     ]
    }
   ],
   "source": [
    "print(f\"word_word_pr_distr matrix sparsity = {calculate_sparsity(word_word_pr_distr):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"space\"\n",
    "given_word = \"science\"\n",
    "word_word_pr_distr[word][given_word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Word Co-Occurence Prime Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_iterations = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x, pbar, word_word_pr_distr_prime):\n",
    "    pbar.update(1)\n",
    "    return word_word_pr_distr_prime.apply(lambda y: x*y, axis=0).max(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94e3109594624ee6ba503ac7346fe0f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4449.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "word_word_pr_distr_prime shape = (1483, 1483)\n"
     ]
    }
   ],
   "source": [
    "# word_word_pr_distr_prime = word_word_pr_distr.copy()\n",
    "# with tqdm(total=len(vocabulary)*num_of_iterations) as pbar:\n",
    "#     for _ in range(num_of_iterations):\n",
    "#         word_word_pr_distr_prime = word_word_pr_distr_prime.apply(func, axis=1, args=(pbar, word_word_pr_distr_prime))\n",
    "\n",
    "# print(f\"word_word_pr_distr_prime shape = {word_word_pr_distr_prime.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>031349</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>16th</th>\n",
       "      <th>1900</th>\n",
       "      <th>1940</th>\n",
       "      <th>1968</th>\n",
       "      <th>1982</th>\n",
       "      <th>1984</th>\n",
       "      <th>...</th>\n",
       "      <th>ya</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yo</th>\n",
       "      <th>yorker</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>zeuge</th>\n",
       "      <th>zuma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>031349</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.431472</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16th</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1483 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             000    031349        10        11      16th      1900      1940  \\\n",
       "000     1.000000  0.125000  0.500000  0.071429  0.071429  0.107143  0.071429   \n",
       "031349  0.125000  1.000000  0.083333  0.166667  0.142857  0.166667  0.200000   \n",
       "10      1.000000  0.166667  1.000000  0.083333  0.125000  0.115385  0.083333   \n",
       "11      0.062500  0.075000  0.042857  1.000000  0.250000  0.250000  0.100000   \n",
       "16th    0.166667  0.166667  0.142857  0.500000  1.000000  0.250000  0.166667   \n",
       "\n",
       "            1968      1982      1984  ...        ya      yeah      year  \\\n",
       "000     0.100000  0.125000  0.500000  ...  0.125000  0.062500  0.107143   \n",
       "031349  0.125000  0.083333  0.100000  ...  0.083333  0.071429  0.166667   \n",
       "10      0.200000  0.166667  1.000000  ...  0.166667  0.076923  0.125000   \n",
       "11      0.062500  0.055556  0.055556  ...  0.125000  0.125000  0.250000   \n",
       "16th    0.166667  0.125000  0.166667  ...  0.333333  0.125000  0.250000   \n",
       "\n",
       "             yes        yo    yorker       you      your     zeuge      zuma  \n",
       "000     0.125000  0.250000  0.050000  0.500000  0.500000  0.050000  0.062500  \n",
       "031349  0.142857  0.166667  0.142857  1.000000  1.000000  0.041667  0.100000  \n",
       "10      0.166667  0.500000  0.083333  1.000000  1.000000  0.100000  0.083333  \n",
       "11      0.107143  0.125000  0.083333  0.431472  0.250000  0.083333  0.125000  \n",
       "16th    0.333333  0.428571  0.214286  0.666667  0.466667  0.166667  0.133333  \n",
       "\n",
       "[5 rows x 1483 columns]"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_word_pr_distr_prime.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified word word pr distr properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           | sparsity | mean   | std\n",
      "-----------------------------------------------------------------------\n",
      "word_word_pr_distr matrix sparsity         | 0.9603   | 0.0215 | 0.0215\n",
      "word_word_pr_distr_prime matrix sparsity   | 0.0000   | 0.1748 | 0.1748\n"
     ]
    }
   ],
   "source": [
    "wwds = calculate_sparsity(word_word_pr_distr)\n",
    "wwdm = word_word_pr_distr.mean().mean()\n",
    "wwdstd = word_word_pr_distr.mean().mean()\n",
    "\n",
    "wwdps = calculate_sparsity(word_word_pr_distr_prime)\n",
    "wwdpm = word_word_pr_distr_prime.mean().mean()\n",
    "wwdpstd = word_word_pr_distr_prime.mean().mean()\n",
    "\n",
    "print(\"                                           | sparsity | mean   | std\")\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "print(f\"word_word_pr_distr matrix sparsity         | {wwds:.4f}   | {wwdm:.4f} | {wwdstd:.4f}\")\n",
    "print(f\"word_word_pr_distr_prime matrix sparsity   | {wwdps:.4f}   | {wwdpm:.4f} | {wwdpstd:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Word Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_inference_weight = calculate_word_inference_weight(word_word_pr_distr)\n",
    "word_inference_weight_prime = calculate_word_inference_weight(word_word_pr_distr_prime)\n",
    "\n",
    "# word_inference_weight.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word             | weight | prime_weight\n",
      "-----------------------------------------------------\n",
      "the              | 0.0000 | 0.0003\n",
      "be               | 0.0038 | 0.0000\n",
      "science          | 0.4704 | 0.0300\n",
      "space            | 0.6439 | 0.0352\n",
      "god              | 0.5162 | 0.0311\n",
      "religion         | 0.4124 | 0.0272\n"
     ]
    }
   ],
   "source": [
    "words = [\"the\", \"be\", \"science\", \"space\", \"god\", \"religion\"]\n",
    "\n",
    "print(f'{\"word\":16s} | {\"weight\":6s} | {\"prime_weight\":6s}')\n",
    "print(\"-----------------------------------------------------\")\n",
    "for w1 in words:\n",
    "    print(f\"{w1:16s} | {word_inference_weight[w1]:.4f} | {word_inference_weight_prime[w1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### word word relation comparison with modified word_word_co matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.16666666666666666)"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"politics\"\n",
    "given_word = \"race\"\n",
    "word_word_pr_distr[word][given_word], word_word_pr_distr_prime[word][given_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: talk.politics.mideast\n",
      "==================================================\n",
      "your ignorance be obvious from your post 1 cyprus be an independent country with turkish greek inhabitant not a greek island like your ignorant post claim 2 the name should be cyprus in english next time read and learn before you post\n",
      "\n",
      "Topic: rec.autos\n",
      "==================================================\n",
      "well the mgb be currently in production for the english market built by rover it now have a v8 improve suspention and a slightly update body too bad it s only available in gb and would set one of u back about 42 000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_index1 = 1\n",
    "doc_index2 = 10\n",
    "\n",
    "doc_indices = [doc_index1, doc_index2]\n",
    "\n",
    "for doc_index in doc_indices[:3]:\n",
    "    print(f\"Topic: {y_train[doc_index]}\\n{'='*50}\\n{x_train[doc_index][:512]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an 000 0.022727272727272728\n",
      "an about 0.1122994652406417\n",
      "an be 0.14120904476234425\n",
      "an the 0.14887406171809842\n",
      "and 000 0.013214146910221531\n",
      "and 42 0.024096385542168676\n",
      "and about 0.09922041105598865\n",
      "and and 1.0\n",
      "be 000 0.023579498935647612\n",
      "be about 0.12433098818182271\n",
      "be and 0.3418751146718855\n",
      "be be 1.0\n",
      "before 000 0.041666666666666664\n",
      "before 42 0.08333333333333333\n",
      "before english 0.16666666666666666\n",
      "claim 000 0.041666666666666664\n",
      "claim 42 0.08333333333333333\n",
      "claim english 0.16666666666666666\n",
      "country 000 0.0625\n",
      "country 42 0.125\n",
      "country english 0.25\n",
      "cyprus 000 0.125\n",
      "cyprus 42 0.25\n",
      "cyprus english 0.5\n",
      "english 000 0.25\n",
      "english 42 0.5\n",
      "english english 1.0\n",
      "from 000 0.009615384615384616\n",
      "from 42 0.019230769230769232\n",
      "from about 0.0407239819004525\n",
      "from and 0.0778498609823911\n",
      "from be 0.1030847325263569\n",
      "from it 0.1054945054945055\n",
      "greek 000 0.08333333333333333\n",
      "greek 42 0.16666666666666666\n",
      "greek english 0.3333333333333333\n",
      "ignorance 000 0.0625\n",
      "ignorance 42 0.125\n",
      "ignorance english 0.25\n",
      "ignorant 000 0.041666666666666664\n",
      "ignorant 42 0.08333333333333333\n",
      "ignorant english 0.16666666666666666\n",
      "in 000 0.04838709677419355\n",
      "in about 0.06461035886072625\n",
      "in and 0.2444617178390983\n",
      "in be 0.41657114786310784\n",
      "in in 1.0\n",
      "independent 000 0.125\n",
      "independent 42 0.25\n",
      "independent english 0.5\n",
      "inhabitant 000 0.125\n",
      "inhabitant 42 0.25\n",
      "inhabitant english 0.5\n",
      "island 000 0.125\n",
      "island 42 0.25\n",
      "island english 0.5\n",
      "learn 000 0.125\n",
      "learn 42 0.25\n",
      "learn english 0.5\n",
      "like 000 0.015\n",
      "like about 0.020437970660025652\n",
      "like and 0.059638554216867486\n",
      "like be 0.09898477157360407\n",
      "like it 0.11999999999999998\n",
      "name 000 0.125\n",
      "name 42 0.25\n",
      "name english 0.5\n",
      "next 000 0.0625\n",
      "next 42 0.125\n",
      "next english 0.25\n",
      "not 000 0.03409090909090909\n",
      "not about 0.04601874110778591\n",
      "not and 0.16374589266155537\n",
      "not be 0.3169127826488233\n",
      "obvious 000 0.041666666666666664\n",
      "obvious 42 0.08333333333333333\n",
      "obvious by 0.10526315789473684\n",
      "obvious english 0.16666666666666666\n",
      "post 000 0.0234375\n",
      "post 42 0.046875\n",
      "post about 0.058823529411764705\n",
      "post and 0.06911821598319884\n",
      "post be 0.0860091743119266\n",
      "post english 0.09375\n",
      "post the 0.12471330275229359\n",
      "read 000 0.03125\n",
      "read 42 0.0625\n",
      "read english 0.125\n",
      "should 000 0.017857142857142856\n",
      "should 42 0.03571428571428571\n",
      "should and 0.060240963855421686\n",
      "should be 0.08715596330275231\n",
      "the 000 0.016840256231563072\n",
      "the about 0.18564490016189966\n",
      "the and 0.46523709516966943\n",
      "the be 0.6697247706422018\n",
      "the the 1.0\n",
      "time 000 0.011363636363636364\n",
      "time 42 0.022727272727272728\n",
      "time and 0.03285870755750274\n",
      "time bad 0.045454545454545456\n",
      "time be 0.06645131518227966\n",
      "turkish 000 0.125\n",
      "turkish 42 0.25\n",
      "turkish english 0.5\n",
      "with 000 0.004821428571428572\n",
      "with 42 0.009642857142857144\n",
      "with about 0.04201680672268907\n",
      "with and 0.10240963855421685\n",
      "with be 0.17131979695431473\n",
      "with the 0.19970511140235914\n",
      "you 000 0.019736842105263157\n",
      "you about 0.057943022694350574\n",
      "you and 0.17786937222574506\n",
      "you be 0.3519903820464868\n",
      "your 000 0.03\n",
      "your about 0.0423529411764706\n",
      "your and 0.10795180722891569\n",
      "your be 0.15431472081218273\n",
      "your in 0.16451612903225804\n"
     ]
    }
   ],
   "source": [
    "ct = Counter()\n",
    "ctp = Counter()\n",
    "\n",
    "for given_word, wfx in wdf_train.iloc[doc_index1][wdf_train.iloc[doc_index1] > 0].items():\n",
    "    if not wfx > 0:\n",
    "        continue\n",
    "        \n",
    "    for word, wfy in wdf_train.iloc[doc_index2][wdf_train.iloc[doc_index2] > 0].items():\n",
    "        xv = word_word_pr_distr[word][given_word] * word_word_pr_distr[given_word][word]# * word_inference_weight[given_word] * word_inference_weight[word]\n",
    "        if xv > ct[given_word]:\n",
    "#             print(given_word, word, xv)\n",
    "            ct[given_word] = xv\n",
    "            \n",
    "        xv = word_word_pr_distr_prime[word][given_word] * word_word_pr_distr_prime[given_word][word]#word_inference_weight_prime[given_word] * word_inference_weight_prime[word]\n",
    "        if xv > ctp[given_word]:\n",
    "            print(given_word, word, xv)\n",
    "            ctp[given_word] = xv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================\n",
      "printing 30 top co occuring words\n",
      "====================================================\n",
      "\n",
      "word             | pr     | pr_prime\n",
      "--------------------------------------------------\n",
      "and              | 1.0000 | 1.0000\n",
      "be               | 1.0000 | 1.0000\n",
      "english          | 1.0000 | 1.0000\n",
      "in               | 1.0000 | 1.0000\n",
      "the              | 1.0000 | 1.0000\n",
      "cyprus           | 0.5000 | 0.5000\n",
      "independent      | 0.5000 | 0.5000\n",
      "inhabitant       | 0.5000 | 0.5000\n",
      "island           | 0.5000 | 0.5000\n",
      "learn            | 0.5000 | 0.5000\n",
      "name             | 0.5000 | 0.5000\n",
      "turkish          | 0.5000 | 0.5000\n",
      "you              | 0.3520 | 0.3520\n",
      "greek            | 0.3333 | 0.3333\n",
      "not              | 0.3169 | 0.3169\n",
      "country          | 0.2500 | 0.2500\n",
      "ignorance        | 0.2500 | 0.2500\n",
      "next             | 0.2500 | 0.2500\n",
      "with             | 0.1997 | 0.1997\n",
      "before           | 0.1667 | 0.1667\n",
      "claim            | 0.1667 | 0.1667\n",
      "ignorant         | 0.1667 | 0.1667\n",
      "obvious          | 0.1667 | 0.1667\n",
      "your             | 0.1645 | 0.1645\n",
      "an               | 0.1489 | 0.1489\n",
      "read             | 0.1250 | 0.1250\n",
      "post             | 0.1247 | 0.1247\n",
      "like             | 0.1200 | 0.1200\n",
      "from             | 0.1055 | 0.1055\n",
      "should           | 0.0827 | 0.0872\n"
     ]
    }
   ],
   "source": [
    "num_of_topwords = 30\n",
    "\n",
    "tw = ct.most_common(num_of_topwords)\n",
    "twp = ctp.most_common(num_of_topwords)\n",
    "\n",
    "num_of_topwords = len(tw)\n",
    "\n",
    "print(\"====================================================\")\n",
    "print(f\"printing {num_of_topwords} top co occuring words\")\n",
    "print(\"====================================================\\n\")\n",
    "\n",
    "print(f'{\"word\":16s} | {\"pr\":6s} | {\"pr_prime\":6s}')\n",
    "print(\"--------------------------------------------------\")\n",
    "\n",
    "for i in range(num_of_topwords):\n",
    "    print(f\"{tw[i][0][:16]:16s} | {tw[i][1]:.4f} | {twp[i][1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doc doc relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: talk.politics.mideast\n",
      "==================================================\n",
      "your ignorance be obvious from your post 1 cyprus be an independent country with turkish greek inhabitant not a greek island like your ignorant post claim 2 the name should be cyprus in english next time read and learn before you post\n",
      "\n"
     ]
    }
   ],
   "source": [
    "given_doc_index = 1\n",
    "print(f\"Topic: {y_train[given_doc_index]}\\n{'='*50}\\n{x_train[given_doc_index][:512]}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65113130816643d2958414b95000bcb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=112.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "doc_doc_pr_distr shape = (112, 31)\n"
     ]
    }
   ],
   "source": [
    "given_doc = wdf_train.iloc[given_doc_index][wdf_train.iloc[given_doc_index] > 0]\n",
    "doc_doc_pr_distr = pd.DataFrame(data=0.0, columns=given_doc.index.tolist(), index=wdf_train.index.tolist())\n",
    "\n",
    "for doc_index in tqdm(range(len(y_train))):\n",
    "    doc = wdf_train.iloc[doc_index][wdf_train.iloc[doc_index] > 0]\n",
    "    \n",
    "    for given_word, wfx in given_doc.items():\n",
    "        doc_doc_pr_distr.iloc[doc_index][given_word] = max(\n",
    "            word_word_pr_distr_prime[word][given_word] * word_word_pr_distr_prime[given_word][word] for word, wfy in doc.items()\n",
    "#             word_word_pr_distr_prime[word][given_word] * word_inference_weight_prime[word] for word, wfy in doc.items()\n",
    "#             word_word_pr_distr_prime[word][given_word] * word_inference_weight_prime[word] * word_inference_weight_prime[given_word] for word, wfy in doc.items()\n",
    "        )\n",
    "        \n",
    "print(f\"doc_doc_pr_distr shape = {doc_doc_pr_distr.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>an</th>\n",
       "      <th>and</th>\n",
       "      <th>be</th>\n",
       "      <th>before</th>\n",
       "      <th>claim</th>\n",
       "      <th>country</th>\n",
       "      <th>cyprus</th>\n",
       "      <th>english</th>\n",
       "      <th>from</th>\n",
       "      <th>greek</th>\n",
       "      <th>...</th>\n",
       "      <th>obvious</th>\n",
       "      <th>post</th>\n",
       "      <th>read</th>\n",
       "      <th>should</th>\n",
       "      <th>the</th>\n",
       "      <th>time</th>\n",
       "      <th>turkish</th>\n",
       "      <th>with</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.465237</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.089286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170455</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.199705</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.141209</td>\n",
       "      <td>0.341875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.048387</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.120445</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055838</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.042453</td>\n",
       "      <td>0.087156</td>\n",
       "      <td>0.669725</td>\n",
       "      <td>0.075359</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.171320</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.148874</td>\n",
       "      <td>0.465237</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.050761</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.103085</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.050459</td>\n",
       "      <td>0.087156</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.35199</td>\n",
       "      <td>0.154315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.178977</td>\n",
       "      <td>0.465237</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.050459</td>\n",
       "      <td>0.089286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.075359</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.199705</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         an       and   be    before     claim   country    cyprus   english  \\\n",
       "0  1.000000  0.465237  1.0  0.111111  1.000000  0.166667  0.333333  0.166667   \n",
       "1  1.000000  1.000000  1.0  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "2  0.141209  0.341875  1.0  0.048387  0.106667  0.060606  0.120000  0.060000   \n",
       "3  0.148874  0.465237  1.0  0.047619  0.050761  0.045455  0.090909  0.045455   \n",
       "4  0.178977  0.465237  1.0  0.166667  0.166667  0.093750  0.187500  0.093750   \n",
       "\n",
       "       from     greek  ...   obvious      post      read    should       the  \\\n",
       "0  1.000000  0.222222  ...  0.111111  1.000000  0.083333  0.089286  1.000000   \n",
       "1  1.000000  1.000000  ...  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "2  0.120445  0.090909  ...  0.055838  0.131579  0.042453  0.087156  0.669725   \n",
       "3  0.103085  0.060606  ...  0.107143  0.150000  0.050459  0.087156  1.000000   \n",
       "4  1.000000  0.125000  ...  0.105263  1.000000  0.050459  0.089286  1.000000   \n",
       "\n",
       "       time   turkish      with      you      your  \n",
       "0  0.170455  0.333333  0.199705  1.00000  0.250000  \n",
       "1  1.000000  1.000000  1.000000  1.00000  1.000000  \n",
       "2  0.075359  0.120000  0.171320  1.00000  1.000000  \n",
       "3  1.000000  0.090909  1.000000  0.35199  0.154315  \n",
       "4  0.075359  0.187500  0.199705  1.00000  0.250000  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_doc_pr_distr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latent_vector, kmeans_inertia =  145.34738323975643\n",
      "Counter({'talk.politics.mideast': 6, 'alt.atheism': 4, 'rec.autos': 4, 'sci.space': 2})\n",
      "Counter({'rec.autos': 28, 'sci.space': 25, 'alt.atheism': 22, 'talk.politics.mideast': 21})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_clusters = 2\n",
    "\n",
    "# cluster the topics\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(doc_doc_pr_distr)\n",
    "print(\"latent_vector, kmeans_inertia = \", kmeans.inertia_)\n",
    "\n",
    "for ii in range(n_clusters):\n",
    "    print(Counter(y_train[kmeans.labels_ == ii]))\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "topsize = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rec.autos', 27),\n",
       " ('talk.politics.mideast', 25),\n",
       " ('alt.atheism', 25),\n",
       " ('sci.space', 23)]"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = kmeans.transform(doc_doc_pr_distr).mean(1).argsort(axis=0)[::-1]\n",
    "indices[:3]\n",
    "\n",
    "Counter(y_train[indices][:topsize]).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rec.autos', 29),\n",
       " ('talk.politics.mideast', 25),\n",
       " ('alt.atheism', 24),\n",
       " ('sci.space', 22)]"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train[doc_doc_pr_distr.mean(1).sort_values(ascending=False).head(topsize).index]).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "topic_modeler.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1029c3cb5c264802a7bd45639c1a7c20": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e8643a34a7143e284ed8e94aaca32d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "44bf4a5432b34d269a82bce24d4e46b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4dcd4b491d694b0aa25514b8486cf3f8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51dd1aa22f7d45ccbd3ba766bb232b57": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5369f73e7d934a68a3478189b5a136b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": " 14%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4dcd4b491d694b0aa25514b8486cf3f8",
      "max": 37408,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_44bf4a5432b34d269a82bce24d4e46b3",
      "value": 5274
     }
    },
    "5c20409065a347d18e1ab6bde4c5a0ba": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "846b5c7701bc49e4be2a7681d5361dd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c20409065a347d18e1ab6bde4c5a0ba",
      "placeholder": "​",
      "style": "IPY_MODEL_cee50571766e465b81cd2d06ac0a4d31",
      "value": " 200/200 [00:52&lt;00:00,  3.85it/s]"
     }
    },
    "94d411d6977f493894ec3c8b5975f693": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b8ce72deb0c34c35a99b91bbc9b5504c",
      "max": 200,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2e8643a34a7143e284ed8e94aaca32d7",
      "value": 200
     }
    },
    "b8ce72deb0c34c35a99b91bbc9b5504c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b8ee6c0914474dab8186285123c3c25a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_94d411d6977f493894ec3c8b5975f693",
       "IPY_MODEL_846b5c7701bc49e4be2a7681d5361dd8"
      ],
      "layout": "IPY_MODEL_1029c3cb5c264802a7bd45639c1a7c20"
     }
    },
    "c3f9b287331c4447a3858c3fed906a66": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5369f73e7d934a68a3478189b5a136b6",
       "IPY_MODEL_f02ad7bad6f74da69de3557e8b7e3b92"
      ],
      "layout": "IPY_MODEL_dc810a1b5ae545a09ef4b77e92695a36"
     }
    },
    "cee50571766e465b81cd2d06ac0a4d31": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dc810a1b5ae545a09ef4b77e92695a36": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb223b5836d04aaea284e26e6a3a6a1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f02ad7bad6f74da69de3557e8b7e3b92": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_51dd1aa22f7d45ccbd3ba766bb232b57",
      "placeholder": "​",
      "style": "IPY_MODEL_eb223b5836d04aaea284e26e6a3a6a1a",
      "value": " 5274/37408 [06:38&lt;40:12, 13.32it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
